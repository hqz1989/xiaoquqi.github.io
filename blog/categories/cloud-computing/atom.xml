<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Cloud Computing | RaySun's Blog]]></title>
  <link href="http://xiaoquqi.github.io/blog/categories/cloud-computing/atom.xml" rel="self"/>
  <link href="http://xiaoquqi.github.io/"/>
  <updated>2016-05-25T10:47:50+08:00</updated>
  <id>http://xiaoquqi.github.io/</id>
  <author>
    <name><![CDATA[Ray Sun ]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[深度解读OpenStack Mitaka国内代码贡献]]></title>
    <link href="http://xiaoquqi.github.io/blog/2016/04/07/contribution-in-mitaka/"/>
    <updated>2016-04-07T23:19:39+08:00</updated>
    <id>http://xiaoquqi.github.io/blog/2016/04/07/contribution-in-mitaka</id>
    <content type="html"><![CDATA[<p>转眼间，OpenStack又迎来了新版本发布的日子，这是OpenStack第13个版本，也是Big Tent后的第二个版本，秉承“公开公正”的原则，OpenStack Release的项目达到了29个，比Liberty多出了8个。</p>

<p>去年的时候，对国内的OpenStack Liberty贡献进行了深度解读后引起了广泛的关注，在今年Mitaka版本发布之后，类似的解读已经遍布朋友圈，但是在看过后，发现并非国内贡献的全部统计，所以决定还是自己写一篇完整的深度解读系列文章，来帮助国内用户对国内OpenStack的现状有一个全面的了解和认识。</p>

<p>这几天一直在思考写这篇文章的目的和意义，我们搞分析也好，搞排名也罢，到底是为了什么？Mitaka版本更新后，各个公司也以排名作为企业宣传的最好的武器，我觉得这些都无可厚非。但是我觉得更重要的一点是在当前去IOEV的大形势下，我们应该告诉国内的企业用户，有一批热衷于追求Geek精神的年轻人在为中国未来的IT产业变革做着不懈的努力，他们用数字证明了国外公司能做到的我们国内公司也能做到，这个世界上不仅有IOEV，还有中国制造的OpenStack。</p>

<p>对于友商们已经分析的数据，这里不再赘述，本文主要通过stackalytics.com提供的API对国内社区贡献进行一次深度挖掘和整理。</p>

<p>OpenStack Liberty深度解读请见：<a href="http://xiaoquqi.github.io/blog/2015/10/29/contribution-in-liberty/">http://xiaoquqi.github.io/blog/2015/10/29/contribution-in-liberty/</a></p>

<!-- more -->


<h2>Release项目简介</h2>

<p>Openstack官方的Release的网站已经更新为：<a href="http://releases.openstack.org/">http://releases.openstack.org/</a></p>

<p>在Big Tent公布之后，OpenStack的项目被分为Core Projects和Big Tent Projects。</p>

<p><img class="center" src="/images/blogs/contribution-in-mitaka-big-tent.jpg"></p>

<p>让我们来看一下在Mitaka版本中，多了哪些新项目。</p>

<ul>
<li>几个与Docker相关的项目被发布出来，magnum, senlin, solum</li>
<li>数据备份容灾的项目：freezer</li>
<li>计费的项目：cloudkitty</li>
<li>NFV相关的项目：tracker</li>
<li>监控相关的项目：monasca</li>
</ul>


<p>关于这些新项目的一些介绍，我将放在另外一篇博客里，敬请关注。</p>

<p><img class="center" src="/images/blogs/contribution-in-mitaka-projects.png"></p>

<h2>社区贡献总体分析</h2>

<p>本次统计的方法仍然为commits的方式，统计范围为stackalystatics默认统计的全部项目。</p>

<p>从总体参与的公司数量来看，Mitaka版本略有下降，但是参与的人数多了100多人。</p>

<p><img class="center" src="/images/blogs/contribution-in-mitaka-companies-contributors.png"></p>

<p>整个社区的公司贡献排名上没有明显的变化，传统的几大豪强仍然霸占公司排名的前十位，华为表现依然强劲，是中国区唯一能进入前十名的公司。</p>

<p>在模块方面，整体统计的绝大部分比例已经被others所占据，说明在Big Tent计划下，OpenStack正在朝更多元化的方向演进。在Mitaka排名前十位的项目中，fuel相关的两个项目都进入了前十，说明fuel在OpenStack部署的地位已经越来越重要了。同时，核心项目中的nova，neutron，cinder项目仍然在前十名的范围内，贡献量基本保持不变。值得一提的是，在Mitaka统计的项目数量已经从Liberty的708个增长到了829个，可见在短短的6个月内，OpenStack社区的蓬勃发展。</p>

<p><img class="center" src="/images/blogs/contribution-in-mitaka-companies-modules.png"></p>

<h2>OpenStack国内社区分析</h2>

<p>看完了整体统计，我们再回到国内，因为已经有文章做了我在Liberty时候的分析，所以这里我换个角度来看国内的社区贡献，首先是统计排名的变化。</p>

<h3>贡献企业</h3>

<p>在Liberty中，有13家国内企业为社区做了贡献，在Mitaka中这个数量增加到了15家企业，这里简单的将这些企业做了一下分类：</p>

<ul>
<li>互联网用户：乐视、新浪、网易</li>
<li>电信用户：中国移动</li>
<li>传统IT服务商：华为、中兴、华三</li>
<li>私有云服务商：Easystack、九州云、海云捷迅、北京有云、麒麟云、UMCloud、象云、Huron(休伦科技)</li>
</ul>


<p><img class="center" src="/images/blogs/contribution-in-mitaka-china-companies.png"></p>

<h3>行业分析</h3>

<p>通过行业的分析我们可以看出，国内的主要贡献仍然来自私有云服务商和传统IT服务商，换言之来自于以OpenStack提供产品或者服务的公司。厂商们贡献的目的很明确，主要为了展示自身在开源项目中的积累和专家形象。而用户的贡献主要来自平时在使用OpenStack时候遇到Bug，就是在实际应用过程中出现的问题。</p>

<p><img class="center" src="/images/blogs/contribution-in-mitaka-china-by-industry.png"></p>

<h3>人员投入分析</h3>

<p>单纯的社区贡献排名的比较仅仅是一个维度，下面我们来看一下各个公司的人员投入情况：</p>

<ul>
<li>排名前几位的公司对社区投入的人力基本都是两位数，相对于Liberty版本，人员均有所增加</li>
<li>在人均贡献投入上，99cloud是国内最高的，平均达到了59天，甚至超过了华为，这个统计不仅仅包含了代码贡献，还包含了邮件、Review、Blueprint的时间，基本可以衡量每个公司在OpenStack社区贡献方面的投入力量</li>
<li>人员投入来看，Easystack和中国移动无疑是最下本的两家，Easystack从Liberty的3人，增长到了23人，一下子增加了20人；中国移动也从最初的4个人，增加到了13个人，可见中国移动未来对OpenStack的野心</li>
</ul>


<p><img class="center" src="/images/blogs/contribution-in-mitaka-companies-effort.png"></p>

<h3>贡献模块分析</h3>

<p>从模块的角度进行统计，国内企业的贡献情况并未出现一个统一的趋势，总体的贡献项目为193个，项目几乎涉及OpenStack所有最活跃的项目，从排名前十的项目来看：</p>

<ul>
<li>得益于华为的主导，dargonflow项目的贡献量超高</li>
<li>紧随其后的，也是当下的热点，容器相关的两个项目</li>
<li>几大OpenStack老模块贡献量也高居前十位，说明这些模块是在解决方案中使用频率较高的</li>
</ul>


<p><img class="center" src="/images/blogs/contribution-in-mitaka-modules.png"></p>

<h3>投入产出比</h3>

<p>这是一个很敏感的话题，每个公司对社区的投入到底换来多少项目上的回报呢？可能这只有每个公司的CEO能够回答的问题了。我在这里就不多做过多的分析，留给大家充分讨论的空间吧。</p>

<h2>总结</h2>

<p>刚刚结束在南京的OpenStack开发培训，也了解到5G的通信网络上已经确定引入了OpenStack，虽然我说不清楚他的具体用途，但是我相信这对OpenStack这个项目、社区是一个重大的利好消息。我也相信，通过国内企业的集体努力，一定能让OpenStack在中国遍地开花结果。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Consul主要使用场景]]></title>
    <link href="http://xiaoquqi.github.io/blog/2015/12/24/use-consul/"/>
    <updated>2015-12-24T18:07:24+08:00</updated>
    <id>http://xiaoquqi.github.io/blog/2015/12/24/use-consul</id>
    <content type="html"><![CDATA[<p>假设你已经按照之前的Consul安装方法部署了一套具备环境，具体方法可以参考：<a href="http://xiaoquqi.github.io/blog/2015/12/07/consul-installation/">http://xiaoquqi.github.io/blog/2015/12/07/consul-installation/</a></p>

<p>这篇文章里主要介绍Consul的使用场景，服务和健康检查。</p>

<!-- more -->


<h2>Service</h2>

<p>服务注册有点像OpenStack Keystone的Endpoints，可以通过API方式查询到所有服务的端点信息。</p>

<p>在Agent的节点上添加一个service，之后重启服务。</p>

<ul>
<li>添加一个服务</li>
</ul>


<pre><code>$ echo '{"service": {"name": "web", "tags": ["rails"], "port": 80}}' \
    &gt;/etc/consul.d/web.json
</code></pre>

<ul>
<li>重启agent</li>
</ul>


<p>重新加载新的服务并不需要杀死进程重启服务，只需要给进程直接发送一个SIGHUP。</p>

<pre><code>$ kill -HUP $(ps -ef | grep agent | grep -v grep | awk '{print $2}')
</code></pre>

<ul>
<li>日志输出</li>
</ul>


<p>从输出的日志上都可以看到加载了新的服务web。</p>

<pre><code>==&gt; Caught signal: hangup
==&gt; Reloading configuration...
==&gt; WARNING: Expect Mode enabled, expecting 3 servers
    2015/12/24 12:01:11 [INFO] agent: Synced service 'web'
</code></pre>

<ul>
<li>利用API查询</li>
</ul>


<p>我们在任意节点上利用REST API查看服务。</p>

<pre><code>$ curl http://localhost:8500/v1/catalog/service/web
</code></pre>

<pre><code>[{"Node":"server1.consul.com","Address":"200.21.1.101","ServiceID":"web","ServiceName":"web","ServiceTags":["rails"],"ServiceAddress":"","ServicePort":80}]
</code></pre>

<h2>Health Check</h2>

<p>健康检查的方法主要是通过运行一小段脚本的方式，根据运行的结果判断检查对象的健康状况。所以可以通过任意语言定义这个脚本，脚本运行将通过和consul执行的相同用户执行。</p>

<ul>
<li>添加一个健康检查</li>
</ul>


<p>每30秒ping google.com</p>

<pre><code>$ echo '{"check": {"name": "ping",
  "script": "ping -c1 google.com &gt;/dev/null", "interval": "30s"}}' \
    &gt; /etc/consul.d/ping.json
</code></pre>

<p>为刚才的服务添加健康检查</p>

<pre><code>$ echo '{"service": {"name": "web", "tags": ["rails"], "port": 80,
  "check": {"script": "curl localhost &gt;/dev/null 2&gt;&amp;1", "interval": "10s"}}}' \
    &gt; /etc/consul.d/web.json
</code></pre>

<ul>
<li>重启agent</li>
</ul>


<pre><code>$ kill -HUP $(ps -ef | grep agent | grep -v grep | awk '{print $2}')
</code></pre>

<ul>
<li>日志输出</li>
</ul>


<p>从输出的日志上都可以看到加载了新的服务web。</p>

<pre><code>==&gt; Caught signal: hangup
==&gt; Reloading configuration...
==&gt; WARNING: Expect Mode enabled, expecting 3 servers
    2015/12/24 12:43:56 [INFO] agent: Synced service 'web'
    2015/12/24 12:43:56 [INFO] agent: Synced check 'ping'
</code></pre>

<p>经过一段时间后出现了critical和warning日志</p>

<pre><code>    2015/12/24 12:43:58 [WARN] agent: Check 'service:web' is now critical
    2015/12/24 12:44:08 [WARN] agent: Check 'ping' is now warning
</code></pre>

<ul>
<li>利用API查询</li>
</ul>


<p>Health check的状态包含了很多种，有any, unkown, passing, warning, critical。any包含了所有状态。</p>

<pre><code>$ curl http://localhost:8500/v1/health/state/critical
</code></pre>

<pre><code>[{"Node":"server1.consul.com","CheckID":"service:web","Name":"Service 'web' check","Status":"critical","Notes":"","Output":"","ServiceID":"web","ServiceName":"web"}]
</code></pre>

<h2>参考文档</h2>

<ul>
<li><a href="http://www.consul.io/docs/agent/http/catalog.html">http://www.consul.io/docs/agent/http/catalog.html</a></li>
<li><a href="http://www.consul.io/docs/agent/http/health.html">http://www.consul.io/docs/agent/http/health.html</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Consul的安装方法]]></title>
    <link href="http://xiaoquqi.github.io/blog/2015/12/07/consul-installation/"/>
    <updated>2015-12-07T10:00:13+08:00</updated>
    <id>http://xiaoquqi.github.io/blog/2015/12/07/consul-installation</id>
    <content type="html"><![CDATA[<h2>什么是Consul?</h2>

<p>Consul拥有众多的组件，简言之，就是一个用于在你的基础设施中，发现和配置服务的工具。包含以下关键功能：服务发现、健康检查、键值存储和多数据中心支持。再说的通俗一点，就是用于管理分布式系统的利器。</p>

<!-- more -->


<h2>安装Consul</h2>

<p>Consul的安装比较简单，下载之后直接解压缩就可以了，下载地址：<a href="https://www.consul.io/downloads.html">https://www.consul.io/downloads.html</a></p>

<p>我们把consul直接放在/usr/local/bin目录中。</p>

<h2>Consul Server</h2>

<pre><code>$ /usr/local/bin/consul agent -server -bootstrap-expect 3 -data-dir /tmp/consul -node=server1 -bind=10.10.10.10
</code></pre>

<h3>参数说明</h3>

<ul>
<li>-server - Serve模式</li>
<li>-bootstrap-expect - Server数量</li>
<li>-data-dir - 数据目录</li>
<li>-node - Node名称</li>
<li>-bind - 集群通讯地址</li>
</ul>


<h3>输出</h3>

<pre><code>==&gt; WARNING: Expect Mode enabled, expecting 3 servers
==&gt; WARNING: It is highly recommended to set GOMAXPROCS higher than 1
==&gt; Starting Consul agent...
==&gt; Starting Consul agent RPC...
==&gt; Consul agent running!
         Node name: 'server1.consul.com'
        Datacenter: 'dc1'
            Server: true (bootstrap: false)
       Client Addr: 127.0.0.1 (HTTP: 8500, HTTPS: -1, DNS: 8600, RPC: 8400)
      Cluster Addr: 200.21.1.101 (LAN: 8301, WAN: 8302)
    Gossip encrypt: false, RPC-TLS: false, TLS-Incoming: false
             Atlas: &lt;disabled&gt;

==&gt; Log data will now stream in as it occurs:

    2015/12/23 03:13:36 [WARN] memberlist: Binding to public address without encryption!
    2015/12/23 03:13:36 [INFO] serf: EventMemberJoin: server1.consul.com 200.21.1.101
    2015/12/23 03:13:36 [WARN] memberlist: Binding to public address without encryption!
    2015/12/23 03:13:36 [INFO] serf: EventMemberJoin: server1.consul.com.dc1 200.21.1.101
    2015/12/23 03:13:36 [INFO] raft: Node at 200.21.1.101:8300 [Follower] entering Follower state
    2015/12/23 03:13:36 [INFO] consul: adding server server1.consul.com (Addr: 200.21.1.101:8300) (DC: dc1)
    2015/12/23 03:13:36 [INFO] consul: adding server server1.consul.com.dc1 (Addr: 200.21.1.101:8300) (DC: dc1)
    2015/12/23 03:13:36 [ERR] agent: failed to sync remote state: No cluster leader
    2015/12/23 03:13:37 [WARN] raft: EnableSingleNode disabled, and no known peers. Aborting election.
    2015/12/23 03:13:51 [ERR] agent: failed to sync remote state: No cluster leader
==&gt; Newer Consul version available: 0.6.0
    2015/12/23 03:14:17 [ERR] agent: failed to sync remote state: No cluster leader
</code></pre>

<h3>查看成员</h3>

<pre><code>$ consul members
</code></pre>

<pre><code>Node                Address            Status  Type    Build  Protocol  DC
server1.consul.com  200.21.1.101:8301  alive   server  0.5.2  2         dc1
</code></pre>

<h2>Consul Agent</h2>

<pre><code>$ /usr/local/bin/consul agent -data-dir /tmp/consul -node=agent1 -bind=10.10.10.100 -config-dir /etc/consul.d
</code></pre>

<ul>
<li>输出</li>
</ul>


<pre><code>==&gt; WARNING: It is highly recommended to set GOMAXPROCS higher than 1
==&gt; Starting Consul agent...
==&gt; Starting Consul agent RPC...
==&gt; Consul agent running!
         Node name: 'agent1.consul.com'
        Datacenter: 'dc1'
            Server: false (bootstrap: false)
       Client Addr: 127.0.0.1 (HTTP: 8500, HTTPS: -1, DNS: 8600, RPC: 8400)
      Cluster Addr: 200.21.1.201 (LAN: 8301, WAN: 8302)
    Gossip encrypt: false, RPC-TLS: false, TLS-Incoming: false
             Atlas: &lt;disabled&gt;

==&gt; Log data will now stream in as it occurs:

    2015/12/24 08:09:51 [WARN] memberlist: Binding to public address without encryption!
    2015/12/24 08:09:51 [INFO] serf: EventMemberJoin: agent1.consul.com 200.21.1.201
    2015/12/24 08:09:51 [ERR] agent: failed to sync remote state: No known Consul servers
    2015/12/24 08:09:56 [INFO] agent.rpc: Accepted client: 127.0.0.1:42794
    2015/12/24 08:09:56 [INFO] agent: (LAN) joining: [200.21.1.101 200.21.1.102 200.21.1.103]
    2015/12/24 08:09:56 [INFO] serf: EventMemberJoin: server1.consul.com 200.21.1.101
    2015/12/24 08:09:56 [INFO] consul: adding server server1.consul.com (Addr: 200.21.1.101:8300) (DC: dc1)
    2015/12/24 08:09:58 [ERR] agent: failed to sync remote state: rpc error: No cluster leader
    2015/12/24 08:10:02 [INFO] agent: (LAN) joined: 1 Err: &lt;nil&gt;
    2015/12/24 08:10:02 [INFO] agent.rpc: Accepted client: 127.0.0.1:42800
==&gt; Newer Consul version available: 0.6.0
    2015/12/24 08:10:21 [WARN] agent: Check 'ping' is now warning
    2015/12/24 08:10:22 [ERR] agent: failed to sync remote state: rpc error: No cluster leader
    2015/12/24 08:10:43 [ERR] agent: failed to sync remote state: rpc error: No cluster leader
    2015/12/24 08:11:01 [WARN] agent: Check 'ping' is now warning
    2015/12/24 08:11:02 [ERR] agent: failed to sync remote state: rpc error: No cluster leader
    2015/12/24 08:11:23 [ERR] agent: failed to sync remote state: rpc error: No cluster leader
    2015/12/24 08:11:41 [WARN] agent: Check 'ping' is now warning
    2015/12/24 08:11:43 [ERR] agent: failed to sync remote state: rpc error: No cluster leader
    2015/12/24 08:12:12 [ERR] agent: failed to sync remote state: rpc error: No cluster leader
    2015/12/24 08:12:21 [WARN] agent: Check 'ping' is now warning
    2015/12/24 08:12:36 [ERR] agent: failed to sync remote state: rpc error: No cluster leader
    2015/12/24 08:13:01 [WARN] agent: Check 'ping' is now warning
    2015/12/24 08:13:03 [ERR] agent: failed to sync remote state: rpc error: No cluster leader
</code></pre>

<ul>
<li>server日志输出</li>
</ul>


<pre><code>    2015/12/24 08:09:58 [INFO] serf: EventMemberJoin: agent1.consul.com 200.21.1.201
</code></pre>

<h3>查看成员</h3>

<pre><code>$ consul members
</code></pre>

<pre><code>Node                Address            Status  Type    Build  Protocol  DC
server1.consul.com  200.21.1.101:8301  alive   server  0.5.2  2         dc1
agent1.consul.com   200.21.1.201:8301  alive   client  0.5.2  2         dc1
</code></pre>

<h2>最终结果</h2>

<pre><code>$ consul members
</code></pre>

<pre><code>Node                Address            Status  Type    Build  Protocol  DC
server1.consul.com  200.21.1.101:8301  alive   server  0.5.2  2         dc1
agent1.consul.com   200.21.1.201:8301  alive   client  0.5.2  2         dc1
agent2.consul.com   200.21.1.202:8301  alive   client  0.5.2  2         dc1
server2.consul.com  200.21.1.102:8301  alive   server  0.5.2  2         dc1
server3.consul.com  200.21.1.103:8301  alive   server  0.5.2  2         dc1
agent3.consul.com   200.21.1.203:8301  alive   client  0.5.2  2         dc1
</code></pre>

<h2>参考文档</h2>

<ul>
<li><a href="https://www.consul.io/intro/getting-started/install.html">https://www.consul.io/intro/getting-started/install.html</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用Grafana+Diamond+Graphite构造完美监控面板]]></title>
    <link href="http://xiaoquqi.github.io/blog/2015/12/01/use-grafana-to-monitor-your-cluster/"/>
    <updated>2015-12-01T07:59:46+08:00</updated>
    <id>http://xiaoquqi.github.io/blog/2015/12/01/use-grafana-to-monitor-your-cluster</id>
    <content type="html"><![CDATA[<p>服务器监控软件五花八门，没有一个是对的，但是总有一款是适合你的，本文中将使用Grafana+Dimaond+Graphite构造一款漂亮的监控面板，你可以独自欣赏，也可以让他们和你的应用勾勾搭搭。</p>

<p>本文中的安装测试，主要在CentOS 6.5下完成。先来张Grafna效果图，左边是我们的数据源Graphite，右边是我们的Grafna的效果图：</p>

<p><img class="center" src="/images/blogs/grafana-screenshot.png" width="800"></p>

<!-- more -->


<h2>安装及配置Dimaond</h2>

<p>安装Diamond最直接和简单的方法就是自己编译RPM或者DEB的安装包, Diamond在这方面提供了比较好的支持。</p>

<pre><code class="bash bash"># cd /root
# yum install -y git rpm-build python-configobj python-setuptools
# git clone https://github.com/python-diamond/Diamond
# cd Diamond
# make rpm
# cd dist
# rpm -ivh diamond-*.noarch.rpm
</code></pre>

<p>默认情况下，Diamond开启了基本的监控信息，包括CPU、内存、磁盘的性能数据。当然，我们可以通过配置启动相应的监控项，也能通过自定义的方式进行相应的扩展。这里，我们在/etc/diamond/collectors加载额外的插件，下面的例子中开启了网络的监控。</p>

<pre><code class="bash bash"># cp -f /etc/diamond/diamond.conf.example /etc/diamond/diamond.conf

# cat &lt;&lt; EOF | tee -a /etc/diamond/diamond.conf
[configs]
path = "/etc/diamond/collectors/"
extension = ".conf"
EOF

# cat &lt;&lt; EOF | tee /etc/diamond/collectors/net.conf
[collectors]

[[NetworkCollector]]
enabled = True
EOF
</code></pre>

<p>那么到目前为止，Diamond的基本安装和配置已经完成，但是现在只是简单的采集数据，并没有指明数据要发送给谁，所以下一步我们来开始配置Graphite。</p>

<h2>安装及配置Graphite</h2>

<p>Graphite主要做两件事情：按照时间存储数据、生成图表，在我们的场景里面，实质上就是把Graphite作为数据源给Grafana提供数据。另外还需要安装的是carbon，负责通过网络接受数据并保存到后端存储中；另外还需要whisper，负责生成Graphite样式的基于文件的时间序列的数据库。</p>

<h3>安装软件包</h3>

<pre><code class="bash bash"># yum install -y graphite-web graphite-web-selinux
# yum install -y mysql mysql-server MySQL-python
# yum install -y python-carbon python-whisper
</code></pre>

<h3>配置MySQL</h3>

<pre><code class="bash bash"># /etc/init.d/mysqld start

# mysql -e "CREATE DATABASE graphite;" -u root
# mysql -e "GRANT ALL PRIVILEGES ON graphite.* TO 'graphite'@'localhost' IDENTIFIED BY 'sysadmin';" -u root
# mysql -e 'FLUSH PRIVILEGES;' -u root
</code></pre>

<h3>配置Graphite</h3>

<ul>
<li>local setting</li>
</ul>


<pre><code class="bash /etc/graphite-web/local_settings.py"># SECRET_KEY=$(md5sum /etc/passwd | awk {'print $1'})

# echo "SECRET_KEY = '$SECRET_KEY'" | tee -a /etc/graphite-web/local_settings.py
# echo "TIME_ZONE = 'Asia/Shanghai'" | tee -a /etc/graphite-web/local_settings.py

# cat &lt;&lt; EOF | tee -a /etc/graphite-web/local_settings.py
DATABASES = {
    'default': {
        'NAME': 'graphite',
        'ENGINE': 'django.db.backends.mysql',
        'USER': 'graphite',
        'PASSWORD': 'sysadmin',
    }
}
EOF

# cd /usr/lib/python2.6/site-packages/graphite
# ./manage.py syncdb --noinput

# echo "from django.contrib.auth.models import User; User.objects.create_superuser('admin', 'admin@hihuron.com', 'sysadmin')" | ./manage.py shell
</code></pre>

<ul>
<li>Apache配置</li>
</ul>


<pre><code class="bash /etc/httpd/conf.d/graphite-web.conf">Listen 0.0.0.0:10000
&lt;VirtualHost *:10000&gt;
    ServerName graphite-web
    DocumentRoot "/usr/share/graphite/webapp"
    ErrorLog /var/log/httpd/graphite-web-error.log
    CustomLog /var/log/httpd/graphite-web-access.log common
    Alias /media/ "/usr/lib/python2.6/site-packages/django/contrib/admin/media/"

    WSGIScriptAlias / /usr/share/graphite/graphite-web.wsgi
    WSGIImportScript /usr/share/graphite/graphite-web.wsgi process-group=%{GLOBAL} application-group=%{GLOBAL}

    &lt;Location "/content/"&gt;
        SetHandler None
    &lt;/Location&gt;

    &lt;Location "/media/"&gt;
        SetHandler None
    &lt;/Location&gt;
&lt;/VirtualHost&gt;
</code></pre>

<ul>
<li>Diamond配置</li>
</ul>


<pre><code class="bash bash"># HOST_IP=$(ifconfig | sed -En 's/127.0.0.1//;s/.*inet (addr:)?(([0-9]*\.){3}[0-9]*).*/\2/p' | head -1)

# sed  -i "/^\[\[GraphiteHandler\]\]$/,/^\[.*\]/s/^host = 127.0.0.1$/host = $HOST_IP/" /etc/diamond/diamond.conf
# sed  -i "/^\[\[GraphitePickleHandler\]\]$/,/^\[.*\]/s/^host = 127.0.0.1$/host = $HOST_IP/" /etc/diamond/diamond.conf
</code></pre>

<h3>启动服务</h3>

<pre><code class="bash bash"># service carbon-cache restart
# service httpd restart
# service diamond restart
</code></pre>

<h2>安装和配置Grafana</h2>

<p>Grafana最主要的功能就是对数据的呈现，基于一切可提供time series的后台服务。这里面我们使用Graphite为Grafana提供数据。</p>

<h3>安装及配置</h3>

<pre><code class="bash bash"># yum install -y nodejs
# rpm -ivh https://grafanarel.s3.amazonaws.com/builds/grafana-2.5.0-1.x86_64.rpm
# sudo /sbin/chkconfig --add grafana-server
# sed -i 's/^;http_port = 3000$/http_port = 10001/g' /etc/grafana/grafana.ini
# sudo service grafana-server start
</code></pre>

<h3>添加datasource</h3>

<p>Grafana提供了非常丰富的REST API，我们不仅可以直接利用Grafana作为数据呈现层，还可以利用REST API直接将Grafana的Graph集成在我们的应用中。下面我们利用REST API为Grafana添加datasource。</p>

<pre><code class="bash bash"># curl -i 'http://admin:admin@localhost:10001/api/datasources' -X POST -H "Accept: application/json" -H "Content-Type: application/json" -d '{"name": "graphite", "type": "graphite", "url": "http://localhost:10000", "access": "proxy", "basicAuth": false}'
</code></pre>

<h2>Ceph监控</h2>

<h3>修改ceph脚本兼容性</h3>

<p>Diamond是基于Python开发的，但是由于CentOS 6.5的Python版本较低(2.6)，所以直接使用社区版本的Ceph监控时，会导致错误。可以通过简单的修改进行修复。</p>

<pre><code class="python /usr/share/diamond/collectors/ceph/ceph.py">    def _get_stats_from_socket(self, name):
        """Return the parsed JSON data returned when ceph is told to
        dump the stats from the named socket.

        In the event of an error error, the exception is logged, and
        an empty result set is returned.
        """
        try:
            #json_blob = subprocess.check_output(
            #    [self.config['ceph_binary'],
            #     '--admin-daemon',
            #     name,
            #     'perf',
            #     'dump',
            #     ])
            cmd = [
                 self.config['ceph_binary'],
                 '--admin-daemon',
                 name,
                 'perf',
                 'dump',
            ]
            process = subprocess.Popen(cmd, stdout=subprocess.PIPE)
            json_blob = process.communicate()[0]
</code></pre>

<h3>增加对ceph osd perf监控</h3>

<p>在实际运维Ceph过程中，ceph osd perf是一个非常重要的指令，能够观察出集群中磁盘的latency的信息，通过观察变化，可以辅助判断磁盘出现性能问题。Diamond的设计中，每个Diamond Agent只会采集自己本机的指标，所以我们在添加的时候，只需要在一个节点上增加这个监控就可以了。在ceph.py中结尾处新增加一个类。</p>

<pre><code class="python /usr/share/diamond/collectors/ceph/ceph.py">class CephOsdCollector(CephCollector):

    def _get_stats(self):
        """Return the parsed JSON data returned when ceph is told to
        dump the stats from the named socket.

        In the event of an error error, the exception is logged, and
        an empty result set is returned.
        """
        try:
            #json_blob = subprocess.check_output(
            #    [self.config['ceph_binary'],
            #     '--admin-daemon',
            #     name,
            #     'perf',
            #     'dump',
            #     ])
            cmd = [
                 self.config['ceph_binary'],
                 'osd',
                 'perf',
                 '--format=json',
            ]
            process = subprocess.Popen(cmd, stdout=subprocess.PIPE)
            json_blob = process.communicate()[0]
        except subprocess.CalledProcessError, err:
            self.log.info('Could not get stats from %s: %s',
                          name, err)
            self.log.exception('Could not get stats from %s' % name)
            return {}

        try:
            json_data = json.loads(json_blob)
        except Exception, err:
            self.log.info('Could not parse stats from %s: %s',
                          name, err)
            self.log.exception('Could not parse stats from %s' % name)
            return {}

        return json_data

    def _publish_stats(self, stats):
        """Given a stats dictionary from _get_stats_from_socket,
        publish the individual values.
        """
        for perf in stats['osd_perf_infos']:
            counter_prefix = 'osd.' + str(perf['id'])
            for stat_name, stat_value in flatten_dictionary(
                perf['perf_stats'],
                prefix=counter_prefix,
            ):
              self.log.info('stat_name is %s', stat_name)
              self.log.info('stat_value is %s', stat_value)
              self.publish_gauge(stat_name, stat_value)

    def collect(self):
        """
        Collect stats
        """
        self.log.info('in ceph osd collector')
        stats = self._get_stats()
        self._publish_stats(stats)
</code></pre>

<h3>修改Diamond监控配置</h3>

<pre><code class="bash /etc/diamond/collectors/ceph.conf"># cat &lt;&lt; EOF | tee /etc/diamond/collectors/ceph.conf
[collectors]

[[CephCollector]]
enabled = True

[[CephOsdCollector]]
enabled = True
EOF
</code></pre>

<pre><code class="bash bash"># service diamond restart
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[深度解读OpenStack Liberty国内代码贡献]]></title>
    <link href="http://xiaoquqi.github.io/blog/2015/10/29/contribution-in-liberty/"/>
    <updated>2015-10-29T18:56:06+08:00</updated>
    <id>http://xiaoquqi.github.io/blog/2015/10/29/contribution-in-liberty</id>
    <content type="html"><![CDATA[<p>又到了OpenStack 新版本发布的季节，虽然秋意寒寒，但是仍然挡不住OpenStack再次掀起全球关注的热点。这是OpenStack第12个版本，与之前的沉稳低调相比，这次的Release中一口气多了5个新模块，也创下了OpenStack项目创建以来的最高纪录。由于天然的架构优势，让OpenStack在云计算横行天下的年代游刃有余，已经逐步成为了云平台的即成标准，从OpenStack对待AWS的API兼容的态度就能看出，OpenStack变得越来越自信。</p>

<p>OpenStack Liberty完整版本的翻译可见：<a href="https://wiki.openstack.org/wiki/ReleaseNotes/Liberty/zh-hans">https://wiki.openstack.org/wiki/ReleaseNotes/Liberty/zh-hans</a></p>

<p>本次OpenStack Liberty更新日志中文版本的翻译工作由我完成。由于时间仓促，难免有很多问题，欢迎各位批评指正。</p>

<!-- more -->


<h2>社区贡献分析</h2>

<p>本次统计，并没有采用Review的数量为依据，而直接采用commits的方式，也就是代码实际merge入库的数量。</p>

<p>我们仍然要先看一下模块的贡献情况：</p>

<p><img class="left" src="/images/blogs/contribution-in-liberty-contribution-by-modules.png" width="400"></p>

<p>与之前Release的特点相似，OpenStack早期的核心模块Nova, Keystone代码commits数量出现明显下滑状态，而Neutron, Heat, Trove, Ceilometer, Cinder等模块都保持着稳中有升的态势。值得关注的是，在排名前20名的项目中，出现了两个直接与Docker有关的项目Kolla和Magnum，一个与docker间接有关的项目Murano。可以预见，OpenStack下一步发展的热点就是在与Docker之间的勾勾搭搭。</p>

<p>特别需要注意的是，在stackalytics.com统计的模块中，在Kilo中是259个，而到了Liberty到了389个，当然有一些项目并非完全是OpenStack的项目，但是也从一个侧面反映出OpenStack以及周边项目的蓬勃发展。</p>

<p>从更新日志中我们也能看到，本次Release的正式项目中，变动较大的是Neutron和Heat两个模块。在经历不断锤炼后，Neutron逐渐走向成熟，但是从生产级别角度看，Neutron的确还有很长的路要走。</p>

<h2>国内社区贡献分析</h2>

<p><img class="center" src="/images/blogs/contribution-in-liberty-contributor.png" width="400"></p>

<p>从全球企业的贡献排名来看，排名状况基本变化不大，仍然是HP, Redhat, Mirantis, IBM, Rackspace, Intel, Cisco，但是非常欣喜的，国内的IT的航空母舰华为已经成功杀入前十名，这无疑是振奋人心的事情，希望华为未来能多一些对OpenStack社区的主导力，提高中国在OpenStack社区的地位，当然最好也能扶植一下国内的OpenStack创业公司，实现共同发展、共同进步。华为的主要代码贡献集中在dragonflow，magnum，heat等模块，特别是在dragonflow上，几乎全部是华为贡献的，magnum上也将近有五分之一的代码。</p>

<p><strong><em>华为社区贡献统计</em></strong></p>

<p><img class="center" src="/images/blogs/contribution-in-liberty-huawei.png" width="800"></p>

<p>记得在OpenStack五周年的庆祝活动上，Intel的陈绪博士说过，国内OpenStack贡献企业，就是一朵大云，四朵小云，下面让我们来看看这几朵小云在这个版本的表现。</p>

<p><strong><em> 99cloud社区贡献统计</em></strong></p>

<p><img class="center" src="/images/blogs/contribution-in-liberty-99cloud.png" width="800"></p>

<p>排名第16位的是99cloud，99cloud自上一个版本排名四朵小云之首后，本次继续强劲来袭，排名创造历史新高，第16名。通过对贡献模块的分析，我们能看出99cloud最大的贡献来自于社区文档，而在项目方面的贡献则主要来自murano-dashboard，horizon，neutron等项目上，从中可以看出99cloud对murano这个applicaton catalog的项目关注程度比较高，可能会在将来的产品中有所体现。从贡献中，我们隐约看到了九州云的副总裁李开总的提交，由此可见九州云为社区贡献的积极程度。
更加难能可贵的是，Horizon的全球贡献99cloud是全球前十，Tempest全球前八，Murano项目更是进入全球前三，相当给力。</p>

<p><strong><em> UnitedStack社区贡献统计 </em></strong>
<img class="center" src="/images/blogs/contribution-in-liberty-unitedstack.png" width="800"></p>

<p>排在第30位的是UnitedStack，经过了上一个版本的短暂沉寂后，这个版本卷土重来，杀回前30。从代码贡献来看，UnitedStack的主要贡献来自python-openstackclient以及部署用到的puppet相关代码，当然对neutron、trove、kolla、heat等也有一定数量的贡献。</p>

<p><strong><em> Kylin Cloud社区贡献统计 </em></strong>
<img class="center" src="/images/blogs/contribution-in-liberty-kylincloud.png" width="800"></p>

<p>排名第38位的是麒麟云，其实麒麟云每次Release中总是有她的身影，但好像总是被忽略的。麒麟云最大的贡献来自Horizon项目，其他模块也有一定数量的贡献。总之，我们想到OpenStack企业的时候，的确应该时常提起麒麟云。</p>

<p><strong><em> Easystack社区贡献统计 </em></strong>
<img class="center" src="/images/blogs/contribution-in-liberty-easystack.png" width="800"></p>

<p>排名第70位的是Easystack，Easystack也属于OpenStack早期创业的公司，对于OpenStack的贡献也是持续的。Easystack最大的贡献来自nova，虽然数量不是很多，但是在国内企业里应该算名列前茅的啦。Easystack对Nova的贡献主要来自对libvirt层的bug修复。</p>

<p><strong><em> Awcloud社区贡献统计 </em></strong>
<img class="center" src="/images/blogs/contribution-in-liberty-awcloud.png" width="800"></p>

<p>排名第75位的是海云捷迅，海云应该算是在国内发展比较迅猛的一家OpenStack早期创业公司。他们的贡献主要来自Neutron相关的项目，看起来应该是为了解决项目中出现的实际问题所做的努力。海云的马力应该是公司内部贡献排名第一的，尤其是前一段时间发布的两篇关于&#8221;Neutron &amp; OpenStack漫谈&#8221;，非常值得一读。</p>

<p><strong><em> LeTV社区贡献统计 </em></strong>
<img class="center" src="/images/blogs/contribution-in-liberty-letv.png" width="800"></p>

<p><strong><em> Netease社区贡献统计 </em></strong>
<img class="center" src="/images/blogs/contribution-in-liberty-netease.png" width="800"></p>

<p>排名第94和95位的分别是两家互联网企业，乐视和网易，乐视是最近互联网中使用OpenStack动静最大的一家了，应该能在大规模应用中发现OpenStack很多问题吧。</p>

<p><strong><em> Huron社区贡献统计 </em></strong>
<img class="center" src="/images/blogs/contribution-in-liberty-huron.png" width="800"></p>

<p>排名第122位的是我的公司——北京休伦科技有限公司，其实我们公司也算是国内最早一批从事OpenStack创业的公司，z早在2013年的时候就已经开始投入OpenStack私有云产品相关的研发。我们贡献的代码主要来自Nova和Murano两个模块中，都是我们在开发和项目使用中发现的问题，修复后回馈给社区的，我也希望我们能在下一个版本Release中贡献更多的力量。</p>

<p><strong><em> China Mobile社区贡献统计 </em></strong>
<img class="center" src="/images/blogs/contribution-in-liberty-chinamobile.png" width="800"></p>

<p>排名第133位的是中国移动，之前并没有在哪一个排名上看到过中国移动在OpenStack贡献，我也是第一次发现。中国移动应该算是国内运营商领域技术实力较强的一家，也是运营商里开始从事OpenStack预研较早的一家。中国移动有大量的IT资源和设备，理应像AT&amp;T一样在OpenStack领域大有所为。纵观中国移动的社区贡献，主要来自Neutron和Ceilometer两个项目，几个Bug修复都是与Volume相关。</p>

<p><strong><em> Lenovo社区贡献统计 </em></strong>
<img class="center" src="/images/blogs/contribution-in-liberty-lenovo.png" width="800"></p>

<p>排名第135位的是联想。不评论了。</p>

<p>排名第139位的是清华大学医学院附属医院，这个有点意思。但是stackalytics.com有Bug，他们的具体统计显示不出来。</p>

<p><strong><em> H3C社区贡献统计 </em></strong>
<img class="center" src="/images/blogs/contribution-in-liberty-h3c.png" width="800"></p>

<p>排名第143位的是H3C。贡献是Nova中的关于VMware的Bug Fix。</p>

<p>由于stackalytics并没有按照区域统计的功能，所以本次统计完全是全自动统计(全靠我自己手动)，所以难免遗漏了为OpenStack贡献的国内企业，如果发生该情况请及时告知。</p>

<h2>社区贡献内容分析</h2>

<p><img class="center" src="/images/blogs/contribution-in-liberty-complete-blueprints.png" width="800"></p>

<p>从贡献的commits的类型来区分，国内贡献出的代码主要还是以bug为主，这可能也与我们使用的都是OpenStack较成熟的模块有关，本身这些模块成熟程度较高，所以想做blueprint很难。另外一个很重要的原因是和OpenStack管理流程有关的，现在像Nova, Cinder等项目都是需要先Review Specs的，其实就是所谓的设计文档，语言成为国内很多工程师贡献的最大障碍，所以这也导致了Blueprint的贡献度在国内并不高。</p>

<p><strong><em> Huawei社区贡献——完成Blueprint </em></strong>
<img class="center" src="/images/blogs/contribution-in-liberty-blueprint-huawei.png" width="800"></p>

<p>纵观整个Blueprint的完成统计情况，华为作为国内最有实力的企业，高居全球第五名，完成最多的模块为cinder和mistral。</p>

<p>之后能完成Blueprint的企业还包括UnitedStack、中国移动、麒麟云、海云捷迅和九州云，但是相比来说数量较少，都是个位数字。</p>

<p>OpenStack在国内发展已经超过了四年的时间，但是遗憾的一点，尽管我们拥有世界上最多的开发人员，但是我们对社区仍然没有话语权，国内的用户的需求无法对社区上游形成影响，导致很多本地化定制的需求无法真正的在社区版本代码得到体现。所以如何让中国的声音出现在社区，是我们所有OpenStack人需要思考的问题。欣喜的一点，本土的巨头华为已经身先士卒，投入很大的力量搞OpenStack的社区贡献，我们更希望越来越多的国内传统IT巨头能够意识到这个问题，投身于开源的事业中，否则我们又在起跑线上输给了别人。</p>

<p>以上仅代表个人观点，如有任何异议，欢迎批评指正。</p>
]]></content>
  </entry>
  
</feed>
