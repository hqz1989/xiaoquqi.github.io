<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
  <meta charset="utf-8">
  <title>使用Docker部署Ceph - RaySun&#8217;s Blog</title>
  <meta name="author" content="Ray Sun <xiaoquqi@gmail.com>&#8221;>

  
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://xiaoquqi.github.io/blog/2016/06/13/bootstrap-your-ceph-cluster-in-docker/">
  <link href="/favicon.png" type="image/png" rel="icon">
  <link href="/atom.xml" rel="alternate" title="RaySun's Blog" type="application/atom+xml">

  <!-- http://opengraphprotocol.org/ -->
  <meta name="twitter:card" content="summary_large_image">
  <meta property="og:type" content="website">
  <meta property="og:url" content="http://xiaoquqi.github.io/blog/2016/06/13/bootstrap-your-ceph-cluster-in-docker/">
  <meta property="og:title" content="使用Docker部署Ceph - RaySun's Blog">
  

  <script src="/javascripts/libs/jquery/jquery-2.1.3.min.js"></script>

<link href="/assets/bootstrap/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="/assets/bootstrap/dist/css/bootstrap-theme.min.css" rel="stylesheet" type="text/css">


  
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/stylesheets/data-table.css" media="screen, projection" rel="stylesheet" type="text/css" />

  

  
  <script>
  var _hmt = _hmt || [];
  (function() {
    var hm = document.createElement("script");
    hm.src = "//hm.baidu.com/hm.js?d43617b82d6762df4e16d4c93de17177";
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(hm, s);
  })();
  </script>


  
<script type="text/javascript" src="http://tajs.qq.com/stats?sId=51237761" charset="UTF-8"></script>


</head>

  <body   >
    <a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>
    <div id="wrap">
      <header role="banner">
        <nav class="navbar navbar-default" role="navigation">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" title="toggle navbar" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">RaySun&#8217;s Blog</a>
        </div>

        <div class="navbar-collapse collapse">
            <ul class="nav navbar-nav">
                <li class="active">
                    <a rel="index" href="/">Blog</a>
                </li>
                <li >
                    <a href="/blog/archives">Archives</a>
                </li>
                <li >
                    <a href="/aboutme">About Me</a>
                </li>
            </ul>
            <ul class="nav navbar-nav navbar-right">
                
                    <li>
                        <form class="search navbar-form navbar-right" action="https://www.google.com/search" method="GET">
                            <input type="hidden" name="sitesearch" value="xiaoquqi.github.io">
                            <div class="form-group">
                                <input class="form-control" type="text" name="q" placeholder="Search">
                            </div>
                        </form>
                    </li>
                
                <li>
                    <a class="subscribe-rss" href="/atom.xml" title="subscribe via RSS">
                        <span class="visible-xs">RSS</span>
                        <img class="hidden-xs" src="/images/rss.png" alt="RSS">
                    </a>
                </li>
                
            </ul>
        </div>
    </div>
</nav>


      </header>
      <div id="main" role="main" class="container">
        <div id="content">
          <div class="row">
  <div class="page-content col-md-9" itemscope itemtype="http://schema.org/Blog">
    <meta itemprop="name" content="RaySun's Blog" />
    
    <meta itemprop="url" content="http://xiaoquqi.github.io" />
    <article class="hentry" role="article" itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting">
      
  <header class="page-header">
    
      <p class="meta text-muted text-uppercase">
        












<span class="glyphicon glyphicon-calendar"></span> <time datetime="2016-06-13T15:20:50+08:00"  data-updated="true" itemprop="datePublished dateCreated">2016-06-13 15:20</time>
        
        
           | <a href="#comments">Comments</a>
        
      </p>
    
    
    <h1 class="entry-title" itemprop="name headline">
        使用Docker部署Ceph
        
    </h1>
    
  </header>


<div class="entry-content clearfix" itemprop="articleBody description"><p>这篇文章是根据Sébastien Han的<a href="https://www.youtube.com/watch?v=FUSTjTBA8f8&amp;feature=youtu.be">演示视频</a>进行整理的，对过程中有问题的部分进行了修复。</p>

<p>Docker作为持久化集成的最佳工具，特别是在部署中有着得天独厚的优势。Ceph作为开源的分布式存储得到越来越多的使用，但是作为分布式系统，Ceph在部署和运维上仍然有不小的难度,本文重点介绍利用Docker快速的进行Ceph集群的创建，以及各个组件的安装。</p>

<!-- more -->


<h2>部署环境</h2>

<ul>
<li>至少需要三台虚拟机或者物理机，每台虚拟机或者物理机至少有两块硬盘，这里我是在一台物理机上用vagrant模拟出三台CentOS 6.6虚拟机进行的实验</li>
<li>三台虚拟机需要安装docker，本文附带Docker加速方案</li>
<li>获取ceph/daemon镜像</li>
</ul>


<h2>部署流程</h2>

<p><img class="center" src="/images/blogs/bootstrap-ceph-docker-flow.png"></p>

<h2>部署架构</h2>

<p>主机名和集群的对应关系如下：</p>

<ul>
<li>node1 -> 192.168.33.11</li>
<li>node2 -> 192.168.33.12</li>
<li>node3 -> 192.168.33.13</li>
</ul>


<p><img class="center" src="/images/blogs/bootstrap-ceph-docker-architecture.png"></p>

<h2>环境准备</h2>

<h3>安装Docker，下载镜像</h3>

<p>国内安装Dcoker还是速度很慢的，这里推荐使用daocloud的加速方案。不但docker安装速度提高了，pull镜像的速度也大幅度提高。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>curl -sSL https://get.daocloud.io/docker | sh</span></code></pre></td></tr></table></div></figure>


<p>我是在CentOS系统上进行的测试，将docker加入自动启动，并启动docker，接下来pull ceph daemon镜像，该镜像包含了所有的ceph服务和entrypoint。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>chkconfig docker
</span><span class='line'>service docker start
</span><span class='line'>docker pull ceph/daemon</span></code></pre></td></tr></table></div></figure>


<h3>启动第一个Monitor</h3>

<p>在node1上启动第一个Monitor，注意，如果你的环境中IP和我不同，请修改MON_IP。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo docker run -d \
</span><span class='line'>     --net=host \
</span><span class='line'>     -v /etc/ceph:/etc/ceph \
</span><span class='line'>     -v /var/lib/ceph/:/var/lib/ceph/ \
</span><span class='line'>     -e MON_IP=192.168.33.11 \
</span><span class='line'>     -e CEPH_PUBLIC_NETWORK=192.168.33.0/24 \
</span><span class='line'>     ceph/daemon mon</span></code></pre></td></tr></table></div></figure>


<p>验证一下效果：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>docker ps</span></code></pre></td></tr></table></div></figure>




<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>CONTAINER ID        IMAGE               COMMAND                CREATED             STATUS              PORTS               NAMES
</span><span class='line'>7babea544ef1        ceph/daemon         "/entrypoint.sh mon"   3 seconds ago       Up 2 seconds                            backstabbing_brattain</span></code></pre></td></tr></table></div></figure>


<p>查看一下集群状态：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>docker exec 7babea544ef1 ceph -s</span></code></pre></td></tr></table></div></figure>


<p>当前集群状态，能看到当前已经有一个mon启动起来了。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cluster 0de1fc5a-084d-4396-bb0b-59db72a9a439
</span><span class='line'> health HEALTH_ERR
</span><span class='line'>        64 pgs stuck inactive
</span><span class='line'>        64 pgs stuck unclean
</span><span class='line'>        no osds
</span><span class='line'> monmap e1: 1 mons at {node1.docker.com=192.168.33.11:6789/0}
</span><span class='line'>        election epoch 2, quorum 0 node1.docker.com
</span><span class='line'> osdmap e1: 0 osds: 0 up, 0 in
</span><span class='line'>        flags sortbitwise
</span><span class='line'>  pgmap v2: 64 pgs, 1 pools, 0 bytes data, 0 objects
</span><span class='line'>        0 kB used, 0 kB / 0 kB avail
</span><span class='line'>              64 creating</span></code></pre></td></tr></table></div></figure>


<h3>复制配置文件</h3>

<p>接下来需要将node1的配置文件复制到node2和node3上，复制的路径包含/etc/ceph和/var/lib/ceph/bootstrap-*下的所有内容。这些配置文件非常重要，如果没有这些配置文件的存在，我们在其他节点启动新的docker ceph daemon的时候会被认为是一个新的集群。
我们在node1执行以下命令：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ssh root@node2 mkdir -p /var/lib/ceph
</span><span class='line'>scp -r /etc/ceph root@node2:/etc
</span><span class='line'>scp -r /var/lib/ceph/bootstrap* root@node2:/var/lib/ceph
</span><span class='line'>
</span><span class='line'>ssh root@node3 mkdir -p /var/lib/ceph
</span><span class='line'>scp -r /etc/ceph root@node3:/etc
</span><span class='line'>scp -r /var/lib/ceph/bootstrap* root@node3:/var/lib/ceph</span></code></pre></td></tr></table></div></figure>


<h3>启动第二个和第三个Monitor</h3>

<p>在node2上执行：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo docker run -d \
</span><span class='line'>     --net=host \
</span><span class='line'>     -v /etc/ceph:/etc/ceph \
</span><span class='line'>     -v /var/lib/ceph/:/var/lib/ceph/ \
</span><span class='line'>     -e MON_IP=192.168.33.12 \
</span><span class='line'>     -e CEPH_PUBLIC_NETWORK=192.168.33.0/24 \
</span><span class='line'>     ceph/daemon mon</span></code></pre></td></tr></table></div></figure>


<p>在node3上执行：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo docker run -d \
</span><span class='line'>     --net=host \
</span><span class='line'>     -v /etc/ceph:/etc/ceph \
</span><span class='line'>     -v /var/lib/ceph/:/var/lib/ceph/ \
</span><span class='line'>     -e MON_IP=192.168.33.13 \
</span><span class='line'>     -e CEPH_PUBLIC_NETWORK=192.168.33.0/24 \
</span><span class='line'>     ceph/daemon mon</span></code></pre></td></tr></table></div></figure>


<p>在node1上查看集群状态：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cluster 0de1fc5a-084d-4396-bb0b-59db72a9a439
</span><span class='line'> health HEALTH_ERR
</span><span class='line'>        64 pgs stuck inactive
</span><span class='line'>        64 pgs stuck unclean
</span><span class='line'>        no osds
</span><span class='line'> monmap e3: 3 mons at {node1.docker.com=192.168.33.11:6789/0,node2.docker.com=192.168.33.12:6789/0,node3.docker.com=192.168.33.13:6789/0}
</span><span class='line'>        election epoch 6, quorum 0,1,2 node1.docker.com,node2.docker.com,node3.docker.com
</span><span class='line'> osdmap e1: 0 osds: 0 up, 0 in
</span><span class='line'>        flags sortbitwise
</span><span class='line'>  pgmap v2: 64 pgs, 1 pools, 0 bytes data, 0 objects
</span><span class='line'>        0 kB used, 0 kB / 0 kB avail
</span><span class='line'>              64 creating</span></code></pre></td></tr></table></div></figure>


<h3>启动OSD的遇到的问题</h3>

<p>按照原视频的介绍的方法，启动OSD可以直接指定某个分区，然后用osd_ceph_disk作为启动ceph/daemon的参数，之后docker镜像会自动的进行分区等动作。但是经过实际验证却发现在mkjournal创建错误，OSD无法启动。</p>

<p>经过和社区确认，发现这个Bug在之前版本中得到过修复，但是之后的版本又出现了。根据社区的建议使用jewel版本的ceph daemon进行了再次验证，发现问题依旧，所以这里介绍的方法只能退而求其次，采用手动方式分区、格式化，之后用osd_directory启动ceph/daemon。</p>

<p>这是github上的相关讨论：<a href="https://github.com/ceph/ceph-docker/issues/171">https://github.com/ceph/ceph-docker/issues/171</a></p>

<p>这是用osd_ceph_disk方式启动后的错误日志：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>command_check_call: Running command: /usr/bin/ceph-osd --cluster ceph --mkfs --mkkey -i 4 --monmap /var/lib/ceph/tmp/mnt.BT8FXG/activate.monmap --osd-data /var/lib/ceph/tmp/mnt.BT8FXG --osd-journal /var/lib/ceph/tmp/mnt.BT8FXG/journal --osd-uuid 89e240e1-17e9-4d6c-8d4f-f1a3e0278b91 --keyring /var/lib/ceph/tmp/mnt.BT8FXG/keyring --setuser ceph --setgroup disk
</span><span class='line'>2016-06-12 23:37:26.180610 7f8889654800 -1 filestore(/var/lib/ceph/tmp/mnt.BT8FXG) mkjournal error creating journal on /var/lib/ceph/tmp/mnt.BT8FXG/journal: (2) No such file or directory
</span><span class='line'>2016-06-12 23:37:26.180752 7f8889654800 -1 OSD::mkfs: ObjectStore::mkfs failed with error -2
</span><span class='line'>2016-06-12 23:37:26.180918 7f8889654800 -1 ** ERROR: error creating empty object store in /var/lib/ceph/tmp/mnt.BT8FXG: (2) No such file or directory
</span><span class='line'>mount_activate: Failed to activate
</span><span class='line'>unmount: Unmounting /var/lib/ceph/tmp/mnt.BT8FXG
</span><span class='line'>command_check_call: Running command: /bin/umount -- /var/lib/ceph/tmp/mnt.BT8FXG</span></code></pre></td></tr></table></div></figure>


<h3>启动OSD</h3>

<p>第一步先进行分区和格式化，这里只给出node1的操作方式，其他两个节点的方式类似。</p>

<p>先来安装必要的工具：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>yum install -y parted xfsprogs</span></code></pre></td></tr></table></div></figure>




<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@node1 vagrant]# parted /dev/sdb
</span><span class='line'>GNU Parted 2.1
</span><span class='line'>Using /dev/sdb
</span><span class='line'>(parted) mklabel
</span><span class='line'>New disk label type? gpt
</span><span class='line'>(parted) p
</span><span class='line'>Model: ATA VBOX HARDDISK (scsi)
</span><span class='line'>Disk /dev/sdb: 107GB
</span><span class='line'>Sector size (logical/physical): 512B/512B
</span><span class='line'>Partition Table: gpt
</span><span class='line'>
</span><span class='line'>Number  Start  End  Size  File system  Name  Flags
</span><span class='line'>
</span><span class='line'>(parted) mkpart
</span><span class='line'>Partition name?  []? "Linux filesystem"
</span><span class='line'>File system type?  [ext2]? xfs
</span><span class='line'>Start? 0G
</span><span class='line'>End? 107GB
</span><span class='line'>(parted) p
</span><span class='line'>Model: ATA VBOX HARDDISK (scsi)
</span><span class='line'>Disk /dev/sdb: 107GB
</span><span class='line'>Sector size (logical/physical): 512B/512B
</span><span class='line'>Partition Table: gpt
</span><span class='line'>
</span><span class='line'>Number  Start   End    Size   File system  Name              Flags
</span><span class='line'> 1      1049kB  107GB  107GB               Linux filesystem
</span><span class='line'>
</span><span class='line'>(parted) quit</span></code></pre></td></tr></table></div></figure>


<p>格式化：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@node1 vagrant]# mkfs.xfs /dev/sdb1
</span><span class='line'>meta-data=/dev/sdb1              isize=256    agcount=4, agsize=6553472 blks
</span><span class='line'>         =                       sectsz=512   attr=2, projid32bit=1
</span><span class='line'>         =                       crc=0        finobt=0
</span><span class='line'>data     =                       bsize=4096   blocks=26213888, imaxpct=25
</span><span class='line'>         =                       sunit=0      swidth=0 blks
</span><span class='line'>naming   =version 2              bsize=4096   ascii-ci=0 ftype=0
</span><span class='line'>log      =internal log           bsize=4096   blocks=12799, version=2
</span><span class='line'>         =                       sectsz=512   sunit=0 blks, lazy-count=1
</span><span class='line'>realtime =none                   extsz=4096   blocks=0, rtextents=0</span></code></pre></td></tr></table></div></figure>


<p>我们把目录在node1上进行挂载。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>mkdir -p /ceph/sdb
</span><span class='line'>mount /dev/sdb1 /ceph/sdb</span></code></pre></td></tr></table></div></figure>


<p>最后启动OSD，这里最重要的就是把我们刚刚挂载好的OSD的实际路径透传给Docker内部的/var/lib/ceph/osd，如果每个节点有多个OSD的情况下，只需要在Host上映射到不同的目录，启动Docker的时候变更和/var/lib/ceph/osd的映射关系即可。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo docker run -d \
</span><span class='line'>    --net=host \
</span><span class='line'>    -v /etc/ceph:/etc/ceph \
</span><span class='line'>    -v /var/lib/ceph/:/var/lib/ceph/ \
</span><span class='line'>    -v /dev/:/dev/ \
</span><span class='line'>    -v /ceph/sdb:/var/lib/ceph/osd \
</span><span class='line'>    --privileged=true \
</span><span class='line'>    ceph/daemon osd_directory</span></code></pre></td></tr></table></div></figure>


<p>按照同样的方法，将node2和node3的OSD也加入到集群，最终的效果如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cluster 0de1fc5a-084d-4396-bb0b-59db72a9a439
</span><span class='line'> health HEALTH_WARN
</span><span class='line'>        clock skew detected on mon.node2.docker.com
</span><span class='line'>        64 pgs degraded
</span><span class='line'>        64 pgs stuck unclean
</span><span class='line'>        64 pgs undersized
</span><span class='line'>        Monitor clock skew detected
</span><span class='line'> monmap e3: 3 mons at {node1.docker.com=192.168.33.11:6789/0,node2.docker.com=192.168.33.12:6789/0,node3.docker.com=192.168.33.13:6789/0}
</span><span class='line'>        election epoch 6, quorum 0,1,2 node1.docker.com,node2.docker.com,node3.docker.com
</span><span class='line'> osdmap e13: 3 osds: 3 up, 3 in
</span><span class='line'>        flags sortbitwise
</span><span class='line'>  pgmap v18: 64 pgs, 1 pools, 0 bytes data, 0 objects
</span><span class='line'>        4551 MB used, 11306 MB / 16720 MB avail
</span><span class='line'>              64 active+undersized+degraded</span></code></pre></td></tr></table></div></figure>


<h3>创建MDS</h3>

<p>创建好基本的环境，其他的就容易了很多，下面来启动MDS。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo docker run -d \
</span><span class='line'>    --net=host \
</span><span class='line'>    -v /etc/ceph:/etc/ceph \
</span><span class='line'>    -v /var/lib/ceph/:/var/lib/ceph/ \
</span><span class='line'>    -e CEPHFS_CREATE=1 \
</span><span class='line'>    ceph/daemon mds</span></code></pre></td></tr></table></div></figure>


<h3>启动RGW，并且映射80端口</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo docker run -d \
</span><span class='line'>    -p 80:80 \
</span><span class='line'>    -v /etc/ceph:/etc/ceph \
</span><span class='line'>    -v /var/lib/ceph/:/var/lib/ceph/ \
</span><span class='line'>    ceph/daemon rgw</span></code></pre></td></tr></table></div></figure>


<h3>最终的集群状态</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cluster 0de1fc5a-084d-4396-bb0b-59db72a9a439
</span><span class='line'> health HEALTH_WARN
</span><span class='line'>        clock skew detected on mon.node2.docker.com
</span><span class='line'>        48 pgs stuck inactive
</span><span class='line'>        48 pgs stuck unclean
</span><span class='line'>        Monitor clock skew detected
</span><span class='line'> monmap e3: 3 mons at {node1.docker.com=192.168.33.11:6789/0,node2.docker.com=192.168.33.12:6789/0,node3.docker.com=192.168.33.13:6789/0}
</span><span class='line'>        election epoch 6, quorum 0,1,2 node1.docker.com,node2.docker.com,node3.docker.com
</span><span class='line'> mdsmap e5: 1/1/1 up {0=mds-node1.docker.com=up:active}
</span><span class='line'> osdmap e25: 3 osds: 3 up, 3 in
</span><span class='line'>        flags sortbitwise
</span><span class='line'>  pgmap v38: 128 pgs, 9 pools, 588 bytes data, 11 objects
</span><span class='line'>        6791 MB used, 16996 MB / 25081 MB avail
</span><span class='line'>              80 active+clean
</span><span class='line'>              45 creating
</span><span class='line'>               3 creating+activating</span></code></pre></td></tr></table></div></figure>


<h2>总结</h2>

<p>在Docker中部署Ceph并没有想象中的那么顺利，社区的版本中仍然有Bug需要解决。</p>

<p>Docker作为一种快捷的部署方式，的确可以大幅度提高Ceph的部署效率，提高扩展的速度。但是从另一个角度我们应该注意到，随着Docker的引入也改变了Ceph的运维方式，比如在OSD增减的时候，需要到容器中对Ceph集群进行维护。再比如配置文件变更后的重启问题等。</p>

<p>但是无论如何，我相信这些问题都会得到完美的解决，用Docker部署Ceph作为一种新的尝试，值得推广。
之后还会为大家带来，如何使用Ansible结合Docker更快速的部署Ceph集群，敬请期待。</p>
</div>


      <footer>
        <p class="meta text-muted">
          
  

<span class="glyphicon glyphicon-user"></span> <span class="byline author vcard" itemprop="author" itemscope itemtype="http://schema.org/Person">Posted by <span class="fn" itemprop="name">Ray Sun <xiaoquqi@gmail.com></span></span>

          












<span class="glyphicon glyphicon-calendar"></span> <time datetime="2016-06-13T15:20:50+08:00"  data-updated="true" itemprop="datePublished dateCreated">2016-06-13 15:20</time>
          

<span class="glyphicon glyphicon-tags"></span>&nbsp;
<span class="categories">
  
    <a class='category' href='/blog/categories/ceph/'>ceph</a>, <a class='category' href='/blog/categories/docker/'>docker</a>
  
</span>


        </p>
        
          <div class="sharing">
  
  
  
</div>

        
        
          <ul class="meta text-muted pager">
            
            <li class="previous"><a href="/blog/2016/04/07/contribution-in-mitaka/" title="Previous Post: 深度解读OpenStack Mitaka国内代码贡献">&laquo; 深度解读OpenStack Mitaka国内代码贡献</a></li>
            
            
          </ul>
        
      </footer>
    </article>
    
    
      <section>
        <h2>Comments</h2>
        <div id="comments" aria-live="polite"><!-- Duoshuo Comment BEGIN -->
<div class="ds-thread" data-title="使用Docker部署Ceph"></div>
<script type="text/javascript">
  var duoshuoQuery = {short_name:"xiaoquqi"};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = 'http://static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
    || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
</script>
<!-- Duoshuo Comment END -->
</div>
      </section>
    
  </div>

  
  <aside class="sidebar col-md-3">
    
      <section class="panel panel-default">
  <div class="panel-heading">
    <h3 class="panel-title">Recent Posts</h3>
  </div>
  
  <div id="recent_posts" class="list-group">
    
    <a class="list-group-item active" href="/blog/2016/06/13/bootstrap-your-ceph-cluster-in-docker/">使用Docker部署Ceph</a>
    
    <a class="list-group-item " href="/blog/2016/04/07/contribution-in-mitaka/">深度解读OpenStack Mitaka国内代码贡献</a>
    
    <a class="list-group-item " href="/blog/2016/03/27/openstack-training-user-experience/">OpenStack培训的用户体验</a>
    
    <a class="list-group-item " href="/blog/2015/12/24/use-consul/">Consul主要使用场景</a>
    
    <a class="list-group-item " href="/blog/2015/12/07/consul-installation/">Consul的安装方法</a>
    
  </div>
</section>

<section class="panel panel-default clearfix">
  <div class="panel-heading">
      <h3 class="panel-title">GitHub Repos</h3>
  </div>
  <div class="list-group" id="gh_repos">
    <p class="loading">Status updating&#8230;</p>
  </div>
  
    <div class="gh-profile-link pull-right text-muted">
      <a href="https://github.com/xiaoquqi">@xiaoquqi</a> on GitHub
    </div>
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'xiaoquqi',
            count: 0,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>






    
  </aside>
  
</div>

        </div>
      </div>
    </div>
    <footer role="contentinfo"><div class="container">
    <p class="text-muted credits">
  Copyright &copy; 2016 - Ray Sun <xiaoquqi@gmail.com><br>
  <small>
      <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>,
      <span class="credit">customized with <a href="https://github.com/kAworu/octostrap3">octostrap3</a></span>.
  </small>
</p>

</div>
</footer>
    








<script src="/assets/bootstrap/dist/js/bootstrap.min.js"></script>
<script src="/javascripts/modernizr.js"></script>


  </body>
</html>
