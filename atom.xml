<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[RaySun's Blog]]></title>
  <link href="http://xiaoquqi.github.io/atom.xml" rel="self"/>
  <link href="http://xiaoquqi.github.io/"/>
  <updated>2016-04-11T16:20:34+08:00</updated>
  <id>http://xiaoquqi.github.io/</id>
  <author>
    <name><![CDATA[Ray Sun ]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[深度解读OpenStack Mitaka国内代码贡献]]></title>
    <link href="http://xiaoquqi.github.io/blog/2016/04/07/contribution-in-mitaka/"/>
    <updated>2016-04-07T23:19:39+08:00</updated>
    <id>http://xiaoquqi.github.io/blog/2016/04/07/contribution-in-mitaka</id>
    <content type="html"><![CDATA[<p>转眼间，OpenStack又迎来了新版本发布的日子，这是OpenStack第13个版本，也是Big Tent后的第二个版本，秉承“公开公正”的原则，OpenStack Release的项目达到了29个，比Liberty多出了8个。</p>

<p>去年的时候，对国内的OpenStack Liberty贡献进行了深度解读后引起了广泛的关注，在今年Mitaka版本发布之后，类似的解读已经遍布朋友圈，但是在看过后，发现并非国内贡献的全部统计，所以决定还是自己写一篇完整的深度解读系列文章，来帮助国内用户对国内OpenStack的现状有一个全面的了解和认识。</p>

<p>这几天一直在思考写这篇文章的目的和意义，我们搞分析也好，搞排名也罢，到底是为了什么？Mitaka版本更新后，各个公司也以排名作为企业宣传的最好的武器，我觉得这些都无可厚非。但是我觉得更重要的一点是在当前去IOEV的大形势下，我们应该告诉国内的企业用户，有一批热衷于追求Geek精神的年轻人在为中国未来的IT产业变革做着不懈的努力，他们用数字证明了国外公司能做到的我们国内公司也能做到，这个世界上不仅有IOEV，还有中国制造的OpenStack。</p>

<p>对于友商们已经分析的数据，这里不再赘述，本文主要通过stackalytics.com提供的API对国内社区贡献进行一次深度挖掘和整理。</p>

<p>OpenStack Liberty深度解读请见：<a href="http://xiaoquqi.github.io/blog/2015/10/29/contribution-in-liberty/">http://xiaoquqi.github.io/blog/2015/10/29/contribution-in-liberty/</a></p>

<!-- more -->


<h2>Release项目简介</h2>

<p>Openstack官方的Release的网站已经更新为：<a href="http://releases.openstack.org/">http://releases.openstack.org/</a></p>

<p>在Big Tent公布之后，OpenStack的项目被分为Core Projects和Big Tent Projects。</p>

<p><img class="center" src="http://xiaoquqi.github.io/images/blogs/contribution-in-mitaka-big-tent.jpg"></p>

<p>让我们来看一下在Mitaka版本中，多了哪些新项目。</p>

<ul>
<li>几个与Docker相关的项目被发布出来，magnum, senlin, solum</li>
<li>数据备份容灾的项目：freezer</li>
<li>计费的项目：cloudkitty</li>
<li>NFV相关的项目：tracker</li>
<li>监控相关的项目：monasca</li>
</ul>


<p>关于这些新项目的一些介绍，我将放在另外一篇博客里，敬请关注。</p>

<p><img class="center" src="http://xiaoquqi.github.io/images/blogs/contribution-in-mitaka-projects.png"></p>

<h2>社区贡献总体分析</h2>

<p>本次统计的方法仍然为commits的方式，统计范围为stackalystatics默认统计的全部项目。</p>

<p>从总体参与的公司数量来看，Mitaka版本略有下降，但是参与的人数多了100多人。</p>

<p><img class="center" src="http://xiaoquqi.github.io/images/blogs/contribution-in-mitaka-companies-contributors.png"></p>

<p>整个社区的公司贡献排名上没有明显的变化，传统的几大豪强仍然霸占公司排名的前十位，华为表现依然强劲，是中国区唯一能进入前十名的公司。</p>

<p>在模块方面，整体统计的绝大部分比例已经被others所占据，说明在Big Tent计划下，OpenStack正在朝更多元化的方向演进。在Mitaka排名前十位的项目中，fuel相关的两个项目都进入了前十，说明fuel在OpenStack部署的地位已经越来越重要了。同时，核心项目中的nova，neutron，cinder项目仍然在前十名的范围内，贡献量基本保持不变。值得一提的是，在Mitaka统计的项目数量已经从Liberty的708个增长到了829个，可见在短短的6个月内，OpenStack社区的蓬勃发展。</p>

<p><img class="center" src="http://xiaoquqi.github.io/images/blogs/contribution-in-mitaka-companies-modules.png"></p>

<h2>OpenStack国内社区分析</h2>

<p>看完了整体统计，我们再回到国内，因为已经有文章做了我在Liberty时候的分析，所以这里我换个角度来看国内的社区贡献，首先是统计排名的变化。</p>

<h3>贡献企业</h3>

<p>在Liberty中，有13家国内企业为社区做了贡献，在Mitaka中这个数量增加到了15家企业，这里简单的将这些企业做了一下分类：</p>

<ul>
<li>互联网用户：乐视、新浪、网易</li>
<li>电信用户：中国移动</li>
<li>传统IT服务商：华为、中兴、华三</li>
<li>私有云服务商：Easystack、九州云、海云捷迅、北京有云、麒麟云、UMCloud、象云、Huron(休伦科技)</li>
</ul>


<p><img class="center" src="http://xiaoquqi.github.io/images/blogs/contribution-in-mitaka-china-companies.png"></p>

<h3>行业分析</h3>

<p>通过行业的分析我们可以看出，国内的主要贡献仍然来自私有云服务商和传统IT服务商，换言之来自于以OpenStack提供产品或者服务的公司。厂商们贡献的目的很明确，主要为了展示自身在开源项目中的积累和专家形象。而用户的贡献主要来自平时在使用OpenStack时候遇到Bug，就是在实际应用过程中出现的问题。</p>

<p><img class="center" src="http://xiaoquqi.github.io/images/blogs/contribution-in-mitaka-china-by-industry.png"></p>

<h3>人员投入分析</h3>

<p>单纯的社区贡献排名的比较仅仅是一个维度，下面我们来看一下各个公司的人员投入情况：</p>

<ul>
<li>排名前几位的公司对社区投入的人力基本都是两位数，相对于Liberty版本，人员均有所增加</li>
<li>在人均贡献投入上，99cloud是国内最高的，平均达到了59天，甚至超过了华为，这个统计不仅仅包含了代码贡献，还包含了邮件、Review、Blueprint的时间，基本可以衡量每个公司在OpenStack社区贡献方面的投入力量</li>
<li>人员投入来看，Easystack和中国移动无疑是最下本的两家，Easystack从Liberty的3人，增长到了23人，一下子增加了20人；中国移动也从最初的4个人，增加到了13个人，可见中国移动未来对OpenStack的野心</li>
</ul>


<p><img class="center" src="http://xiaoquqi.github.io/images/blogs/contribution-in-mitaka-companies-effort.png"></p>

<h3>贡献模块分析</h3>

<p>从模块的角度进行统计，国内企业的贡献情况并未出现一个统一的趋势，总体的贡献项目为193个，项目几乎涉及OpenStack所有最活跃的项目，从排名前十的项目来看：</p>

<ul>
<li>得益于华为的主导，dargonflow项目的贡献量超高</li>
<li>紧随其后的，也是当下的热点，容器相关的两个项目</li>
<li>几大OpenStack老模块贡献量也高居前十位，说明这些模块是在解决方案中使用频率较高的</li>
</ul>


<p><img class="center" src="http://xiaoquqi.github.io/images/blogs/contribution-in-mitaka-modules.png"></p>

<h3>投入产出比</h3>

<p>这是一个很敏感的话题，每个公司对社区的投入到底换来多少项目上的回报呢？可能这只有每个公司的CEO能够回答的问题了。我在这里就不多做过多的分析，留给大家充分讨论的空间吧。</p>

<h2>总结</h2>

<p>刚刚结束在南京的OpenStack开发培训，也了解到5G的通信网络上已经确定引入了OpenStack，虽然我说不清楚他的具体用途，但是我相信这对OpenStack这个项目、社区是一个重大的利好消息。我也相信，通过国内企业的集体努力，一定能让OpenStack在中国遍地开花结果。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[OpenStack培训的用户体验]]></title>
    <link href="http://xiaoquqi.github.io/blog/2016/03/27/openstack-training-user-experience/"/>
    <updated>2016-03-27T18:42:38+08:00</updated>
    <id>http://xiaoquqi.github.io/blog/2016/03/27/openstack-training-user-experience</id>
    <content type="html"><![CDATA[<p>尽管在云计算领域仍然有很大的争议，但是OpenStack事实上已经成为Iaas云平台的事实标准和首选的平台。从培训市场的火热也证明了这一点，现在的OpenStack培训有很多，讲的内容也不尽相同，那么哪一种培训才是用户最需要的呢？</p>

<p>这篇文章并不是要评价任何一个OpenStack培训，只是想从用户体验的角度分析一下，到底什么才是用户真正需要的。如果文章观点有任何不妥，还请各位前辈和大牛们多多海涵。</p>

<!-- more -->


<h2>关于我</h2>

<p>简单来说，我带过OpenStack产品的研发团队，谈过OpenStack的合作，做过OpenStack培训讲师，也卖过OpenStack的私有云产品，也和大量的用户聊过OpenStack，所以还算是对OpenStack这个行业整体上有个清晰认识。</p>

<h2>OpenStack培训的目标群体</h2>

<p>我做过的OpenStack培训大体上分为两类，内训和外训。</p>

<p>内训是面向公司内部，因为我曾经带过的两个团队都是以开发OpenStack私有云产品为主的，所以我的培训对象主要是研发、运维、售前和销售人员。</p>

<p>外训的对象很多，包括知名的国企、外企和民营企业以及学校，行业大部分以传统行业为主，涉及通讯、金融、系统集成等，面向的群体主要是研发、IT和售前，培训的内容以OpenStack的基础和研发为主。</p>

<p>所以我把OpenStack培训的目标群体定义为：研发人员、系统工程师和运维人员、售前、销售人员、学生。</p>

<h2>针对不同的群体，到底需要哪些培训？</h2>

<h3>销售人员</h3>

<p>现在做OpenStack生意的无外乎两种：产品和服务。无论是哪一种，对传统的销售人员都是一种极大的挑战。云平台并不像传统软件一样，能够一眼看明白他到底是做什么的，解决了用户的哪些痛点。并且在企业中，能够做决策的人往往并不全是技术出身，所以想和他们解释清楚OpenStack到底能做什么，又是难上艰难。</p>

<p>所以对于销售人员来讲，培训的重点应该有以下几点：</p>

<ul>
<li>使用培训：我觉得无论为哪一类群体培训，演示如何使用OpenStack，都是最有效的帮助人理解的方式。但是这里的演示，必须要设定场景，即传统的业务形态下我们的业务系统是什么样子的，迁移到云平台后该如何部署，从这种比较中，加深对OpenStack的理解。销售人员通过对OpenStack操作，加深对OpenStack或OpenStack产品的理解。毕竟图形是最高效的一种记忆方式。</li>
<li>理解什么是开源软件：开源软件一定是未来的发展趋势，如果无法对开源软件有一个清晰的认识，也就无法理解清楚OpenStack这个项目出现的价值和意义。</li>
<li>了解OpenStack的发展历史、OpenStack基金会以及OpenStack社区的运营方式：学习这些的目的是为了给用户讲故事，让用户了解为什么要选择OpenStack，为什么OpenStack项目有持续的生命力，让用户相信使用了OpenStack能够保证未来的基础架构灵活面对业务层面敏捷性的需求。</li>
<li>案例学习：案例最大的价值就是教育用户，VMWare花了十几年的时间教育了用户，OpenStack不可能在短短的几年时间内就改变这样的局面，所以“学会用别人的案例来教育自己的用户”，是在销售人员OpenStack培训中非常重要的一课。</li>
</ul>


<h3>售前人员</h3>

<p>售前人员不但要从技术层面让用户信服产品，而且还要结合用户的业务系统需求提供建设方案，外企中的很多售前工程师还要承担搭建POC环境的职责。售前人员沟通的主要对象是企业中有实际需求的业务部门，也是最有可能落地的部门，沟通的成败决定了是否能签单，所以需要更多的专业知识来满足和用户的沟通需要。 培训的重点应该是：</p>

<ul>
<li>使用培训：理由同上，但是我觉得售前人员还需要站在用户的角度来思考一下，我的用户到底会如何使用云平台？业务系统迁移到平台后，会有哪些问题？</li>
<li>如何部署：部署培训向来是各大OpenStack培训必讲的内容，而且90%的内容都是围绕部署展开的，例如某知名企业的OpenStack授证培训。对于售前人员，我认为OpenStack部署训练还是很有必要的。一方面，能够帮助培训对象快速理解OpenStack的架构；另一方面，也能在未来的方案设计上提供参考和依据。由于云平台在使用上与企业传统的IT环境有较大的区别，所以售前人员在学习过程中，应该更多的了解OpenStack部署的特点，服务和服务之间的关系，云平台高可靠等和生产环境部署息息相关的问题。另外还要关注，用户的业务系统迁移到云平台后，可能带来的变化以及应对方式。例如：OpenStack里的网络分为fixed ip和floating ip，但是用户原有的业务系统只会有一个IP，这时候就需要考虑如何为用户选择适当的部署方案。</li>
<li>OpenStack架构：掌握OpenStack模块的基本工作原理和模块的详细作用。学习这些内容，是为了帮助售前人员在和用户后续交流中，帮助用户选择适当的模块解决用户的需求。</li>
<li>OpenStack的发展趋势：这部分内容就是能够引导客户未来的项目需求。例如在分布式存储，NFV和SDN方面。</li>
</ul>


<h3>系统工程师和运维人员</h3>

<p>Iaas云平台不但是对传统的企业IT架构进行了变革，也从管理上对企业原有的流程形成了冲击。需要培训的用户往往集中在自用OpenStack云平台的企业。</p>

<ul>
<li>使用培训，不同于上面两种简单的使用，运维人员要求对OpenStack管理部分的使用也要有很深的理解，而且还需要掌握命令行方式的相关操作。</li>
<li>OpenStack架构，了解OpenStack内部的工作原理，有助于快速定位问题，对系统进行维护。这部分包含的内容比较多，从OpenStack自身的原理到虚拟机，存储，再到虚拟网络的实现都需要有一个系统的了解才可以。</li>
<li>部署培训，要求详细掌握安装的过程，了解全部配置文件的功能及常用选项和参数。</li>
<li>自动化部署培训，手动部署即耗费时间又不能保证准确，所以作为运维人员，必须要掌握至少一种自动化部署的方法。这方面的方案有很多，从TripleO、Fuel到Puppet，Salt，Ansible。个人还是推崇应该选择Salt或者Ansible的一种进行学习和掌握。</li>
<li>运维培训，要求就是在云平台出现问题之后快速定位问题。</li>
<li>自动化运维培训，DevOps作为未来运维的趋势，反复被提到。云平台自动化运维的内容很多，部署、监控、告警、自动巡检、健康检查等等，使用的工具无外乎上面提到的Salt或者Ansible这样的工具。自动化运维不仅仅是云平台未来培训的一大趋势，也是企业有需求的培训内容。</li>
</ul>


<h3>开发人员</h3>

<p>开发人员对OpenStack培训的需求主要和未来的工作有关（除了是公司强制或者兴趣之外），从我的经验来看：一种是基于OpenStack API开发，一种是开发OpenStack。所以针对两种不同的需求，培训内容需要单独进行设计，总体来说后一种包含前一种培训。</p>

<p>与之前几种培训不同，我认为部署培训对开发人员并不是必须的，因为在实际工作中，开发人员很难有机会真正接触到安装过程，这部分工作往往由公司的IT人员去完成，并且其中涉及到大量的Linux基础命令，很多研发人员其实对这部分并不是十分熟悉，所以即使学习了安装内容，也还是一知半解。与其在安装上浪费时间，不如多了解一些架构方面的细节。</p>

<ul>
<li>使用培训，帮助开发人员快速了解OpenStack。</li>
<li>了解社区的开发流程，OpenStack之所以发展到今天的程度，和社区的代码的管理流程密不可分，所以这部分是值得每一名开发人员学习的。</li>
<li>搭建研发环境，既然要开发OpenStack就应该按照开发的方式搭建研发环境，这样屏蔽了很多安装上的细节，并且让开发人员有个快速能使用和开发的环境。</li>
<li>基于OpenStack API开发，这部分应该是个重点，我通常会设定一个具体的用户需求，通过解决用户需求来了解API的使用。例如：作为一名用户，我想给我的虚拟机挂卷并自动分区，挂载到/mnt目录。这里的内容包含API文档的使用，通过浏览器REST Client插件详细了解OpenStack API的调用过程，学习使用OpenStack SDK。</li>
<li>OpenStack编排服务，将API开发中的场景，用编排服务加以实现，还可以包含Scaling和Auto Scaling的场景。这部分很可能是开发人员在未来开发中非常需要的一部分内容。</li>
<li>OpenStack发展方向，OpenStack的大帐篷展现了对未来的野心，所以了解OpenStack未来的发展方向是很有必要的。</li>
</ul>


<p>针对于以后开发OpenStack的研发人员，还需要根据实际的开发内容增加以下的培训内容：</p>

<ul>
<li>OpenStack通用技术，学习OpenStack的通用技术有助于理解OpenStack的所有模块，这部分内容主要包括：Eventlet，REST和WSGI，Taskflow，OSLO项目等诸多重要的类库。</li>
<li>典型模块的架构及开发入门，这里面推荐的模块包含：Nova/Neutron/Horizon/Ceilometer，这几种模块几乎涵盖了OpenStack大部分模块的架构，所以重点理解这些模块的架构和工作原理，对于理解整个OpenStack项目都非常有帮助。直接将代码其实真的很困难，我习惯于使用场景的方式追踪代码的运行轨迹，从而整理出时序图的方式讲解。</li>
</ul>


<h3>学生</h3>

<p>学生群体事实上是相当有潜力的市场，现在国内OpenStack人才紧缺，所以OpenStack一定要从大学抓起。学生对OpenStack的学习不能仅仅停留在OpenStack本身，与之相关的内容都要学习，但是又不建议完全理论化的学习，强调动手的能力是关键。例如：对Python的学习，虚拟化软件的学习，OpenStack的安装，OpenStack的开发进行循序渐进的学习。</p>

<h2>总结</h2>

<p>我认为培训中很重要的一环就是让学员动手，否则培训的效果不会很好。以上就是我对OpenStack培训的粗浅认识，还请各位多多指教。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Consul主要使用场景]]></title>
    <link href="http://xiaoquqi.github.io/blog/2015/12/24/use-consul/"/>
    <updated>2015-12-24T18:07:24+08:00</updated>
    <id>http://xiaoquqi.github.io/blog/2015/12/24/use-consul</id>
    <content type="html"><![CDATA[<p>假设你已经按照之前的Consul安装方法部署了一套具备环境，具体方法可以参考：<a href="http://xiaoquqi.github.io/blog/2015/12/07/consul-installation/">http://xiaoquqi.github.io/blog/2015/12/07/consul-installation/</a></p>

<p>这篇文章里主要介绍Consul的使用场景，服务和健康检查。</p>

<!-- more -->


<h2>Service</h2>

<p>服务注册有点像OpenStack Keystone的Endpoints，可以通过API方式查询到所有服务的端点信息。</p>

<p>在Agent的节点上添加一个service，之后重启服务。</p>

<ul>
<li>添加一个服务</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ echo '{"service": {"name": "web", "tags": ["rails"], "port": 80}}' \
</span><span class='line'>    &gt;/etc/consul.d/web.json</span></code></pre></td></tr></table></div></figure>


<ul>
<li>重启agent</li>
</ul>


<p>重新加载新的服务并不需要杀死进程重启服务，只需要给进程直接发送一个SIGHUP。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ kill -HUP $(ps -ef | grep agent | grep -v grep | awk '{print $2}')</span></code></pre></td></tr></table></div></figure>


<ul>
<li>日志输出</li>
</ul>


<p>从输出的日志上都可以看到加载了新的服务web。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>==&gt; Caught signal: hangup
</span><span class='line'>==&gt; Reloading configuration...
</span><span class='line'>==&gt; WARNING: Expect Mode enabled, expecting 3 servers
</span><span class='line'>    2015/12/24 12:01:11 [INFO] agent: Synced service 'web'</span></code></pre></td></tr></table></div></figure>


<ul>
<li>利用API查询</li>
</ul>


<p>我们在任意节点上利用REST API查看服务。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ curl http://localhost:8500/v1/catalog/service/web</span></code></pre></td></tr></table></div></figure>




<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[{"Node":"server1.consul.com","Address":"200.21.1.101","ServiceID":"web","ServiceName":"web","ServiceTags":["rails"],"ServiceAddress":"","ServicePort":80}]</span></code></pre></td></tr></table></div></figure>


<h2>Health Check</h2>

<p>健康检查的方法主要是通过运行一小段脚本的方式，根据运行的结果判断检查对象的健康状况。所以可以通过任意语言定义这个脚本，脚本运行将通过和consul执行的相同用户执行。</p>

<ul>
<li>添加一个健康检查</li>
</ul>


<p>每30秒ping google.com</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ echo '{"check": {"name": "ping",
</span><span class='line'>  "script": "ping -c1 google.com &gt;/dev/null", "interval": "30s"}}' \
</span><span class='line'>    &gt; /etc/consul.d/ping.json</span></code></pre></td></tr></table></div></figure>


<p>为刚才的服务添加健康检查</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ echo '{"service": {"name": "web", "tags": ["rails"], "port": 80,
</span><span class='line'>  "check": {"script": "curl localhost &gt;/dev/null 2&gt;&1", "interval": "10s"}}}' \
</span><span class='line'>    &gt; /etc/consul.d/web.json</span></code></pre></td></tr></table></div></figure>


<ul>
<li>重启agent</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ kill -HUP $(ps -ef | grep agent | grep -v grep | awk '{print $2}')</span></code></pre></td></tr></table></div></figure>


<ul>
<li>日志输出</li>
</ul>


<p>从输出的日志上都可以看到加载了新的服务web。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>==&gt; Caught signal: hangup
</span><span class='line'>==&gt; Reloading configuration...
</span><span class='line'>==&gt; WARNING: Expect Mode enabled, expecting 3 servers
</span><span class='line'>    2015/12/24 12:43:56 [INFO] agent: Synced service 'web'
</span><span class='line'>    2015/12/24 12:43:56 [INFO] agent: Synced check 'ping'</span></code></pre></td></tr></table></div></figure>


<p>经过一段时间后出现了critical和warning日志</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>2015/12/24 12:43:58 [WARN] agent: Check 'service:web' is now critical
</span><span class='line'>2015/12/24 12:44:08 [WARN] agent: Check 'ping' is now warning</span></code></pre></td></tr></table></div></figure>


<ul>
<li>利用API查询</li>
</ul>


<p>Health check的状态包含了很多种，有any, unkown, passing, warning, critical。any包含了所有状态。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ curl http://localhost:8500/v1/health/state/critical</span></code></pre></td></tr></table></div></figure>




<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[{"Node":"server1.consul.com","CheckID":"service:web","Name":"Service 'web' check","Status":"critical","Notes":"","Output":"","ServiceID":"web","ServiceName":"web"}]</span></code></pre></td></tr></table></div></figure>


<h2>参考文档</h2>

<ul>
<li><a href="http://www.consul.io/docs/agent/http/catalog.html">http://www.consul.io/docs/agent/http/catalog.html</a></li>
<li><a href="http://www.consul.io/docs/agent/http/health.html">http://www.consul.io/docs/agent/http/health.html</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Consul的安装方法]]></title>
    <link href="http://xiaoquqi.github.io/blog/2015/12/07/consul-installation/"/>
    <updated>2015-12-07T10:00:13+08:00</updated>
    <id>http://xiaoquqi.github.io/blog/2015/12/07/consul-installation</id>
    <content type="html"><![CDATA[<h2>什么是Consul?</h2>

<p>Consul拥有众多的组件，简言之，就是一个用于在你的基础设施中，发现和配置服务的工具。包含以下关键功能：服务发现、健康检查、键值存储和多数据中心支持。再说的通俗一点，就是用于管理分布式系统的利器。</p>

<!-- more -->


<h2>安装Consul</h2>

<p>Consul的安装比较简单，下载之后直接解压缩就可以了，下载地址：<a href="https://www.consul.io/downloads.html">https://www.consul.io/downloads.html</a></p>

<p>我们把consul直接放在/usr/local/bin目录中。</p>

<h2>Consul Server</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ /usr/local/bin/consul agent -server -bootstrap-expect 3 -data-dir /tmp/consul -node=server1 -bind=10.10.10.10</span></code></pre></td></tr></table></div></figure>


<h3>参数说明</h3>

<ul>
<li>-server - Serve模式</li>
<li>-bootstrap-expect - Server数量</li>
<li>-data-dir - 数据目录</li>
<li>-node - Node名称</li>
<li>-bind - 集群通讯地址</li>
</ul>


<h3>输出</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>==&gt; WARNING: Expect Mode enabled, expecting 3 servers
</span><span class='line'>==&gt; WARNING: It is highly recommended to set GOMAXPROCS higher than 1
</span><span class='line'>==&gt; Starting Consul agent...
</span><span class='line'>==&gt; Starting Consul agent RPC...
</span><span class='line'>==&gt; Consul agent running!
</span><span class='line'>         Node name: 'server1.consul.com'
</span><span class='line'>        Datacenter: 'dc1'
</span><span class='line'>            Server: true (bootstrap: false)
</span><span class='line'>       Client Addr: 127.0.0.1 (HTTP: 8500, HTTPS: -1, DNS: 8600, RPC: 8400)
</span><span class='line'>      Cluster Addr: 200.21.1.101 (LAN: 8301, WAN: 8302)
</span><span class='line'>    Gossip encrypt: false, RPC-TLS: false, TLS-Incoming: false
</span><span class='line'>             Atlas: &lt;disabled&gt;
</span><span class='line'>
</span><span class='line'>==&gt; Log data will now stream in as it occurs:
</span><span class='line'>
</span><span class='line'>    2015/12/23 03:13:36 [WARN] memberlist: Binding to public address without encryption!
</span><span class='line'>    2015/12/23 03:13:36 [INFO] serf: EventMemberJoin: server1.consul.com 200.21.1.101
</span><span class='line'>    2015/12/23 03:13:36 [WARN] memberlist: Binding to public address without encryption!
</span><span class='line'>    2015/12/23 03:13:36 [INFO] serf: EventMemberJoin: server1.consul.com.dc1 200.21.1.101
</span><span class='line'>    2015/12/23 03:13:36 [INFO] raft: Node at 200.21.1.101:8300 [Follower] entering Follower state
</span><span class='line'>    2015/12/23 03:13:36 [INFO] consul: adding server server1.consul.com (Addr: 200.21.1.101:8300) (DC: dc1)
</span><span class='line'>    2015/12/23 03:13:36 [INFO] consul: adding server server1.consul.com.dc1 (Addr: 200.21.1.101:8300) (DC: dc1)
</span><span class='line'>    2015/12/23 03:13:36 [ERR] agent: failed to sync remote state: No cluster leader
</span><span class='line'>    2015/12/23 03:13:37 [WARN] raft: EnableSingleNode disabled, and no known peers. Aborting election.
</span><span class='line'>    2015/12/23 03:13:51 [ERR] agent: failed to sync remote state: No cluster leader
</span><span class='line'>==&gt; Newer Consul version available: 0.6.0
</span><span class='line'>    2015/12/23 03:14:17 [ERR] agent: failed to sync remote state: No cluster leader</span></code></pre></td></tr></table></div></figure>


<h3>查看成员</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ consul members</span></code></pre></td></tr></table></div></figure>




<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Node                Address            Status  Type    Build  Protocol  DC
</span><span class='line'>server1.consul.com  200.21.1.101:8301  alive   server  0.5.2  2         dc1</span></code></pre></td></tr></table></div></figure>


<h2>Consul Agent</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ /usr/local/bin/consul agent -data-dir /tmp/consul -node=agent1 -bind=10.10.10.100 -config-dir /etc/consul.d</span></code></pre></td></tr></table></div></figure>


<ul>
<li>输出</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>==&gt; WARNING: It is highly recommended to set GOMAXPROCS higher than 1
</span><span class='line'>==&gt; Starting Consul agent...
</span><span class='line'>==&gt; Starting Consul agent RPC...
</span><span class='line'>==&gt; Consul agent running!
</span><span class='line'>         Node name: 'agent1.consul.com'
</span><span class='line'>        Datacenter: 'dc1'
</span><span class='line'>            Server: false (bootstrap: false)
</span><span class='line'>       Client Addr: 127.0.0.1 (HTTP: 8500, HTTPS: -1, DNS: 8600, RPC: 8400)
</span><span class='line'>      Cluster Addr: 200.21.1.201 (LAN: 8301, WAN: 8302)
</span><span class='line'>    Gossip encrypt: false, RPC-TLS: false, TLS-Incoming: false
</span><span class='line'>             Atlas: &lt;disabled&gt;
</span><span class='line'>
</span><span class='line'>==&gt; Log data will now stream in as it occurs:
</span><span class='line'>
</span><span class='line'>    2015/12/24 08:09:51 [WARN] memberlist: Binding to public address without encryption!
</span><span class='line'>    2015/12/24 08:09:51 [INFO] serf: EventMemberJoin: agent1.consul.com 200.21.1.201
</span><span class='line'>    2015/12/24 08:09:51 [ERR] agent: failed to sync remote state: No known Consul servers
</span><span class='line'>    2015/12/24 08:09:56 [INFO] agent.rpc: Accepted client: 127.0.0.1:42794
</span><span class='line'>    2015/12/24 08:09:56 [INFO] agent: (LAN) joining: [200.21.1.101 200.21.1.102 200.21.1.103]
</span><span class='line'>    2015/12/24 08:09:56 [INFO] serf: EventMemberJoin: server1.consul.com 200.21.1.101
</span><span class='line'>    2015/12/24 08:09:56 [INFO] consul: adding server server1.consul.com (Addr: 200.21.1.101:8300) (DC: dc1)
</span><span class='line'>    2015/12/24 08:09:58 [ERR] agent: failed to sync remote state: rpc error: No cluster leader
</span><span class='line'>    2015/12/24 08:10:02 [INFO] agent: (LAN) joined: 1 Err: &lt;nil&gt;
</span><span class='line'>    2015/12/24 08:10:02 [INFO] agent.rpc: Accepted client: 127.0.0.1:42800
</span><span class='line'>==&gt; Newer Consul version available: 0.6.0
</span><span class='line'>    2015/12/24 08:10:21 [WARN] agent: Check 'ping' is now warning
</span><span class='line'>    2015/12/24 08:10:22 [ERR] agent: failed to sync remote state: rpc error: No cluster leader
</span><span class='line'>    2015/12/24 08:10:43 [ERR] agent: failed to sync remote state: rpc error: No cluster leader
</span><span class='line'>    2015/12/24 08:11:01 [WARN] agent: Check 'ping' is now warning
</span><span class='line'>    2015/12/24 08:11:02 [ERR] agent: failed to sync remote state: rpc error: No cluster leader
</span><span class='line'>    2015/12/24 08:11:23 [ERR] agent: failed to sync remote state: rpc error: No cluster leader
</span><span class='line'>    2015/12/24 08:11:41 [WARN] agent: Check 'ping' is now warning
</span><span class='line'>    2015/12/24 08:11:43 [ERR] agent: failed to sync remote state: rpc error: No cluster leader
</span><span class='line'>    2015/12/24 08:12:12 [ERR] agent: failed to sync remote state: rpc error: No cluster leader
</span><span class='line'>    2015/12/24 08:12:21 [WARN] agent: Check 'ping' is now warning
</span><span class='line'>    2015/12/24 08:12:36 [ERR] agent: failed to sync remote state: rpc error: No cluster leader
</span><span class='line'>    2015/12/24 08:13:01 [WARN] agent: Check 'ping' is now warning
</span><span class='line'>    2015/12/24 08:13:03 [ERR] agent: failed to sync remote state: rpc error: No cluster leader</span></code></pre></td></tr></table></div></figure>


<ul>
<li>server日志输出</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>2015/12/24 08:09:58 [INFO] serf: EventMemberJoin: agent1.consul.com 200.21.1.201</span></code></pre></td></tr></table></div></figure>


<h3>查看成员</h3>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ consul members</span></code></pre></td></tr></table></div></figure>




<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Node                Address            Status  Type    Build  Protocol  DC
</span><span class='line'>server1.consul.com  200.21.1.101:8301  alive   server  0.5.2  2         dc1
</span><span class='line'>agent1.consul.com   200.21.1.201:8301  alive   client  0.5.2  2         dc1</span></code></pre></td></tr></table></div></figure>


<h2>最终结果</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ consul members</span></code></pre></td></tr></table></div></figure>




<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Node                Address            Status  Type    Build  Protocol  DC
</span><span class='line'>server1.consul.com  200.21.1.101:8301  alive   server  0.5.2  2         dc1
</span><span class='line'>agent1.consul.com   200.21.1.201:8301  alive   client  0.5.2  2         dc1
</span><span class='line'>agent2.consul.com   200.21.1.202:8301  alive   client  0.5.2  2         dc1
</span><span class='line'>server2.consul.com  200.21.1.102:8301  alive   server  0.5.2  2         dc1
</span><span class='line'>server3.consul.com  200.21.1.103:8301  alive   server  0.5.2  2         dc1
</span><span class='line'>agent3.consul.com   200.21.1.203:8301  alive   client  0.5.2  2         dc1</span></code></pre></td></tr></table></div></figure>


<h2>参考文档</h2>

<ul>
<li><a href="https://www.consul.io/intro/getting-started/install.html">https://www.consul.io/intro/getting-started/install.html</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用Grafana+Diamond+Graphite构造完美监控面板]]></title>
    <link href="http://xiaoquqi.github.io/blog/2015/12/01/use-grafana-to-monitor-your-cluster/"/>
    <updated>2015-12-01T07:59:46+08:00</updated>
    <id>http://xiaoquqi.github.io/blog/2015/12/01/use-grafana-to-monitor-your-cluster</id>
    <content type="html"><![CDATA[<p>服务器监控软件五花八门，没有一个是对的，但是总有一款是适合你的，本文中将使用Grafana+Dimaond+Graphite构造一款漂亮的监控面板，你可以独自欣赏，也可以让他们和你的应用勾勾搭搭。</p>

<p>本文中的安装测试，主要在CentOS 6.5下完成。先来张Grafna效果图，左边是我们的数据源Graphite，右边是我们的Grafna的效果图：</p>

<p><img class="center" src="http://xiaoquqi.github.io/images/blogs/grafana-screenshot.png" width="800"></p>

<!-- more -->


<h2>安装及配置Dimaond</h2>

<p>安装Diamond最直接和简单的方法就是自己编译RPM或者DEB的安装包, Diamond在这方面提供了比较好的支持。</p>

<figure class='code'><figcaption><span>bash</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># cd /root</span>
</span><span class='line'><span class="c"># yum install -y git rpm-build python-configobj python-setuptools</span>
</span><span class='line'><span class="c"># git clone https://github.com/python-diamond/Diamond</span>
</span><span class='line'><span class="c"># cd Diamond</span>
</span><span class='line'><span class="c"># make rpm</span>
</span><span class='line'><span class="c"># cd dist</span>
</span><span class='line'><span class="c"># rpm -ivh diamond-*.noarch.rpm</span>
</span></code></pre></td></tr></table></div></figure>


<p>默认情况下，Diamond开启了基本的监控信息，包括CPU、内存、磁盘的性能数据。当然，我们可以通过配置启动相应的监控项，也能通过自定义的方式进行相应的扩展。这里，我们在/etc/diamond/collectors加载额外的插件，下面的例子中开启了网络的监控。</p>

<figure class='code'><figcaption><span>bash</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># cp -f /etc/diamond/diamond.conf.example /etc/diamond/diamond.conf</span>
</span><span class='line'>
</span><span class='line'><span class="c"># cat &lt;&lt; EOF | tee -a /etc/diamond/diamond.conf</span>
</span><span class='line'><span class="o">[</span>configs<span class="o">]</span>
</span><span class='line'><span class="nv">path</span> <span class="o">=</span> <span class="s2">&quot;/etc/diamond/collectors/&quot;</span>
</span><span class='line'><span class="nv">extension</span> <span class="o">=</span> <span class="s2">&quot;.conf&quot;</span>
</span><span class='line'>EOF
</span><span class='line'>
</span><span class='line'><span class="c"># cat &lt;&lt; EOF | tee /etc/diamond/collectors/net.conf</span>
</span><span class='line'><span class="o">[</span>collectors<span class="o">]</span>
</span><span class='line'>
</span><span class='line'><span class="o">[[</span>NetworkCollector<span class="o">]]</span>
</span><span class='line'><span class="nv">enabled</span> <span class="o">=</span> True
</span><span class='line'>EOF
</span></code></pre></td></tr></table></div></figure>


<p>那么到目前为止，Diamond的基本安装和配置已经完成，但是现在只是简单的采集数据，并没有指明数据要发送给谁，所以下一步我们来开始配置Graphite。</p>

<h2>安装及配置Graphite</h2>

<p>Graphite主要做两件事情：按照时间存储数据、生成图表，在我们的场景里面，实质上就是把Graphite作为数据源给Grafana提供数据。另外还需要安装的是carbon，负责通过网络接受数据并保存到后端存储中；另外还需要whisper，负责生成Graphite样式的基于文件的时间序列的数据库。</p>

<h3>安装软件包</h3>

<figure class='code'><figcaption><span>bash</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># yum install -y graphite-web graphite-web-selinux</span>
</span><span class='line'><span class="c"># yum install -y mysql mysql-server MySQL-python</span>
</span><span class='line'><span class="c"># yum install -y python-carbon python-whisper</span>
</span></code></pre></td></tr></table></div></figure>


<h3>配置MySQL</h3>

<figure class='code'><figcaption><span>bash</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># /etc/init.d/mysqld start</span>
</span><span class='line'>
</span><span class='line'><span class="c"># mysql -e &quot;CREATE DATABASE graphite;&quot; -u root</span>
</span><span class='line'><span class="c"># mysql -e &quot;GRANT ALL PRIVILEGES ON graphite.* TO &#39;graphite&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;sysadmin&#39;;&quot; -u root</span>
</span><span class='line'><span class="c"># mysql -e &#39;FLUSH PRIVILEGES;&#39; -u root</span>
</span></code></pre></td></tr></table></div></figure>


<h3>配置Graphite</h3>

<ul>
<li>local setting</li>
</ul>


<figure class='code'><figcaption><span>/etc/graphite-web/local_settings.py</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># SECRET_KEY=$(md5sum /etc/passwd | awk {&#39;print $1&#39;})</span>
</span><span class='line'>
</span><span class='line'><span class="c"># echo &quot;SECRET_KEY = &#39;$SECRET_KEY&#39;&quot; | tee -a /etc/graphite-web/local_settings.py</span>
</span><span class='line'><span class="c"># echo &quot;TIME_ZONE = &#39;Asia/Shanghai&#39;&quot; | tee -a /etc/graphite-web/local_settings.py</span>
</span><span class='line'>
</span><span class='line'><span class="c"># cat &lt;&lt; EOF | tee -a /etc/graphite-web/local_settings.py</span>
</span><span class='line'><span class="nv">DATABASES</span> <span class="o">=</span> <span class="o">{</span>
</span><span class='line'>    <span class="s1">&#39;default&#39;</span>: <span class="o">{</span>
</span><span class='line'>        <span class="s1">&#39;NAME&#39;</span>: <span class="s1">&#39;graphite&#39;</span>,
</span><span class='line'>        <span class="s1">&#39;ENGINE&#39;</span>: <span class="s1">&#39;django.db.backends.mysql&#39;</span>,
</span><span class='line'>        <span class="s1">&#39;USER&#39;</span>: <span class="s1">&#39;graphite&#39;</span>,
</span><span class='line'>        <span class="s1">&#39;PASSWORD&#39;</span>: <span class="s1">&#39;sysadmin&#39;</span>,
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span><span class='line'>EOF
</span><span class='line'>
</span><span class='line'><span class="c"># cd /usr/lib/python2.6/site-packages/graphite</span>
</span><span class='line'><span class="c"># ./manage.py syncdb --noinput</span>
</span><span class='line'>
</span><span class='line'><span class="c"># echo &quot;from django.contrib.auth.models import User; User.objects.create_superuser(&#39;admin&#39;, &#39;admin@hihuron.com&#39;, &#39;sysadmin&#39;)&quot; | ./manage.py shell</span>
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Apache配置</li>
</ul>


<figure class='code'><figcaption><span>/etc/httpd/conf.d/graphite-web.conf</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>Listen 0.0.0.0:10000
</span><span class='line'>&lt;VirtualHost *:10000&gt;
</span><span class='line'>    ServerName graphite-web
</span><span class='line'>    DocumentRoot <span class="s2">&quot;/usr/share/graphite/webapp&quot;</span>
</span><span class='line'>    ErrorLog /var/log/httpd/graphite-web-error.log
</span><span class='line'>    CustomLog /var/log/httpd/graphite-web-access.log common
</span><span class='line'>    Alias /media/ <span class="s2">&quot;/usr/lib/python2.6/site-packages/django/contrib/admin/media/&quot;</span>
</span><span class='line'>
</span><span class='line'>    WSGIScriptAlias / /usr/share/graphite/graphite-web.wsgi
</span><span class='line'>    WSGIImportScript /usr/share/graphite/graphite-web.wsgi process-group<span class="o">=</span>%<span class="o">{</span>GLOBAL<span class="o">}</span> application-group<span class="o">=</span>%<span class="o">{</span>GLOBAL<span class="o">}</span>
</span><span class='line'>
</span><span class='line'>    &lt;Location <span class="s2">&quot;/content/&quot;</span>&gt;
</span><span class='line'>        SetHandler None
</span><span class='line'>    &lt;/Location&gt;
</span><span class='line'>
</span><span class='line'>    &lt;Location <span class="s2">&quot;/media/&quot;</span>&gt;
</span><span class='line'>        SetHandler None
</span><span class='line'>    &lt;/Location&gt;
</span><span class='line'>&lt;/VirtualHost&gt;
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Diamond配置</li>
</ul>


<figure class='code'><figcaption><span>bash</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># HOST_IP=$(ifconfig | sed -En &#39;s/127.0.0.1//;s/.*inet (addr:)?(([0-9]*\.){3}[0-9]*).*/\2/p&#39; | head -1)</span>
</span><span class='line'>
</span><span class='line'><span class="c"># sed  -i &quot;/^\[\[GraphiteHandler\]\]$/,/^\[.*\]/s/^host = 127.0.0.1$/host = $HOST_IP/&quot; /etc/diamond/diamond.conf</span>
</span><span class='line'><span class="c"># sed  -i &quot;/^\[\[GraphitePickleHandler\]\]$/,/^\[.*\]/s/^host = 127.0.0.1$/host = $HOST_IP/&quot; /etc/diamond/diamond.conf</span>
</span></code></pre></td></tr></table></div></figure>


<h3>启动服务</h3>

<figure class='code'><figcaption><span>bash</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># service carbon-cache restart</span>
</span><span class='line'><span class="c"># service httpd restart</span>
</span><span class='line'><span class="c"># service diamond restart</span>
</span></code></pre></td></tr></table></div></figure>


<h2>安装和配置Grafana</h2>

<p>Grafana最主要的功能就是对数据的呈现，基于一切可提供time series的后台服务。这里面我们使用Graphite为Grafana提供数据。</p>

<h3>安装及配置</h3>

<figure class='code'><figcaption><span>bash</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># yum install -y nodejs</span>
</span><span class='line'><span class="c"># rpm -ivh https://grafanarel.s3.amazonaws.com/builds/grafana-2.5.0-1.x86_64.rpm</span>
</span><span class='line'><span class="c"># sudo /sbin/chkconfig --add grafana-server</span>
</span><span class='line'><span class="c"># sed -i &#39;s/^;http_port = 3000$/http_port = 10001/g&#39; /etc/grafana/grafana.ini</span>
</span><span class='line'><span class="c"># sudo service grafana-server start</span>
</span></code></pre></td></tr></table></div></figure>


<h3>添加datasource</h3>

<p>Grafana提供了非常丰富的REST API，我们不仅可以直接利用Grafana作为数据呈现层，还可以利用REST API直接将Grafana的Graph集成在我们的应用中。下面我们利用REST API为Grafana添加datasource。</p>

<figure class='code'><figcaption><span>bash</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># curl -i &#39;http://admin:admin@localhost:10001/api/datasources&#39; -X POST -H &quot;Accept: application/json&quot; -H &quot;Content-Type: application/json&quot; -d &#39;{&quot;name&quot;: &quot;graphite&quot;, &quot;type&quot;: &quot;graphite&quot;, &quot;url&quot;: &quot;http://localhost:10000&quot;, &quot;access&quot;: &quot;proxy&quot;, &quot;basicAuth&quot;: false}&#39;</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Ceph监控</h2>

<h3>修改ceph脚本兼容性</h3>

<p>Diamond是基于Python开发的，但是由于CentOS 6.5的Python版本较低(2.6)，所以直接使用社区版本的Ceph监控时，会导致错误。可以通过简单的修改进行修复。</p>

<figure class='code'><figcaption><span>/usr/share/diamond/collectors/ceph/ceph.py</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">_get_stats_from_socket</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
</span><span class='line'>    <span class="sd">&quot;&quot;&quot;Return the parsed JSON data returned when ceph is told to</span>
</span><span class='line'><span class="sd">    dump the stats from the named socket.</span>
</span><span class='line'>
</span><span class='line'><span class="sd">    In the event of an error error, the exception is logged, and</span>
</span><span class='line'><span class="sd">    an empty result set is returned.</span>
</span><span class='line'><span class="sd">    &quot;&quot;&quot;</span>
</span><span class='line'>    <span class="k">try</span><span class="p">:</span>
</span><span class='line'>        <span class="c">#json_blob = subprocess.check_output(</span>
</span><span class='line'>        <span class="c">#    [self.config[&#39;ceph_binary&#39;],</span>
</span><span class='line'>        <span class="c">#     &#39;--admin-daemon&#39;,</span>
</span><span class='line'>        <span class="c">#     name,</span>
</span><span class='line'>        <span class="c">#     &#39;perf&#39;,</span>
</span><span class='line'>        <span class="c">#     &#39;dump&#39;,</span>
</span><span class='line'>        <span class="c">#     ])</span>
</span><span class='line'>        <span class="n">cmd</span> <span class="o">=</span> <span class="p">[</span>
</span><span class='line'>             <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s">&#39;ceph_binary&#39;</span><span class="p">],</span>
</span><span class='line'>             <span class="s">&#39;--admin-daemon&#39;</span><span class="p">,</span>
</span><span class='line'>             <span class="n">name</span><span class="p">,</span>
</span><span class='line'>             <span class="s">&#39;perf&#39;</span><span class="p">,</span>
</span><span class='line'>             <span class="s">&#39;dump&#39;</span><span class="p">,</span>
</span><span class='line'>        <span class="p">]</span>
</span><span class='line'>        <span class="n">process</span> <span class="o">=</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">Popen</span><span class="p">(</span><span class="n">cmd</span><span class="p">,</span> <span class="n">stdout</span><span class="o">=</span><span class="n">subprocess</span><span class="o">.</span><span class="n">PIPE</span><span class="p">)</span>
</span><span class='line'>        <span class="n">json_blob</span> <span class="o">=</span> <span class="n">process</span><span class="o">.</span><span class="n">communicate</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
</span></code></pre></td></tr></table></div></figure>


<h3>增加对ceph osd perf监控</h3>

<p>在实际运维Ceph过程中，ceph osd perf是一个非常重要的指令，能够观察出集群中磁盘的latency的信息，通过观察变化，可以辅助判断磁盘出现性能问题。Diamond的设计中，每个Diamond Agent只会采集自己本机的指标，所以我们在添加的时候，只需要在一个节点上增加这个监控就可以了。在ceph.py中结尾处新增加一个类。</p>

<figure class='code'><figcaption><span>/usr/share/diamond/collectors/ceph/ceph.py</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">class</span> <span class="nc">CephOsdCollector</span><span class="p">(</span><span class="n">CephCollector</span><span class="p">):</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">_get_stats</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span class='line'>        <span class="sd">&quot;&quot;&quot;Return the parsed JSON data returned when ceph is told to</span>
</span><span class='line'><span class="sd">        dump the stats from the named socket.</span>
</span><span class='line'>
</span><span class='line'><span class="sd">        In the event of an error error, the exception is logged, and</span>
</span><span class='line'><span class="sd">        an empty result set is returned.</span>
</span><span class='line'><span class="sd">        &quot;&quot;&quot;</span>
</span><span class='line'>        <span class="k">try</span><span class="p">:</span>
</span><span class='line'>            <span class="c">#json_blob = subprocess.check_output(</span>
</span><span class='line'>            <span class="c">#    [self.config[&#39;ceph_binary&#39;],</span>
</span><span class='line'>            <span class="c">#     &#39;--admin-daemon&#39;,</span>
</span><span class='line'>            <span class="c">#     name,</span>
</span><span class='line'>            <span class="c">#     &#39;perf&#39;,</span>
</span><span class='line'>            <span class="c">#     &#39;dump&#39;,</span>
</span><span class='line'>            <span class="c">#     ])</span>
</span><span class='line'>            <span class="n">cmd</span> <span class="o">=</span> <span class="p">[</span>
</span><span class='line'>                 <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s">&#39;ceph_binary&#39;</span><span class="p">],</span>
</span><span class='line'>                 <span class="s">&#39;osd&#39;</span><span class="p">,</span>
</span><span class='line'>                 <span class="s">&#39;perf&#39;</span><span class="p">,</span>
</span><span class='line'>                 <span class="s">&#39;--format=json&#39;</span><span class="p">,</span>
</span><span class='line'>            <span class="p">]</span>
</span><span class='line'>            <span class="n">process</span> <span class="o">=</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">Popen</span><span class="p">(</span><span class="n">cmd</span><span class="p">,</span> <span class="n">stdout</span><span class="o">=</span><span class="n">subprocess</span><span class="o">.</span><span class="n">PIPE</span><span class="p">)</span>
</span><span class='line'>            <span class="n">json_blob</span> <span class="o">=</span> <span class="n">process</span><span class="o">.</span><span class="n">communicate</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
</span><span class='line'>        <span class="k">except</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">CalledProcessError</span><span class="p">,</span> <span class="n">err</span><span class="p">:</span>
</span><span class='line'>            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s">&#39;Could not get stats from </span><span class="si">%s</span><span class="s">: </span><span class="si">%s</span><span class="s">&#39;</span><span class="p">,</span>
</span><span class='line'>                          <span class="n">name</span><span class="p">,</span> <span class="n">err</span><span class="p">)</span>
</span><span class='line'>            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">exception</span><span class="p">(</span><span class="s">&#39;Could not get stats from </span><span class="si">%s</span><span class="s">&#39;</span> <span class="o">%</span> <span class="n">name</span><span class="p">)</span>
</span><span class='line'>            <span class="k">return</span> <span class="p">{}</span>
</span><span class='line'>
</span><span class='line'>        <span class="k">try</span><span class="p">:</span>
</span><span class='line'>            <span class="n">json_data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">json_blob</span><span class="p">)</span>
</span><span class='line'>        <span class="k">except</span> <span class="ne">Exception</span><span class="p">,</span> <span class="n">err</span><span class="p">:</span>
</span><span class='line'>            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s">&#39;Could not parse stats from </span><span class="si">%s</span><span class="s">: </span><span class="si">%s</span><span class="s">&#39;</span><span class="p">,</span>
</span><span class='line'>                          <span class="n">name</span><span class="p">,</span> <span class="n">err</span><span class="p">)</span>
</span><span class='line'>            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">exception</span><span class="p">(</span><span class="s">&#39;Could not parse stats from </span><span class="si">%s</span><span class="s">&#39;</span> <span class="o">%</span> <span class="n">name</span><span class="p">)</span>
</span><span class='line'>            <span class="k">return</span> <span class="p">{}</span>
</span><span class='line'>
</span><span class='line'>        <span class="k">return</span> <span class="n">json_data</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">_publish_stats</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stats</span><span class="p">):</span>
</span><span class='line'>        <span class="sd">&quot;&quot;&quot;Given a stats dictionary from _get_stats_from_socket,</span>
</span><span class='line'><span class="sd">        publish the individual values.</span>
</span><span class='line'><span class="sd">        &quot;&quot;&quot;</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">perf</span> <span class="ow">in</span> <span class="n">stats</span><span class="p">[</span><span class="s">&#39;osd_perf_infos&#39;</span><span class="p">]:</span>
</span><span class='line'>            <span class="n">counter_prefix</span> <span class="o">=</span> <span class="s">&#39;osd.&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">perf</span><span class="p">[</span><span class="s">&#39;id&#39;</span><span class="p">])</span>
</span><span class='line'>            <span class="k">for</span> <span class="n">stat_name</span><span class="p">,</span> <span class="n">stat_value</span> <span class="ow">in</span> <span class="n">flatten_dictionary</span><span class="p">(</span>
</span><span class='line'>                <span class="n">perf</span><span class="p">[</span><span class="s">&#39;perf_stats&#39;</span><span class="p">],</span>
</span><span class='line'>                <span class="n">prefix</span><span class="o">=</span><span class="n">counter_prefix</span><span class="p">,</span>
</span><span class='line'>            <span class="p">):</span>
</span><span class='line'>              <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s">&#39;stat_name is </span><span class="si">%s</span><span class="s">&#39;</span><span class="p">,</span> <span class="n">stat_name</span><span class="p">)</span>
</span><span class='line'>              <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s">&#39;stat_value is </span><span class="si">%s</span><span class="s">&#39;</span><span class="p">,</span> <span class="n">stat_value</span><span class="p">)</span>
</span><span class='line'>              <span class="bp">self</span><span class="o">.</span><span class="n">publish_gauge</span><span class="p">(</span><span class="n">stat_name</span><span class="p">,</span> <span class="n">stat_value</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">collect</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span class='line'>        <span class="sd">&quot;&quot;&quot;</span>
</span><span class='line'><span class="sd">        Collect stats</span>
</span><span class='line'><span class="sd">        &quot;&quot;&quot;</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s">&#39;in ceph osd collector&#39;</span><span class="p">)</span>
</span><span class='line'>        <span class="n">stats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_stats</span><span class="p">()</span>
</span><span class='line'>        <span class="bp">self</span><span class="o">.</span><span class="n">_publish_stats</span><span class="p">(</span><span class="n">stats</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<h3>修改Diamond监控配置</h3>

<figure class='code'><figcaption><span>/etc/diamond/collectors/ceph.conf</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># cat &lt;&lt; EOF | tee /etc/diamond/collectors/ceph.conf</span>
</span><span class='line'><span class="o">[</span>collectors<span class="o">]</span>
</span><span class='line'>
</span><span class='line'><span class="o">[[</span>CephCollector<span class="o">]]</span>
</span><span class='line'><span class="nv">enabled</span> <span class="o">=</span> True
</span><span class='line'>
</span><span class='line'><span class="o">[[</span>CephOsdCollector<span class="o">]]</span>
</span><span class='line'><span class="nv">enabled</span> <span class="o">=</span> True
</span><span class='line'>EOF
</span></code></pre></td></tr></table></div></figure>




<figure class='code'><figcaption><span>bash</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># service diamond restart</span>
</span></code></pre></td></tr></table></div></figure>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[深度解读OpenStack Liberty国内代码贡献]]></title>
    <link href="http://xiaoquqi.github.io/blog/2015/10/29/contribution-in-liberty/"/>
    <updated>2015-10-29T18:56:06+08:00</updated>
    <id>http://xiaoquqi.github.io/blog/2015/10/29/contribution-in-liberty</id>
    <content type="html"><![CDATA[<p>又到了OpenStack 新版本发布的季节，虽然秋意寒寒，但是仍然挡不住OpenStack再次掀起全球关注的热点。这是OpenStack第12个版本，与之前的沉稳低调相比，这次的Release中一口气多了5个新模块，也创下了OpenStack项目创建以来的最高纪录。由于天然的架构优势，让OpenStack在云计算横行天下的年代游刃有余，已经逐步成为了云平台的即成标准，从OpenStack对待AWS的API兼容的态度就能看出，OpenStack变得越来越自信。</p>

<p>OpenStack Liberty完整版本的翻译可见：<a href="https://wiki.openstack.org/wiki/ReleaseNotes/Liberty/zh-hans">https://wiki.openstack.org/wiki/ReleaseNotes/Liberty/zh-hans</a></p>

<p>本次OpenStack Liberty更新日志中文版本的翻译工作由我完成。由于时间仓促，难免有很多问题，欢迎各位批评指正。</p>

<!-- more -->


<h2>社区贡献分析</h2>

<p>本次统计，并没有采用Review的数量为依据，而直接采用commits的方式，也就是代码实际merge入库的数量。</p>

<p>我们仍然要先看一下模块的贡献情况：</p>

<p><img class="left" src="http://xiaoquqi.github.io/images/blogs/contribution-in-liberty-contribution-by-modules.png" width="400"></p>

<p>与之前Release的特点相似，OpenStack早期的核心模块Nova, Keystone代码commits数量出现明显下滑状态，而Neutron, Heat, Trove, Ceilometer, Cinder等模块都保持着稳中有升的态势。值得关注的是，在排名前20名的项目中，出现了两个直接与Docker有关的项目Kolla和Magnum，一个与docker间接有关的项目Murano。可以预见，OpenStack下一步发展的热点就是在与Docker之间的勾勾搭搭。</p>

<p>特别需要注意的是，在stackalytics.com统计的模块中，在Kilo中是259个，而到了Liberty到了389个，当然有一些项目并非完全是OpenStack的项目，但是也从一个侧面反映出OpenStack以及周边项目的蓬勃发展。</p>

<p>从更新日志中我们也能看到，本次Release的正式项目中，变动较大的是Neutron和Heat两个模块。在经历不断锤炼后，Neutron逐渐走向成熟，但是从生产级别角度看，Neutron的确还有很长的路要走。</p>

<h2>国内社区贡献分析</h2>

<p><img class="center" src="http://xiaoquqi.github.io/images/blogs/contribution-in-liberty-contributor.png" width="400"></p>

<p>从全球企业的贡献排名来看，排名状况基本变化不大，仍然是HP, Redhat, Mirantis, IBM, Rackspace, Intel, Cisco，但是非常欣喜的，国内的IT的航空母舰华为已经成功杀入前十名，这无疑是振奋人心的事情，希望华为未来能多一些对OpenStack社区的主导力，提高中国在OpenStack社区的地位，当然最好也能扶植一下国内的OpenStack创业公司，实现共同发展、共同进步。华为的主要代码贡献集中在dragonflow，magnum，heat等模块，特别是在dragonflow上，几乎全部是华为贡献的，magnum上也将近有五分之一的代码。</p>

<p><strong><em>华为社区贡献统计</em></strong></p>

<p><img class="center" src="http://xiaoquqi.github.io/images/blogs/contribution-in-liberty-huawei.png" width="800"></p>

<p>记得在OpenStack五周年的庆祝活动上，Intel的陈绪博士说过，国内OpenStack贡献企业，就是一朵大云，四朵小云，下面让我们来看看这几朵小云在这个版本的表现。</p>

<p><strong><em> 99cloud社区贡献统计</em></strong></p>

<p><img class="center" src="http://xiaoquqi.github.io/images/blogs/contribution-in-liberty-99cloud.png" width="800"></p>

<p>排名第16位的是99cloud，99cloud自上一个版本排名四朵小云之首后，本次继续强劲来袭，排名创造历史新高，第16名。通过对贡献模块的分析，我们能看出99cloud最大的贡献来自于社区文档，而在项目方面的贡献则主要来自murano-dashboard，horizon，neutron等项目上，从中可以看出99cloud对murano这个applicaton catalog的项目关注程度比较高，可能会在将来的产品中有所体现。从贡献中，我们隐约看到了九州云的副总裁李开总的提交，由此可见九州云为社区贡献的积极程度。
更加难能可贵的是，Horizon的全球贡献99cloud是全球前十，Tempest全球前八，Murano项目更是进入全球前三，相当给力。</p>

<p><strong><em> UnitedStack社区贡献统计 </em></strong>
<img class="center" src="http://xiaoquqi.github.io/images/blogs/contribution-in-liberty-unitedstack.png" width="800"></p>

<p>排在第30位的是UnitedStack，经过了上一个版本的短暂沉寂后，这个版本卷土重来，杀回前30。从代码贡献来看，UnitedStack的主要贡献来自python-openstackclient以及部署用到的puppet相关代码，当然对neutron、trove、kolla、heat等也有一定数量的贡献。</p>

<p><strong><em> Kylin Cloud社区贡献统计 </em></strong>
<img class="center" src="http://xiaoquqi.github.io/images/blogs/contribution-in-liberty-kylincloud.png" width="800"></p>

<p>排名第38位的是麒麟云，其实麒麟云每次Release中总是有她的身影，但好像总是被忽略的。麒麟云最大的贡献来自Horizon项目，其他模块也有一定数量的贡献。总之，我们想到OpenStack企业的时候，的确应该时常提起麒麟云。</p>

<p><strong><em> Easystack社区贡献统计 </em></strong>
<img class="center" src="http://xiaoquqi.github.io/images/blogs/contribution-in-liberty-easystack.png" width="800"></p>

<p>排名第70位的是Easystack，Easystack也属于OpenStack早期创业的公司，对于OpenStack的贡献也是持续的。Easystack最大的贡献来自nova，虽然数量不是很多，但是在国内企业里应该算名列前茅的啦。Easystack对Nova的贡献主要来自对libvirt层的bug修复。</p>

<p><strong><em> Awcloud社区贡献统计 </em></strong>
<img class="center" src="http://xiaoquqi.github.io/images/blogs/contribution-in-liberty-awcloud.png" width="800"></p>

<p>排名第75位的是海云捷迅，海云应该算是在国内发展比较迅猛的一家OpenStack早期创业公司。他们的贡献主要来自Neutron相关的项目，看起来应该是为了解决项目中出现的实际问题所做的努力。海云的马力应该是公司内部贡献排名第一的，尤其是前一段时间发布的两篇关于&#8221;Neutron &amp; OpenStack漫谈&#8221;，非常值得一读。</p>

<p><strong><em> LeTV社区贡献统计 </em></strong>
<img class="center" src="http://xiaoquqi.github.io/images/blogs/contribution-in-liberty-letv.png" width="800"></p>

<p><strong><em> Netease社区贡献统计 </em></strong>
<img class="center" src="http://xiaoquqi.github.io/images/blogs/contribution-in-liberty-netease.png" width="800"></p>

<p>排名第94和95位的分别是两家互联网企业，乐视和网易，乐视是最近互联网中使用OpenStack动静最大的一家了，应该能在大规模应用中发现OpenStack很多问题吧。</p>

<p><strong><em> Huron社区贡献统计 </em></strong>
<img class="center" src="http://xiaoquqi.github.io/images/blogs/contribution-in-liberty-huron.png" width="800"></p>

<p>排名第122位的是我的公司——北京休伦科技有限公司，其实我们公司也算是国内最早一批从事OpenStack创业的公司，z早在2013年的时候就已经开始投入OpenStack私有云产品相关的研发。我们贡献的代码主要来自Nova和Murano两个模块中，都是我们在开发和项目使用中发现的问题，修复后回馈给社区的，我也希望我们能在下一个版本Release中贡献更多的力量。</p>

<p><strong><em> China Mobile社区贡献统计 </em></strong>
<img class="center" src="http://xiaoquqi.github.io/images/blogs/contribution-in-liberty-chinamobile.png" width="800"></p>

<p>排名第133位的是中国移动，之前并没有在哪一个排名上看到过中国移动在OpenStack贡献，我也是第一次发现。中国移动应该算是国内运营商领域技术实力较强的一家，也是运营商里开始从事OpenStack预研较早的一家。中国移动有大量的IT资源和设备，理应像AT&amp;T一样在OpenStack领域大有所为。纵观中国移动的社区贡献，主要来自Neutron和Ceilometer两个项目，几个Bug修复都是与Volume相关。</p>

<p><strong><em> Lenovo社区贡献统计 </em></strong>
<img class="center" src="http://xiaoquqi.github.io/images/blogs/contribution-in-liberty-lenovo.png" width="800"></p>

<p>排名第135位的是联想。不评论了。</p>

<p>排名第139位的是清华大学医学院附属医院，这个有点意思。但是stackalytics.com有Bug，他们的具体统计显示不出来。</p>

<p><strong><em> H3C社区贡献统计 </em></strong>
<img class="center" src="http://xiaoquqi.github.io/images/blogs/contribution-in-liberty-h3c.png" width="800"></p>

<p>排名第143位的是H3C。贡献是Nova中的关于VMware的Bug Fix。</p>

<p>由于stackalytics并没有按照区域统计的功能，所以本次统计完全是全自动统计(全靠我自己手动)，所以难免遗漏了为OpenStack贡献的国内企业，如果发生该情况请及时告知。</p>

<h2>社区贡献内容分析</h2>

<p><img class="center" src="http://xiaoquqi.github.io/images/blogs/contribution-in-liberty-complete-blueprints.png" width="800"></p>

<p>从贡献的commits的类型来区分，国内贡献出的代码主要还是以bug为主，这可能也与我们使用的都是OpenStack较成熟的模块有关，本身这些模块成熟程度较高，所以想做blueprint很难。另外一个很重要的原因是和OpenStack管理流程有关的，现在像Nova, Cinder等项目都是需要先Review Specs的，其实就是所谓的设计文档，语言成为国内很多工程师贡献的最大障碍，所以这也导致了Blueprint的贡献度在国内并不高。</p>

<p><strong><em> Huawei社区贡献——完成Blueprint </em></strong>
<img class="center" src="http://xiaoquqi.github.io/images/blogs/contribution-in-liberty-blueprint-huawei.png" width="800"></p>

<p>纵观整个Blueprint的完成统计情况，华为作为国内最有实力的企业，高居全球第五名，完成最多的模块为cinder和mistral。</p>

<p>之后能完成Blueprint的企业还包括UnitedStack、中国移动、麒麟云、海云捷迅和九州云，但是相比来说数量较少，都是个位数字。</p>

<p>OpenStack在国内发展已经超过了四年的时间，但是遗憾的一点，尽管我们拥有世界上最多的开发人员，但是我们对社区仍然没有话语权，国内的用户的需求无法对社区上游形成影响，导致很多本地化定制的需求无法真正的在社区版本代码得到体现。所以如何让中国的声音出现在社区，是我们所有OpenStack人需要思考的问题。欣喜的一点，本土的巨头华为已经身先士卒，投入很大的力量搞OpenStack的社区贡献，我们更希望越来越多的国内传统IT巨头能够意识到这个问题，投身于开源的事业中，否则我们又在起跑线上输给了别人。</p>

<p>以上仅代表个人观点，如有任何异议，欢迎批评指正。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ubuntu 14.04 Server开发者安装指南]]></title>
    <link href="http://xiaoquqi.github.io/blog/2015/09/09/ubuntu-14-dot-04-installation-guide-for-developer/"/>
    <updated>2015-09-09T13:50:24+08:00</updated>
    <id>http://xiaoquqi.github.io/blog/2015/09/09/ubuntu-14-dot-04-installation-guide-for-developer</id>
    <content type="html"><![CDATA[<h2>为什么会写这篇Blog</h2>

<p>近期，接触了一些OpenStack的入门者，很多人对Linux系统并不是很熟悉，导致安装出来的系统五花八门，间接地影响了后面的开发与调试，所以这里给出我的安装流程，供初学者们参考。我使用的是Ubuntu 14.04 64bit Server版本的ISO进行安装，其他版本方法类似。</p>

<!-- more -->


<h2>注意</h2>

<p>这篇Blog没有提及的地方：</p>

<ul>
<li>网络，需要根据实际情况进行配置，我这里面使用的是DHCP自动获取，所以没有相关步骤</li>
<li>分区，这里面使用的是默认配置，但是生产环境的配置一般需要手动划分</li>
</ul>


<h2>安装步骤</h2>

<ul>
<li>一定要选择English，否则处理中文的时候太麻烦
<img class="center" src="http://xiaoquqi.github.io/images/blogs/install-ubuntu/1.png"></li>
<li>正式开始进入安装
<img class="center" src="http://xiaoquqi.github.io/images/blogs/install-ubuntu/2.png"></li>
<li>与上面的原则一致，一定要选择English
<img class="center" src="http://xiaoquqi.github.io/images/blogs/install-ubuntu/3.png"></li>
<li>Location一定要选择中国，否则默认不会使用中文的Ubuntu源，影响安装速度，这一步很多初学者不会在意
<img class="center" src="http://xiaoquqi.github.io/images/blogs/install-ubuntu/4.png">
<img class="center" src="http://xiaoquqi.github.io/images/blogs/install-ubuntu/5.png">
<img class="center" src="http://xiaoquqi.github.io/images/blogs/install-ubuntu/6.png"></li>
<li>这里面主要是字符集的问题，选择United States
<img class="center" src="http://xiaoquqi.github.io/images/blogs/install-ubuntu/7.png"></li>
<li>不需要检查键盘布局
<img class="center" src="http://xiaoquqi.github.io/images/blogs/install-ubuntu/8.png"></li>
<li>默认使用English布局就好了
<img class="center" src="http://xiaoquqi.github.io/images/blogs/install-ubuntu/9.png"></li>
<li>主机名设置，就是hostname
<img class="center" src="http://xiaoquqi.github.io/images/blogs/install-ubuntu/10.png"></li>
<li>用户设置，建议建立一个普通用户
<img class="center" src="http://xiaoquqi.github.io/images/blogs/install-ubuntu/11.png">
<img class="center" src="http://xiaoquqi.github.io/images/blogs/install-ubuntu/12.png">
<img class="center" src="http://xiaoquqi.github.io/images/blogs/install-ubuntu/13.png">
<img class="center" src="http://xiaoquqi.github.io/images/blogs/install-ubuntu/15.png">
<img class="center" src="http://xiaoquqi.github.io/images/blogs/install-ubuntu/16.png"></li>
<li>不加密Home目录
<img class="center" src="http://xiaoquqi.github.io/images/blogs/install-ubuntu/17.png"></li>
<li>设置时区，这一步也很重要，默认情况下会自动检测到，但是如果不对，一定要修改一下，否则你的系统时间与你实际不一致，你程序里的时间跟着不对，跟调试增加难度
<img class="center" src="http://xiaoquqi.github.io/images/blogs/install-ubuntu/18.png"></li>
<li>这里面分区用默认的就好啦，当然如果你知道该如何分区，可以采用Manual方式
<img class="center" src="http://xiaoquqi.github.io/images/blogs/install-ubuntu/19.png">
<img class="center" src="http://xiaoquqi.github.io/images/blogs/install-ubuntu/20.png">
<img class="center" src="http://xiaoquqi.github.io/images/blogs/install-ubuntu/21.png">
<img class="center" src="http://xiaoquqi.github.io/images/blogs/install-ubuntu/22.png">
<img class="center" src="http://xiaoquqi.github.io/images/blogs/install-ubuntu/23.png"></li>
<li>如果访问网络需要使用代理，可以设置一下
<img class="center" src="http://xiaoquqi.github.io/images/blogs/install-ubuntu/24.png"></li>
<li>不选择自动更新
<img class="center" src="http://xiaoquqi.github.io/images/blogs/install-ubuntu/25.png"></li>
<li>默认只需要选择SSH服务，保证我们在安装后能够SSH登陆服务器即可
<img class="center" src="http://xiaoquqi.github.io/images/blogs/install-ubuntu/26.png"></li>
<li>安装grub
<img class="center" src="http://xiaoquqi.github.io/images/blogs/install-ubuntu/27.png"></li>
<li>重启完成安装
<img class="center" src="http://xiaoquqi.github.io/images/blogs/install-ubuntu/28.png"></li>
</ul>


<h2>后记</h2>

<p>谨记此篇Blog送给我的小徒弟周小球小朋友，希望你能利用利用最后的一年的时间努力学习，找到称心如意的工作。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[(Kilo)Devstack完全用户手册]]></title>
    <link href="http://xiaoquqi.github.io/blog/2015/09/03/devstack-guide/"/>
    <updated>2015-09-03T18:34:20+08:00</updated>
    <id>http://xiaoquqi.github.io/blog/2015/09/03/devstack-guide</id>
    <content type="html"><![CDATA[<p>Devstack作为开发OpenStack必不可少的辅助环境搭建工具，其重要性不言而喻，但是由于网络上的原因，在使用中总是出现各种各样的问题，而且也不是所有人对使用上的细节非常清晰，所以想用这篇Blog总结一下在三年多的使用过程中的心得，来帮助将要走进OpenStack开发的志愿者们。下一篇博客我将为大家介绍Devstack的源代码，以及扩展插件的开发方法。</p>

<p>本篇Blog主要介绍以下几个实用场景：</p>

<ul>
<li>如何利用Devstack构建一套完美的开发环境</li>
<li>提高Devstack安装成功率的方法</li>
<li>Devstack的实用技巧</li>
<li>各种场景下的配置和注意事项</li>
</ul>


<p>本篇博客提到的所有方法均在2015年9月4日使用stable/kilo branch得到验证，后续版本请持续关注本博客。</p>

<!-- more -->


<h2>运行环境的选择</h2>

<p>对于刚刚接触OpenStack的开发者而言，没有太多闲置的资源，所以比较容易的上手方式就是使用虚拟机。对于桌面的虚拟机软件来说，主流的软件无外乎VMWare Workstation和Oracle Virtualbox，对于OpenStack开发而言，二者并无太大差异。以下几点可能会作为选择的主要依据：</p>

<ul>
<li>VMWare Workstation是收费软件，Virtualbox是免费软件</li>
<li>VMWare Workstation支持nested virtualization，就是安装完的devstack virt type是kvm，节省资源，Virtualbox安装以后只能使用qemu，虽然在Virtualbox 5以上版本号称支持，但是实际验证中仍然不能生效，还在研究中</li>
<li>VMWare Workstation使用NAT方式时，内部的IP可以在HOST主机直接访问到，Virtualbox还需要端口转发，所以建议单独增加一块Host-only的Apdaptor便于调试</li>
<li>使用Virtualbox时，为了让虚拟机能够访问外部网络，并且允许Host通过Floating IP对虚拟机进行访问，需要在Host层面设置NAT规则，转换到可以访问的物理网卡上，详情请见下文</li>
</ul>


<h2>Virtualbox网络设置</h2>

<p><img class="center" src="http://xiaoquqi.github.io/images/blogs/devstack-guide-network-topology.jpg"></p>

<ul>
<li>Nova Network网卡配置</li>
</ul>


<figure class='code'><figcaption><span>/etc/network/interface</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>auto eth0
</span><span class='line'>iface eth0 inet dhcp
</span><span class='line'>
</span><span class='line'>auto eth1
</span><span class='line'>iface eth1 inet static
</span><span class='line'>address 192.168.56.101
</span><span class='line'>netmask 255.255.255.0
</span><span class='line'>
</span><span class='line'>auto eth2
</span><span class='line'>iface eth1 inet static
</span><span class='line'>address 172.16.0.101
</span><span class='line'>netmask 255.255.255.0</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Neutron网卡配置</li>
</ul>


<figure class='code'><figcaption><span>/etc/network/interface</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>auto eth0
</span><span class='line'>iface eth0 inet dhcp
</span><span class='line'>
</span><span class='line'>auto eth1
</span><span class='line'>iface eth1 inet static
</span><span class='line'>address 192.168.56.101
</span><span class='line'>netmask 255.255.255.0
</span><span class='line'>
</span><span class='line'>auto eth2
</span><span class='line'>iface eth2 inet manual
</span><span class='line'>up ip link set dev $IFACE up
</span><span class='line'>down ip link set dev $IFACE down</span></code></pre></td></tr></table></div></figure>


<ul>
<li>MAC网卡NAT映射</li>
</ul>


<p>我们将第三块网卡作为提供外部网络的接口，采用系统层面的NAT方式让该网卡能够访问外部网络。</p>

<figure class='code'><figcaption><span>bash</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo sysctl net.inet.ip.forwarding=1</span></code></pre></td></tr></table></div></figure>


<p>在nat-anchor后面添加</p>

<figure class='code'><figcaption><span>/etc/pf.conf</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>nat on en0 from 172.16.0.0/24 -&gt; (en0)</span></code></pre></td></tr></table></div></figure>


<p>之后加载</p>

<figure class='code'><figcaption><span>bash</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>sudo pfctl -e -f /etc/pf.conf
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Linux网卡NAT映射</li>
</ul>


<figure class='code'><figcaption><span>bash</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>echo 1 &gt; /proc/sys/net/ipv4/ip_forward
</span><span class='line'>iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE</span></code></pre></td></tr></table></div></figure>


<h2>Devstack快速开始</h2>

<p>其实，Devstack本身并不需要很复杂的配置就可以成功运行，但是仍然有几个需要注意的地方：</p>

<ul>
<li>Ubuntu 14.04 64bit(LTS), 12.04已经逐渐退出历史舞台，所以这里推荐14.04</li>
<li>不能使用root用户，即使你使用root用户执行Devstack，默认也会为你建立一个stack用户，所以不如老老实实的直接使用普通用户运行Devstack，或者提前建立好stack用户，切换后再执行</li>
<li>默认获取Devstack进行安装，安装的是master分支的代码，但是在实际开发中(比如我们做产品的时候)，都是基于某个stable分支进行，所以一般情况在clone devstack的时候需要指定stable分支</li>
</ul>


<p>下面给出一个最简安装步骤：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># adduser stack
</span><span class='line'># apt-get install sudo -y
</span><span class='line'># echo "stack ALL=(ALL) NOPASSWD: ALL" &gt;&gt; /etc/sudoers
</span><span class='line'># sudo su - stack
</span><span class='line'>
</span><span class='line'>(stack)$ git clone https://git.openstack.org/openstack-dev/devstack --branch=stable/kilo
</span><span class='line'>(stack)$ cd devstack && ./stack.sh</span></code></pre></td></tr></table></div></figure>


<h2>提高Devstack安装成功率</h2>

<p>估计在国内使用Devstack的人基本都遇到过安装失败的状况，为了节约大家的时间，先分析一下Devstack为什么会失败，我们先从这张时序图看一下Devstack执行的过程：</p>

<p><img class="center" src="http://xiaoquqi.github.io/images/blogs/devstack-guide-flow.png"></p>

<p>从上述流程图中可以很清楚的看到Devstack有以下几个地方需要访问网络：</p>

<ul>
<li>安装依赖时，需要访问Ubuntu的源</li>
<li>执行get_pip.sh时，地址是彻底被墙的，需要访问<a href="https://bootstrap.pypa.io/get-pip.py">https://bootstrap.pypa.io/get-pip.py</a></li>
<li>从github clone源代码，github在国内访问速度并不很快而且间歇性被墙</li>
<li>安装过程中执行pip install requirements，需要访问pip repo</li>
<li>下载镜像，这一步骤取决于你需要安装的模块，如果默认安装只会下载cirros镜像，但是如果是安装类似Trove的模块，可能需要下载的更多</li>
</ul>


<hr />

<p>所以综上所述，为了提高devstack的安装成功率，需要从这几个方面着手优化：</p>

<ul>
<li>使用国内源</li>
</ul>


<figure class='code'><figcaption><span>/etc/apt/sources.list</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>deb http://mirrors.163.com/ubuntu/ trusty main restricted universe multiverse
</span><span class='line'>deb http://mirrors.163.com/ubuntu/ trusty-security main restricted universe multiverse
</span><span class='line'>deb http://mirrors.163.com/ubuntu/ trusty-updates main restricted universe multiverse
</span><span class='line'>deb http://mirrors.163.com/ubuntu/ trusty-proposed main restricted universe multiverse
</span><span class='line'>deb http://mirrors.163.com/ubuntu/ trusty-backports main restricted universe multiverse</span></code></pre></td></tr></table></div></figure>


<ul>
<li>从国内源获取get-pip.py，从源代码可以分析出，检测get-pip.py的方式，这里面有两种方式一种是手动下载get-pip.py之后，注释代码，还有一种就是修改PIP_GET_PIP_URL的地址，但是这里只能通过修改install_pip.sh的方式，暂时无法从环境变量里获取</li>
</ul>


<figure class='code'><figcaption><span>devstack/tools/install_pip.sh</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">FILES</span><span class="o">=</span><span class="nv">$TOP_DIR</span>/files
</span><span class='line'>
</span><span class='line'><span class="nv">PIP_GET_PIP_URL</span><span class="o">=</span>https://bootstrap.pypa.io/get-pip.py
</span><span class='line'><span class="nv">LOCAL_PIP</span><span class="o">=</span><span class="s2">&quot;$FILES/$(basename $PIP_GET_PIP_URL)&quot;</span>
</span><span class='line'>
</span><span class='line'><span class="k">function</span> install_get_pip <span class="o">{</span>
</span><span class='line'>    <span class="c"># The OpenStack gate and others put a cached version of get-pip.py</span>
</span><span class='line'>    <span class="c"># for this to find, explicitly to avoid download issues.</span>
</span><span class='line'>    <span class="c">#</span>
</span><span class='line'>    <span class="c"># However, if DevStack *did* download the file, we want to check</span>
</span><span class='line'>    <span class="c"># for updates; people can leave their stacks around for a long</span>
</span><span class='line'>    <span class="c"># time and in the mean-time pip might get upgraded.</span>
</span><span class='line'>    <span class="c">#</span>
</span><span class='line'>    <span class="c"># Thus we use curl&#39;s &quot;-z&quot; feature to always check the modified</span>
</span><span class='line'>    <span class="c"># since and only download if a new version is out -- but only if</span>
</span><span class='line'>    <span class="c"># it seems we downloaded the file originally.</span>
</span><span class='line'>    <span class="k">if</span> <span class="o">[[</span> ! -r <span class="nv">$LOCAL_PIP</span> <span class="o">||</span> -r <span class="nv">$LOCAL_PIP</span>.downloaded <span class="o">]]</span><span class="p">;</span> <span class="k">then</span>
</span><span class='line'>        curl --retry <span class="m">6</span> --retry-delay <span class="m">5</span> <span class="se">\</span>
</span><span class='line'>            -z <span class="nv">$LOCAL_PIP</span> -o <span class="nv">$LOCAL_PIP</span> <span class="nv">$PIP_GET_PIP_URL</span> <span class="o">||</span> <span class="se">\</span>
</span><span class='line'>            die <span class="nv">$LINENO</span> <span class="s2">&quot;Download of get-pip.py failed&quot;</span>
</span><span class='line'>        touch <span class="nv">$LOCAL_PIP</span>.downloaded
</span><span class='line'>    <span class="k">fi</span>
</span><span class='line'>    sudo -H -E python <span class="nv">$LOCAL_PIP</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>修改为我在coding.net上缓存的get-pip脚本</p>

<figure class='code'><figcaption><span>devstack/tools/install_pip.sh</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">PIP_GET_PIP_URL</span><span class="o">=</span>https://coding.net/u/xiaoquqi/p/pip/git/raw/master/contrib/get-pip.py
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>国内的代码托管服务器有从github上定期同步源代码的，但是经过实际测试都不是很理想，所以可能这是最不稳定的一部分，但是可以提前使用脚本，人工的下载所有代码，之后我会尝试在我自己的源中定时同步OpenStack源代码，敬请关注</li>
<li>现在pip的安装速度明显提升，原来还需要使用国内源，例如豆瓣，现在即使不修改也能很快的进行安装</li>
<li>镜像下载建议使用一些下载工具，然后放到指定的目录中，这样最有效</li>
</ul>


<h2>无网络状况下安装Devstack</h2>

<p>因为我们是做OpenStack的产品的公司，所以就要求我们的Devstack要能够满足无网络状况下的安装，之前也写过一篇详细介绍无网络安装Devstack博客,由于时间关系，可能一些内容已经过时了，这里面再进行一下更新，思路还是上面的思路，这里给出一些使用的工具，如果不清楚如何使用的话，可以参考我之前的博客。</p>

<ul>
<li>本地源的缓存使用apt-mirror，这是一个需要时间的工作，第一次同步的时间会非常长，准备好大约100G左右的空间吧</li>
<li>缓存get-pip.py，这个比较容易，搭建一个Apache服务器，但是需要把端口修改为10000，否则在安装好OpenStack后，会占用80端口，重新执行Devstack时候会出现错误</li>
<li>建立本地的Gerrit，并且上传所有代码</li>
<li>从requirements项目中，下载所有的pip，建立本地的pip缓存源，如果是搭建研发环境，可能还需要下载test-requirements的内容和tox</li>
<li>将镜像下载到刚刚创建的Apache服务器</li>
</ul>


<p>完成以上步骤，你可以尽情断掉外网，愉快的进行Devstack的安装了，稍后我会将以上步骤进行进一步完善。</p>

<h2>OFFLINE模式下安装Devstack</h2>

<p>在Devstack中提供了一种OFFLINE的方式，这种方式的含义就是，当你第一次完成安装后，所有需要的内容已经下载到本地，再次运行就没有必要访问网络了(前提是你不想升级)，所以可以将安装模式设置为OFFLINE，避免网络的访问，方法为：</p>

<figure class='code'><figcaption><span>devstack/localrc</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">OFFLINE</span><span class="o">=</span>True
</span></code></pre></td></tr></table></div></figure>


<h2>虚拟机重启后，如何利用rejoin-stack.sh，免重新安装</h2>

<p>其实使用OFFLINE模式，可以在离线状态下无数次重新运行devstack，但是如果不是为了重新配置，我们并没有需要每次重新运行stack.sh。在Devstack中提供了另外一个脚本叫做rejoin-stack.sh，原理很简单就是把所有的进程重新组合进screen，所以我们借助这个脚本完全可以不重新执行stack.sh，快速恢复环境。但是当虚拟机重启后，cinder使用的卷组并不会自动重建，所以在运行rejoin之前，需要将恢复卷组的工作，放入开机启动的脚本中。</p>

<figure class='code'><figcaption><span>/etc/init.d/cinder-setup-backing-file</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>losetup /dev/loop1 /opt/stack/data/stack-volumes-default-backing-file
</span><span class='line'>losetup /dev/loop2 /opt/stack/data/stack-volumes-lvmdriver-1-backing-file
</span><span class='line'><span class="nb">exit </span>0
</span></code></pre></td></tr></table></div></figure>




<figure class='code'><figcaption><span>Run as root</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>chmod <span class="m">755</span> /etc/init.d/cinder-setup-backing-file
</span><span class='line'>ln -s /etc/init.d/cinder-setup-backing-file /etc/rc2.d/S10cinder-setup-backing-file
</span></code></pre></td></tr></table></div></figure>




<figure class='code'><figcaption><span>Run as normal user</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nb">cd</span> <span class="nv">$HOME</span>/devstack
</span><span class='line'>./rejoin-stack.sh
</span></code></pre></td></tr></table></div></figure>


<h2>Scenario 0: 公共部分</h2>

<figure class='code'><figcaption><span>devstack/localrc</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># Misc</span>
</span><span class='line'><span class="nv">ADMIN_PASSWORD</span><span class="o">=</span>sysadmin
</span><span class='line'><span class="nv">DATABASE_PASSWORD</span><span class="o">=</span><span class="nv">$ADMIN_PASSWORD</span>
</span><span class='line'><span class="nv">RABBIT_PASSWORD</span><span class="o">=</span><span class="nv">$ADMIN_PASSWORD</span>
</span><span class='line'><span class="nv">SERVICE_PASSWORD</span><span class="o">=</span><span class="nv">$ADMIN_PASSWORD</span>
</span><span class='line'><span class="nv">SERVICE_TOKEN</span><span class="o">=</span><span class="nv">$ADMIN_PASSWORD</span>
</span><span class='line'>
</span><span class='line'><span class="c"># Target Path</span>
</span><span class='line'><span class="nv">DEST</span><span class="o">=</span>/opt/stack.kilo
</span><span class='line'>
</span><span class='line'><span class="c"># Enable Logging</span>
</span><span class='line'><span class="nv">LOGFILE</span><span class="o">=</span><span class="nv">$DEST</span>/logs/stack.sh.log
</span><span class='line'><span class="nv">VERBOSE</span><span class="o">=</span>True
</span><span class='line'><span class="nv">LOG_COLOR</span><span class="o">=</span>True
</span><span class='line'><span class="nv">SCREEN_LOGDIR</span><span class="o">=</span><span class="nv">$DEST</span>/logs
</span></code></pre></td></tr></table></div></figure>


<h2>Scenario 1: 单节点Nova-Network的安装</h2>

<p>这应该就是Devstack默认的模式，有以下几点需要注意：</p>

<ul>
<li>根据上面的网卡配置</li>
</ul>


<blockquote><p>第一块网卡为NAT方式，用于访问外部网络</p>

<p>第二块为Host-only Adaptor，用于访问云平台</p>

<p>第三块为Host-only Adaptor，用于虚拟机桥接网路</p>

<p>需要注意的是：这种方式下并不能让虚拟机正常访问外部网络，可以通过将eth2设置为Bridge模式，但是这样会造成DHCP冲突(如果外部网络有DHCP)，所以暂时没有完美的解决方案</p></blockquote>

<ul>
<li>打开novnc和consoleauth，否则无法访问VNC</li>
</ul>


<p>这里给出的配置方案是第一种网络配置，即虚拟机无法网络外部网络的情况</p>

<figure class='code'><figcaption><span>devstack/localrc</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># Nova</span>
</span><span class='line'>enable_service n-novnc n-cauth
</span><span class='line'>
</span><span class='line'><span class="nv">FLAT_INTERFACE</span><span class="o">=</span>eth1
</span><span class='line'><span class="c"># eth1 address</span>
</span><span class='line'><span class="nv">HOST_IP</span><span class="o">=</span>192.168.56.101
</span><span class='line'><span class="nv">FIXED_RANGE</span><span class="o">=</span>172.24.17.0/24
</span><span class='line'><span class="nv">FIXED_NETWORK_SIZE</span><span class="o">=</span>254
</span><span class='line'><span class="nv">FLOATING_RANGE</span><span class="o">=</span>172.16.0.128/25
</span></code></pre></td></tr></table></div></figure>


<h2>Scenario 2: 双节点Nova-Network的安装</h2>

<ul>
<li>控制节点</li>
</ul>


<figure class='code'><figcaption><span>devstack/localrc</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># Nova</span>
</span><span class='line'>enable_service n-novnc n-cauth
</span><span class='line'>disable_service n-cpu n-net n-api-meta c-vol
</span><span class='line'>
</span><span class='line'><span class="c"># current host ip</span>
</span><span class='line'><span class="nv">HOST_IP</span><span class="o">=</span>192.168.56.101
</span><span class='line'><span class="nv">FLAT_INTERFACE</span><span class="o">=</span>eth1
</span><span class='line'><span class="nv">MULTI_HOST</span><span class="o">=</span>1
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>计算节点</li>
</ul>


<figure class='code'><figcaption><span>devstack/localrc</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># Nova</span>
</span><span class='line'>enable_service n-novnc n-cauth
</span><span class='line'><span class="nv">ENABLED_SERVICES</span><span class="o">=</span>n-cpu,n-net,n-api-meta,c-vol
</span><span class='line'>
</span><span class='line'><span class="c"># current host ip</span>
</span><span class='line'><span class="nv">HOST_IP</span><span class="o">=</span>192.168.56.101
</span><span class='line'><span class="nv">FLAT_INTERFACE</span><span class="o">=</span>eth1
</span><span class='line'><span class="c"># needed by cinder-volume service</span>
</span><span class='line'><span class="nv">DATABASE_TYPE</span><span class="o">=</span>mysql
</span><span class='line'>
</span><span class='line'><span class="c"># controller ip</span>
</span><span class='line'><span class="nv">SERVICE_HOST</span><span class="o">=</span>192.168.56.101
</span><span class='line'><span class="nv">MYSQL_HOST</span><span class="o">=</span><span class="nv">$SERVICE_HOST</span>
</span><span class='line'><span class="nv">RABBIT_HOST</span><span class="o">=</span><span class="nv">$SERVICE_HOST</span>
</span><span class='line'><span class="nv">GLANCE_HOSTPORT</span><span class="o">=</span><span class="nv">$SERVICE_HOST</span>:9292
</span><span class='line'><span class="nv">NOVA_VNC_ENABLED</span><span class="o">=</span>True
</span><span class='line'><span class="nv">NOVNCPROXY_URL</span><span class="o">=</span><span class="s2">&quot;http://$SERVICE_HOST:6080/vnc_auto.html&quot;</span>
</span><span class='line'><span class="nv">VNCSERVER_LISTEN</span><span class="o">=</span><span class="nv">$HOST_IP</span>
</span><span class='line'><span class="nv">VNCSERVER_PROXYCLIENT_ADDRESS</span><span class="o">=</span><span class="nv">$VNCSERVER_LISTEN</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Scenario 3: 单节点Neutron的安装</h2>

<ul>
<li>基本配置</li>
</ul>


<figure class='code'><figcaption><span>devstack/localrc</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># Nova</span>
</span><span class='line'>enable_service n-novnc n-cauth
</span><span class='line'>
</span><span class='line'><span class="c"># Neutron</span>
</span><span class='line'>disable_service n-net
</span><span class='line'>ENABLED_SERVICES+<span class="o">=</span>,q-svc,q-agt,q-dhcp,q-l3,q-meta,neutron
</span><span class='line'>ENABLED_SERVICES+<span class="o">=</span>,q-lbaas,q-vpn,q-fwaas
</span><span class='line'>
</span><span class='line'><span class="nv">HOST_IP</span><span class="o">=</span>192.168.56.101
</span><span class='line'><span class="nv">FIXED_RANGE</span><span class="o">=</span>20.0.0.0/24
</span><span class='line'><span class="nv">NETWORK_GATEWAY</span><span class="o">=</span>20.0.0.1
</span><span class='line'><span class="nv">FLOATING_RANGE</span><span class="o">=</span>172.16.0.0/24
</span><span class='line'><span class="nv">PUBLIC_NETWORK_GATEWAY</span><span class="o">=</span>172.16.0.1
</span><span class='line'><span class="nv">Q_FLOATING_ALLOCATION_POOL</span><span class="o">=</span><span class="nv">start</span><span class="o">=</span>172.16.0.101,end<span class="o">=</span>172.16.0.200
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>OVS设置</li>
</ul>


<p>由于在Devstack安装过程中，将br-ex的地址也设置成了PUBLIC_NETWORK_GATEWAY的地址，但是实际使用过程中，我们建立的Host Apdator充当了gateway的角色，所以为了避免冲突，直接将br-ex地址清除掉。</p>

<figure class='code'><figcaption><span>bash</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>sudo ip addr flush dev br-ex
</span></code></pre></td></tr></table></div></figure>


<p>之后将eth2作为br-ex的port，之后创建的虚拟机就可以通过eth2访问网络了，Host也可以通过floating ip访问虚拟机了。</p>

<figure class='code'><figcaption><span>bash</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>sudo ovs-vsctl add-port br-ex eth2
</span></code></pre></td></tr></table></div></figure>


<h2>Scenario 4: 多节点Neutron的安装(控制/网络+计算节点)</h2>

<ul>
<li>控制/网络节点</li>
</ul>


<figure class='code'><figcaption><span>devstack/localrc</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># Nova
</span><span class='line'>enable_service n-novnc n-cauth
</span><span class='line'>HOST_IP=192.168.56.101
</span><span class='line'>disable_service n-cpu n-net n-api-meta c-vol
</span><span class='line'>
</span><span class='line'># Neutron
</span><span class='line'>disable_service n-net
</span><span class='line'>ENABLED_SERVICES+=,q-svc,q-agt,q-dhcp,q-l3,q-meta
</span><span class='line'>FIXED_RANGE=20.0.0.0/24
</span><span class='line'>NETWORK_GATEWAY=20.0.0.1
</span><span class='line'>FLOATING_RANGE=172.16.0.0/24
</span><span class='line'>PUBLIC_NETWORK_GATEWAY=172.16.0.1
</span><span class='line'>Q_FLOATING_ALLOCATION_POOL=start=172.16.0.101,end=172.16.0.200</span></code></pre></td></tr></table></div></figure>


<ul>
<li>计算节点</li>
</ul>


<figure class='code'><figcaption><span>devstack/localrc</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># Nova
</span><span class='line'>disable_all_services
</span><span class='line'>ENABLED_SERVICES=n-cpu,rabbit,neutron,q-agt,c-vol
</span><span class='line'>
</span><span class='line'># current host ip
</span><span class='line'>HOST_IP=192.168.56.103
</span><span class='line'># needed by cinder-volume service
</span><span class='line'>DATABASE_TYPE=mysql
</span><span class='line'>
</span><span class='line'># controller ip
</span><span class='line'>SERVICE_HOST=192.168.56.101
</span><span class='line'>MYSQL_HOST=$SERVICE_HOST
</span><span class='line'>RABBIT_HOST=$SERVICE_HOST
</span><span class='line'>GLANCE_HOSTPORT=$SERVICE_HOST:9292
</span><span class='line'>NOVA_VNC_ENABLED=True
</span><span class='line'>NOVNCPROXY_URL="http://$SERVICE_HOST:6080/vnc_auto.html"
</span><span class='line'>VNCSERVER_LISTEN=$HOST_IP
</span><span class='line'>VNCSERVER_PROXYCLIENT_ADDRESS=$VNCSERVER_LISTEN
</span><span class='line'>Q_HOST=$SERVICE_HOST</span></code></pre></td></tr></table></div></figure>


<ul>
<li>OVS设置</li>
</ul>


<p>由于在Devstack安装过程中，将br-ex的地址也设置成了PUBLIC_NETWORK_GATEWAY的地址，但是实际使用过程中，我们建立的Host Apdator充当了gateway的角色，所以为了避免冲突，直接将br-ex地址清除掉。</p>

<figure class='code'><figcaption><span>bash</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>sudo ip addr flush dev br-ex
</span></code></pre></td></tr></table></div></figure>


<p>之后将eth2作为br-ex的port，之后创建的虚拟机就可以通过eth2访问网络了，Host也可以通过floating ip访问虚拟机了。</p>

<figure class='code'><figcaption><span>bash</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>sudo ovs-vsctl add-port br-ex eth2
</span></code></pre></td></tr></table></div></figure>


<h2>Scenario 5: 从源代码安装客户端</h2>

<p>新的Devstack里面默认不再提供client的源代码的安装方式，需要使用localrc中的环境变量进行开启，否则将直接从master获取的client代码进行安装，当然这样会造成系统无法正常使用。那么如何才能确定client在当前Devstack可用的版本呢？最简单的方法可以先从pip中安装包，之后通过pip list | grep client的方式获取client的源代码。这里面提供我在Kilo中使用的版本依赖。</p>

<figure class='code'><figcaption><span>devstack/localrc</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">KEYSTONECLIENT_BRANCH</span><span class="o">=</span>1.3.1
</span><span class='line'><span class="nv">CINDERCLIENT_BRANCH</span><span class="o">=</span>1.1.1
</span><span class='line'><span class="nv">GLANCECLIENT_BRANCH</span><span class="o">=</span>0.17.1
</span><span class='line'><span class="nv">HEATCLIENT_BRANCH</span><span class="o">=</span>0.4.0
</span><span class='line'><span class="nv">NEUTRONCLIENT_BRANCH</span><span class="o">=</span>2.4.0
</span><span class='line'><span class="nv">NOVACLIENT_BRANCH</span><span class="o">=</span>2.23.0
</span><span class='line'><span class="nv">SWIFTCLIENT_BRANCH</span><span class="o">=</span>2.4.0
</span><span class='line'>
</span><span class='line'><span class="c"># client code</span>
</span><span class='line'><span class="nv">LIBS_FROM_GIT</span><span class="o">=</span>python-keystoneclient,python-glanceclient,python-novaclient,python-neutronclient,python-swiftclient,python-cinderclient
</span></code></pre></td></tr></table></div></figure>


<h2>Scenario 6: 安装Ceilometer/Heat/Trove/Sahara/Swift</h2>

<figure class='code'><figcaption><span>devstack/localrc</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># Ceilometer</span>
</span><span class='line'>enable_service ceilometer-acompute ceilometer-acentral ceilometer-anotification ceilometer-collector ceilometer-api
</span><span class='line'>enable_service ceilometer-alarm-notifier ceilometer-alarm-evaluator
</span><span class='line'>
</span><span class='line'><span class="c"># Heat</span>
</span><span class='line'>enable_service heat h-api h-api-cfn h-api-cw h-eng
</span><span class='line'>
</span><span class='line'><span class="c"># Trove</span>
</span><span class='line'>enable_service trove tr-api tr-tmgr tr-cond
</span><span class='line'>
</span><span class='line'><span class="c"># Sahara</span>
</span><span class='line'>enable_service sahara
</span><span class='line'>
</span><span class='line'><span class="c"># Swift</span>
</span><span class='line'>enable_service s-proxy s-object s-container s-account
</span><span class='line'><span class="nv">SWIFT_REPLICAS</span><span class="o">=</span>1
</span><span class='line'><span class="nv">SWIFT_HASH</span><span class="o">=</span>011688b44136573e209e
</span></code></pre></td></tr></table></div></figure>


<h2>Scenario 7: 安装Ceph</h2>

<figure class='code'><figcaption><span>devstack/localrc</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># Ceph</span>
</span><span class='line'>ENABLED_SERVICES+<span class="o">=</span>,ceph
</span><span class='line'><span class="nv">CEPH_LOOPBACK_DISK_SIZE</span><span class="o">=</span>200G
</span><span class='line'><span class="nv">CEPH_CONF</span><span class="o">=</span>/etc/ceph/ceph.conf
</span><span class='line'><span class="nv">CEPH_REPLICAS</span><span class="o">=</span>1
</span><span class='line'>
</span><span class='line'><span class="c"># Glance - Image Service</span>
</span><span class='line'><span class="nv">GLANCE_CEPH_USER</span><span class="o">=</span>glance
</span><span class='line'><span class="nv">GLANCE_CEPH_POOL</span><span class="o">=</span>glance-pool
</span><span class='line'>
</span><span class='line'><span class="c"># Cinder - Block Device Service</span>
</span><span class='line'><span class="nv">CINDER_DRIVER</span><span class="o">=</span>ceph
</span><span class='line'><span class="nv">CINDER_CEPH_USER</span><span class="o">=</span>cinder
</span><span class='line'><span class="nv">CINDER_CEPH_POOL</span><span class="o">=</span>cinder-pool
</span><span class='line'><span class="nv">CINDER_CEPH_UUID</span><span class="o">=</span>1b1519e4-5ecd-11e5-8559-080027f18a73
</span><span class='line'><span class="nv">CINDER_BAK_CEPH_POOL</span><span class="o">=</span>cinder-backups
</span><span class='line'><span class="nv">CINDER_BAK_CEPH_USER</span><span class="o">=</span>cinder-backups
</span><span class='line'><span class="nv">CINDER_ENABLED_BACKENDS</span><span class="o">=</span>ceph
</span><span class='line'><span class="nv">CINDER_ENABLED_BACKENDS</span><span class="o">=</span>ceph
</span><span class='line'>
</span><span class='line'><span class="c"># Nova - Compute Service</span>
</span><span class='line'><span class="nv">NOVA_CEPH_POOL</span><span class="o">=</span>nova-pool
</span></code></pre></td></tr></table></div></figure>


<h2>Scenario 8: 安装Murano</h2>

<p>想通过这个例子演示，对于一个新的OpenStack项目，如何使用Devstack尝鲜。</p>

<figure class='code'><figcaption><span>bash</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nb">cd</span> /opt/stack.kilo
</span><span class='line'>git clone https://github.com/openstack/murano --branch<span class="o">=</span>stable/kilo
</span><span class='line'><span class="nb">cd </span>murano/contrib/devstack
</span><span class='line'>cp lib/murano <span class="k">${</span><span class="nv">DEVSTACK_DIR</span><span class="k">}</span>/lib
</span><span class='line'>cp lib/murano-dashboard <span class="k">${</span><span class="nv">DEVSTACK_DIR</span><span class="k">}</span>/lib
</span><span class='line'>cp extras.d/70-murano.sh <span class="k">${</span><span class="nv">DEVSTACK_DIR</span><span class="k">}</span>/extras.d
</span></code></pre></td></tr></table></div></figure>




<figure class='code'><figcaption><span>devstack/localrc</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># Enable Neutron
</span><span class='line'>ENABLED_SERVICES+=,q-svc,q-agt,q-dhcp,q-l3,q-meta,neutron
</span><span class='line'>
</span><span class='line'># Enable Heat
</span><span class='line'>enable_service heat h-api h-api-cfn h-api-cw h-eng
</span><span class='line'>
</span><span class='line'># Enable Murano
</span><span class='line'>enable_service murano murano-api murano-engine</span></code></pre></td></tr></table></div></figure>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[为什么叫Monkey Patch？]]></title>
    <link href="http://xiaoquqi.github.io/blog/2015/08/18/about-monkey-patch/"/>
    <updated>2015-08-18T18:51:21+08:00</updated>
    <id>http://xiaoquqi.github.io/blog/2015/08/18/about-monkey-patch</id>
    <content type="html"><![CDATA[<p>在程序运行时给代码加补丁的方法被称为Monkey Patch，这种方式多见于脚本类语言中(Dynamic Programming Languages)，例如: Ruby/Python等。国内很多人翻译为猴子补丁，但是为什么叫猴子补丁而不叫老虎补丁、狮子补丁呢？</p>

<p>估计刚刚看到这个表述的开发人员可能很难理解到底这是什么意思，其实Monkey Patch本与猴子无关，这个词原来为Guerrilla Patch，这样看着好像能明白一些了，游击队嘛，神出鬼没的，好像和运行状态打补丁这个功能贴近点了，但是为什么又变成猴子了。原来老外们都是很顽皮的，他们喜欢一些玩笑式的表述，就像很多技术的文档中一样。在英文里，Guerrilla和Gorilla读音是几乎一样的，Gorilla当什么讲呢？大猩猩。但是大猩猩有点吓人，所以干脆换成了大猩猩的近亲——猴子。就这样Monkey Patch形成了。</p>

<p>当然这并不是这个词的唯一解释，还有一种解释是说由于这种方式将原来的代码弄乱了(messing with it)，在英文里叫monkeying about(顽皮的)，所以叫做Monkey Patch。这种描述应该是和Monkey Test有异曲同工之妙。但是无论这个词从哪里来，我们只要正确理解Monkey Patch的含义就好了。</p>

<p>相同的表述还有Duck Typing，描述的是动态类型的一种风格。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ceph性能优化总结(v0.94)]]></title>
    <link href="http://xiaoquqi.github.io/blog/2015/06/28/ceph-performance-optimization-summary/"/>
    <updated>2015-06-28T14:30:22+08:00</updated>
    <id>http://xiaoquqi.github.io/blog/2015/06/28/ceph-performance-optimization-summary</id>
    <content type="html"><![CDATA[<p>最近一直在忙着搞Ceph存储的优化和测试，看了各种资料，但是好像没有一篇文章把其中的方法论交代清楚，所以呢想在这里进行一下总结，很多内容并不是我原创，只是做一个总结。如果其中有任何的问题，欢迎各位喷我，以便我提高。</p>

<h2>优化方法论</h2>

<p>做任何事情还是要有个方法论的，“授人以鱼不如授人以渔”的道理吧，方法通了，所有的问题就有了解决的途径。通过对公开资料的分析进行总结，对分布式存储系统的优化离不开以下几点：</p>

<h3>1. 硬件层面</h3>

<ul>
<li>硬件规划</li>
<li>SSD选择</li>
<li>BIOS设置</li>
</ul>


<h3>2. 软件层面</h3>

<ul>
<li>Linux OS</li>
<li>Ceph Configurations</li>
<li>PG Number调整</li>
<li>CRUSH Map</li>
<li>其他因素</li>
</ul>


<!-- more -->


<h2>硬件优化</h2>

<h3>1. 硬件规划</h3>

<ul>
<li>Processor</li>
</ul>


<p>ceph-osd进程在运行过程中会消耗CPU资源，所以一般会为每一个ceph-osd进程绑定一个CPU核上。当然如果你使用EC方式，可能需要更多的CPU资源。</p>

<p>ceph-mon进程并不十分消耗CPU资源，所以不必为ceph-mon进程预留过多的CPU资源。</p>

<p>ceph-msd也是非常消耗CPU资源的，所以需要提供更多的CPU资源。</p>

<ul>
<li>内存</li>
</ul>


<p>ceph-mon和ceph-mds需要2G内存，每个ceph-osd进程需要1G内存，当然2G更好。</p>

<ul>
<li>网络规划</li>
</ul>


<p>万兆网络现在基本上是跑Ceph必备的，网络规划上，也尽量考虑分离cilent和cluster网络。</p>

<h3>2. SSD选择</h3>

<p>硬件的选择也直接决定了Ceph集群的性能，从成本考虑，一般选择SATA SSD作为Journal，<a href="http://www.intel.com/content/www/us/en/solid-state-drives/solid-state-drives-dc-s3500-series.html">Intel® SSD DC S3500 Series</a>基本是目前看到的方案中的首选。400G的规格4K随机写可以达到11000 IOPS。如果在预算足够的情况下，推荐使用PCIE SSD，性能会得到进一步提升，但是由于Journal在向数据盘写入数据时Block后续请求，所以Journal的加入并未呈现出想象中的性能提升，但是的确会对Latency有很大的改善。</p>

<p>如何确定你的SSD是否适合作为SSD Journal，可以参考SÉBASTIEN HAN的<a href="http://www.sebastien-han.fr/blog/2014/10/10/ceph-how-to-test-if-your-ssd-is-suitable-as-a-journal-device/">Ceph: How to Test if Your SSD Is Suitable as a Journal Device?</a>，这里面他也列出了常见的SSD的测试结果，从结果来看SATA SSD中，Intel S3500性能表现最好。</p>

<h3>3. BIOS设置</h3>

<ul>
<li>Hyper-Threading(HT)</li>
</ul>


<p>基本做云平台的，VT和HT打开都是必须的，超线程技术(HT)就是利用特殊的硬件指令，把两个逻辑内核模拟成两个物理芯片，让单个处理器都能使用线程级并行计算，进而兼容多线程操作系统和软件，减少了CPU的闲置时间，提高的CPU的运行效率。</p>

<ul>
<li>关闭节能</li>
</ul>


<p>关闭节能后，对性能还是有所提升的，所以坚决调整成性能型(Performance)。当然也可以在操作系统级别进行调整，详细的调整过程请参考<a href="http://www.servernoobs.com/avoiding-cpu-speed-scaling-in-modern-linux-distributions-running-cpu-at-full-speed-tips/">链接</a>，但是不知道是不是由于BIOS已经调整的缘故，所以在CentOS 6.6上并没有发现相关的设置。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>for CPUFREQ in /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor; do [ -f $CPUFREQ ] || continue; echo -n performance &gt; $CPUFREQ; done</span></code></pre></td></tr></table></div></figure>


<ul>
<li><a href="http://www.ibm.com/developerworks/cn/linux/l-numa/">NUMA</a></li>
</ul>


<p>简单来说，NUMA思路就是将内存和CPU分割为多个区域，每个区域叫做NODE,然后将NODE高速互联。 node内cpu与内存访问速度快于访问其他node的内存，<a href="http://lists.ceph.com/pipermail/ceph-users-ceph.com/2013-December/036211.html">NUMA可能会在某些情况下影响ceph-osd</a>。解决的方案，一种是通过BIOS关闭NUMA，另外一种就是通过cgroup将ceph-osd进程与某一个CPU Core以及同一NODE下的内存进行绑定。但是第二种看起来更麻烦，所以一般部署的时候可以在系统层面关闭NUMA。CentOS系统下，通过修改/etc/grub.conf文件，添加numa=off来关闭NUMA。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>kernel /vmlinuz-2.6.32-504.12.2.el6.x86_64 ro root=UUID=870d47f8-0357-4a32-909f-74173a9f0633 rd_NO_LUKS rd_NO_LVM LANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16 crashkernel=auto  KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM   biosdevname=0 numa=off</span></code></pre></td></tr></table></div></figure>


<h2>软件优化</h2>

<h3>1. Linux OS</h3>

<ul>
<li>Kernel pid max</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>echo 4194303 &gt; /proc/sys/kernel/pid_max</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Jumbo frames, 交换机端需要支持该功能，系统网卡设置才有效果</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ifconfig eth0 mtu 9000</span></code></pre></td></tr></table></div></figure>


<p>永久设置</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>echo "MTU=9000" | tee -a /etc/sysconfig/network-script/ifcfg-eth0
</span><span class='line'>/etc/init.d/networking restart</span></code></pre></td></tr></table></div></figure>


<ul>
<li>read_ahead, 通过数据预读并且记载到随机访问内存方式提高磁盘读操作，查看默认值</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cat /sys/block/sda/queue/read_ahead_kb</span></code></pre></td></tr></table></div></figure>


<p>根据一些Ceph的公开分享，8192是比较理想的值</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>echo "8192" &gt; /sys/block/sda/queue/read_ahead_kb</span></code></pre></td></tr></table></div></figure>


<ul>
<li>swappiness, 主要控制系统对swap的使用，这个参数的调整最先见于UnitedStack公开的文档中，猜测调整的原因主要是使用swap会影响系统的性能。</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>echo "vm.swappiness = 0" | tee -a /etc/sysctl.conf</span></code></pre></td></tr></table></div></figure>


<ul>
<li>I/O Scheduler，关于I/O Scheculder的调整网上已经有很多资料，这里不再赘述，简单说SSD要用noop，SATA/SAS使用deadline。</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>echo "deadline" &gt; /sys/block/sd[x]/queue/scheduler
</span><span class='line'>echo "noop" &gt; /sys/block/sd[x]/queue/scheduler</span></code></pre></td></tr></table></div></figure>


<ul>
<li>cgroup</li>
</ul>


<p>这方面的文章好像比较少，昨天在和Ceph社区交流过程中，Jan Schermer说准备把生产环境中的一些脚本贡献出来，但是暂时还没有，他同时也列举了一些使用cgroup进行隔离的<a href="https://www.mail-archive.com/ceph-users@lists.ceph.com/msg21111.html">原因</a>。</p>

<blockquote><ul>
<li>不在process和thread在不同的core上移动(更好的缓存利用)</li>
<li>减少NUMA的影响</li>
<li>网络和存储控制器影响 - 较小</li>
<li>通过限制cpuset来限制Linux调度域(不确定是不是重要但是是最佳实践)</li>
<li>如果开启了HT，可能会造成OSD在thread1上，KVM在thread2上，并且是同一个core。Core的延迟和性能取决于其他一个线程做什么。</li>
</ul>
</blockquote>

<p>这一点具体实现待补充！！！</p>

<h3>2. Ceph Configurations</h3>

<h4>[global]</h4>

<table>
<thead>
<tr>
<th> 参数名 </th>
<th> 描述 </th>
<th> 默认值 </th>
<th> 建议值 </th>
</tr>
</thead>
<tbody>
<tr>
<td> public network </td>
<td> 客户端访问网络 </td>
<td> </td>
<td> 192.168.100.0/24 </td>
</tr>
<tr>
<td> cluster network </td>
<td> 集群网络 </td>
<td> </td>
<td> 192.168.1.0/24 </td>
</tr>
<tr>
<td> max open files </td>
<td> 如果设置了该选项，Ceph会设置系统的max open fds </td>
<td> 0 </td>
<td> 131072 </td>
</tr>
</tbody>
</table>


<hr />

<ul>
<li>查看系统最大文件打开数可以使用命令</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cat /proc/sys/fs/file-max</span></code></pre></td></tr></table></div></figure>


<hr />

<h4>[osd] - filestore</h4>

<table>
<thead>
<tr>
<th> 参数名 </th>
<th> 描述 </th>
<th> 默认值 </th>
<th> 建议值 </th>
</tr>
</thead>
<tbody>
<tr>
<td> filestore xattr use omap </td>
<td> 为XATTRS使用object map，EXT4文件系统时使用，XFS或者btrfs也可以使用 </td>
<td> false </td>
<td> true </td>
</tr>
<tr>
<td> filestore max sync interval </td>
<td> 从日志到数据盘最大同步间隔(seconds) </td>
<td> 5 </td>
<td> 15 </td>
</tr>
<tr>
<td> filestore min sync interval </td>
<td> 从日志到数据盘最小同步间隔(seconds) </td>
<td> 0.1 </td>
<td> 10 </td>
</tr>
<tr>
<td> filestore queue max ops </td>
<td> 数据盘最大接受的操作数 </td>
<td> 500 </td>
<td> 25000 </td>
</tr>
<tr>
<td> filestore queue max bytes </td>
<td> 数据盘一次操作最大字节数(bytes) </td>
<td> 100 &lt;&lt; 20 </td>
<td> 10485760 </td>
</tr>
<tr>
<td> filestore queue committing max ops </td>
<td> 数据盘能够commit的操作数 </td>
<td> 500 </td>
<td> 5000 </td>
</tr>
<tr>
<td> filestore queue committing max bytes </td>
<td> 数据盘能够commit的最大字节数(bytes) </td>
<td> 100 &lt;&lt; 20 </td>
<td> 10485760000 </td>
</tr>
<tr>
<td> filestore op threads </td>
<td> 并发文件系统操作数 </td>
<td> 2 </td>
<td> 32 </td>
</tr>
</tbody>
</table>


<hr />

<ul>
<li>调整omap的原因主要是EXT4文件系统默认仅有4K</li>
<li>filestore queue相关的参数对于性能影响很小，参数调整不会对性能优化有本质上提升</li>
</ul>


<hr />

<h4>[osd] - journal</h4>

<table>
<thead>
<tr>
<th> 参数名 </th>
<th> 描述 </th>
<th> 默认值 </th>
<th> 建议值 </th>
</tr>
</thead>
<tbody>
<tr>
<td> osd journal size </td>
<td> OSD日志大小(MB) </td>
<td> 5120 </td>
<td> 20000 </td>
</tr>
<tr>
<td> journal max write bytes </td>
<td> journal一次性写入的最大字节数(bytes) </td>
<td> 10 &lt;&lt; 20 </td>
<td> 1073714824 </td>
</tr>
<tr>
<td> journal max write entries </td>
<td> journal一次性写入的最大记录数 </td>
<td> 100 </td>
<td> 10000 </td>
</tr>
<tr>
<td> journal queue max ops </td>
<td> journal一次性最大在队列中的操作数 </td>
<td> 500 </td>
<td> 50000 </td>
</tr>
<tr>
<td> journal queue max bytes </td>
<td> journal一次性最大在队列中的字节数(bytes) </td>
<td> 10 &lt;&lt; 20 </td>
<td> 10485760000 </td>
</tr>
</tbody>
</table>


<hr />

<ul>
<li>Ceph OSD Daemon stops writes and synchronizes the journal with the filesystem, allowing Ceph OSD Daemons to trim operations from the journal and reuse the space.</li>
<li>上面这段话的意思就是，Ceph OSD进程在往数据盘上刷数据的过程中，是停止写操作的。</li>
</ul>


<hr />

<h4>[osd] - osd config tuning</h4>

<table>
<thead>
<tr>
<th> 参数名 </th>
<th> 描述 </th>
<th> 默认值 </th>
<th> 建议值 </th>
</tr>
</thead>
<tbody>
<tr>
<td> osd max write size </td>
<td> OSD一次可写入的最大值(MB) </td>
<td> 90 </td>
<td> 512 </td>
</tr>
<tr>
<td> osd client message size cap </td>
<td> 客户端允许在内存中的最大数据(bytes) </td>
<td> 524288000 </td>
<td> 2147483648 </td>
</tr>
<tr>
<td> osd deep scrub stride </td>
<td> 在Deep Scrub时候允许读取的字节数(bytes) </td>
<td> 524288 </td>
<td> 131072 </td>
</tr>
<tr>
<td> osd op threads </td>
<td> OSD进程操作的线程数 </td>
<td> 2 </td>
<td> 8 </td>
</tr>
<tr>
<td> osd disk threads </td>
<td> OSD密集型操作例如恢复和Scrubbing时的线程 </td>
<td> 1 </td>
<td> 4 </td>
</tr>
<tr>
<td> osd map cache size </td>
<td> 保留OSD Map的缓存(MB) </td>
<td> 500 </td>
<td> 1024 </td>
</tr>
<tr>
<td> osd map cache bl size </td>
<td> OSD进程在内存中的OSD Map缓存(MB) </td>
<td> 50 </td>
<td> 128 </td>
</tr>
<tr>
<td> osd mount options xfs </td>
<td> Ceph OSD xfs Mount选项 </td>
<td> rw,noatime,inode64 </td>
<td> rw,noexec,nodev,noatime,nodiratime,nobarrier </td>
</tr>
</tbody>
</table>


<hr />

<ul>
<li>增加osd op threads和disk threads会带来额外的CPU开销</li>
</ul>


<hr />

<h4>[osd] - recovery tuning</h4>

<table>
<thead>
<tr>
<th> 参数名 </th>
<th> 描述 </th>
<th> 默认值 </th>
<th> 建议值 </th>
</tr>
</thead>
<tbody>
<tr>
<td> osd recovery op priority </td>
<td> 恢复操作优先级，取值1-63，值越高占用资源越高 </td>
<td> 10 </td>
<td> 4 </td>
</tr>
<tr>
<td> osd recovery max active </td>
<td> 同一时间内活跃的恢复请求数 </td>
<td> 15 </td>
<td> 10 </td>
</tr>
<tr>
<td> osd max backfills </td>
<td> 一个OSD允许的最大backfills数 </td>
<td> 10 </td>
<td> 4 </td>
</tr>
</tbody>
</table>


<h4>[osd] - client tuning</h4>

<table>
<thead>
<tr>
<th> 参数名 </th>
<th> 描述 </th>
<th> 默认值 </th>
<th> 建议值 </th>
</tr>
</thead>
<tbody>
<tr>
<td> rbd cache </td>
<td> RBD缓存 </td>
<td> true </td>
<td> true </td>
</tr>
<tr>
<td> rbd cache size </td>
<td> RBD缓存大小(bytes) </td>
<td> 33554432 </td>
<td> 268435456 </td>
</tr>
<tr>
<td> rbd cache max dirty </td>
<td> 缓存为write-back时允许的最大dirty字节数(bytes)，如果为0，使用write-through </td>
<td> 25165824 </td>
<td> 134217728 </td>
</tr>
<tr>
<td> rbd cache max dirty age </td>
<td> 在被刷新到存储盘前dirty数据存在缓存的时间(seconds) </td>
<td> 1 </td>
<td> 5 </td>
</tr>
</tbody>
</table>


<h4>关闭Debug</h4>

<h3>3. PG Number</h3>

<p>PG和PGP数量一定要根据OSD的数量进行调整，计算公式如下，但是最后算出的结果一定要接近或者等于一个2的指数。</p>

<pre><code>Total PGs = (Total_number_of_OSD * 100) / max_replication_count
</code></pre>

<p>例如15个OSD，副本数为3的情况下，根据公式计算的结果应该为500，最接近512，所以需要设定该pool(volumes)的pg_num和pgp_num都为512.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ceph osd pool set volumes pg_num 512
</span><span class='line'>ceph osd pool set volumes pgp_num 512</span></code></pre></td></tr></table></div></figure>


<h3>4. CRUSH Map</h3>

<p>CRUSH是一个非常灵活的方式，CRUSH MAP的调整取决于部署的具体环境，这个可能需要根据具体情况进行分析，这里面就不再赘述了。</p>

<h3>5. 其他因素的影响</h3>

<p>在今年的(2015年)的Ceph Day上，海云捷迅在调优过程中分享过一个由于在集群中存在一个性能不好的磁盘，导致整个集群性能下降的case。通过osd perf可以提供磁盘latency的状况，同时在运维过程中也可以作为监控的一个重要指标，很明显在下面的例子中，OSD 8的磁盘延时较长，所以需要考虑将该OSD剔除出集群：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ceph osd perf</span></code></pre></td></tr></table></div></figure>


<pre><code>osd fs_commit_latency(ms) fs_apply_latency(ms)
  0                    14                   17
  1                    14                   16
  2                    10                   11
  3                     4                    5
  4                    13                   15
  5                    17                   20
  6                    15                   18
  7                    14                   16
  8                   299                  329
</code></pre>

<h2>ceph.conf</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[global]
</span><span class='line'>fsid = 059f27e8-a23f-4587-9033-3e3679d03b31
</span><span class='line'>mon_host = 10.10.20.102, 10.10.20.101, 10.10.20.100
</span><span class='line'>auth cluster required = cephx
</span><span class='line'>auth service required = cephx
</span><span class='line'>auth client required = cephx
</span><span class='line'>osd pool default size = 3
</span><span class='line'>osd pool default min size = 1
</span><span class='line'>
</span><span class='line'>public network = 10.10.20.0/24
</span><span class='line'>cluster network = 10.10.20.0/24
</span><span class='line'>
</span><span class='line'>max open files = 131072
</span><span class='line'>
</span><span class='line'>[mon]
</span><span class='line'>mon data = /var/lib/ceph/mon/ceph-$id
</span><span class='line'>
</span><span class='line'>[osd]
</span><span class='line'>osd data = /var/lib/ceph/osd/ceph-$id
</span><span class='line'>osd journal size = 20000
</span><span class='line'>osd mkfs type = xfs
</span><span class='line'>osd mkfs options xfs = -f
</span><span class='line'>
</span><span class='line'>filestore xattr use omap = true
</span><span class='line'>filestore min sync interval = 10
</span><span class='line'>filestore max sync interval = 15
</span><span class='line'>filestore queue max ops = 25000
</span><span class='line'>filestore queue max bytes = 10485760
</span><span class='line'>filestore queue committing max ops = 5000
</span><span class='line'>filestore queue committing max bytes = 10485760000
</span><span class='line'>
</span><span class='line'>journal max write bytes = 1073714824
</span><span class='line'>journal max write entries = 10000
</span><span class='line'>journal queue max ops = 50000
</span><span class='line'>journal queue max bytes = 10485760000
</span><span class='line'>
</span><span class='line'>osd max write size = 512
</span><span class='line'>osd client message size cap = 2147483648
</span><span class='line'>osd deep scrub stride = 131072
</span><span class='line'>osd op threads = 8
</span><span class='line'>osd disk threads = 4
</span><span class='line'>osd map cache size = 1024
</span><span class='line'>osd map cache bl size = 128
</span><span class='line'>osd mount options xfs = "rw,noexec,nodev,noatime,nodiratime,nobarrier"
</span><span class='line'>osd recovery op priority = 4
</span><span class='line'>osd recovery max active = 10
</span><span class='line'>osd max backfills = 4
</span><span class='line'>
</span><span class='line'>[client]
</span><span class='line'>rbd cache = true
</span><span class='line'>rbd cache size = 268435456
</span><span class='line'>rbd cache max dirty = 134217728
</span><span class='line'>rbd cache max dirty age = 5</span></code></pre></td></tr></table></div></figure>


<h2>总结</h2>

<p>优化是一个长期迭代的过程，所有的方法都是别人的，只有在实践过程中才能发现自己的，本篇文章仅仅是一个开始，欢迎各位积极补充，共同完成一篇具有指导性的文章。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ceph集群磁盘没有剩余空间的解决方法]]></title>
    <link href="http://xiaoquqi.github.io/blog/2015/05/12/ceph-osd-is-full/"/>
    <updated>2015-05-12T09:21:42+08:00</updated>
    <id>http://xiaoquqi.github.io/blog/2015/05/12/ceph-osd-is-full</id>
    <content type="html"><![CDATA[<h2>故障描述</h2>

<p>OpenStack + Ceph集群在使用过程中，由于虚拟机拷入大量新的数据，导致集群的磁盘迅速消耗，没有空余空间，虚拟机无法操作，Ceph集群所有操作都无法执行。</p>

<!-- more -->


<h2>故障现象</h2>

<ul>
<li>尝试使用OpenStack重启虚拟机无效</li>
<li>尝试直接用rbd命令直接删除块失败</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[root@controller ~]# rbd -p volumes rm volume-c55fd052-212d-4107-a2ac-cf53bfc049be
</span><span class='line'>2015-04-29 05:31:31.719478 7f5fb82f7760  0 client.4781741.objecter  FULL, paused modify 0xe9a9e0 tid 6</span></code></pre></td></tr></table></div></figure>


<ul>
<li>查看ceph健康状态</li>
</ul>


<figure class='code'><figcaption><span>ceph -s</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cluster 059f27e8-a23f-4587-9033-3e3679d03b31
</span><span class='line'> health HEALTH_ERR 20 pgs backfill_toofull; 20 pgs degraded; 20 pgs stuck unclean; recovery 7482/129081 objects degraded (5.796%); 2 full osd(s); 1 near full osd(s)
</span><span class='line'> monmap e6: 4 mons at {node-5e40.cloud.com=10.10.20.40:6789/0,node-6670.cloud.com=10.10.20.31:6789/0,node-66c4.cloud.com=10.10.20.36:6789/0,node-fb27.cloud.com=10.10.20.41:6789/0}, election epoch 886, quorum 0,1,2,3 node-6670.cloud.com,node-66c4.cloud.com,node-5e40.cloud.com,node-fb27.cloud.com
</span><span class='line'> osdmap e2743: 3 osds: 3 up, 3 in
</span><span class='line'>        flags full
</span><span class='line'>  pgmap v6564199: 320 pgs, 4 pools, 262 GB data, 43027 objects
</span><span class='line'>        786 GB used, 47785 MB / 833 GB avail
</span><span class='line'>        7482/129081 objects degraded (5.796%)
</span><span class='line'>             300 active+clean
</span><span class='line'>              20 active+degraded+remapped+backfill_toofull</span></code></pre></td></tr></table></div></figure>




<figure class='code'><figcaption><span>ceph health detail</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>HEALTH_ERR 20 pgs backfill_toofull; 20 pgs degraded; 20 pgs stuck unclean; recovery 7482/129081 objects degraded (5.796%); 2 full osd(s); 1 near full osd(s)
</span><span class='line'>pg 3.8 is stuck unclean for 7067109.597691, current state active+degraded+remapped+backfill_toofull, last acting [2,0]
</span><span class='line'>pg 3.7d is stuck unclean for 1852078.505139, current state active+degraded+remapped+backfill_toofull, last acting [2,0]
</span><span class='line'>pg 3.21 is stuck unclean for 7072842.637848, current state active+degraded+remapped+backfill_toofull, last acting [0,2]
</span><span class='line'>pg 3.22 is stuck unclean for 7070880.213397, current state active+degraded+remapped+backfill_toofull, last acting [0,2]
</span><span class='line'>pg 3.a is stuck unclean for 7067057.863562, current state active+degraded+remapped+backfill_toofull, last acting [2,0]
</span><span class='line'>pg 3.7f is stuck unclean for 7067122.493746, current state active+degraded+remapped+backfill_toofull, last acting [0,2]
</span><span class='line'>pg 3.5 is stuck unclean for 7067088.369629, current state active+degraded+remapped+backfill_toofull, last acting [2,0]
</span><span class='line'>pg 3.1e is stuck unclean for 7073386.246281, current state active+degraded+remapped+backfill_toofull, last acting [0,2]
</span><span class='line'>pg 3.19 is stuck unclean for 7068035.310269, current state active+degraded+remapped+backfill_toofull, last acting [0,2]
</span><span class='line'>pg 3.5d is stuck unclean for 1852078.505949, current state active+degraded+remapped+backfill_toofull, last acting [2,0]
</span><span class='line'>pg 3.1a is stuck unclean for 7067088.429544, current state active+degraded+remapped+backfill_toofull, last acting [2,0]
</span><span class='line'>pg 3.1b is stuck unclean for 7072773.771385, current state active+degraded+remapped+backfill_toofull, last acting [0,2]
</span><span class='line'>pg 3.3 is stuck unclean for 7067057.864514, current state active+degraded+remapped+backfill_toofull, last acting [2,0]
</span><span class='line'>pg 3.15 is stuck unclean for 7067088.825483, current state active+degraded+remapped+backfill_toofull, last acting [2,0]
</span><span class='line'>pg 3.11 is stuck unclean for 7067057.862408, current state active+degraded+remapped+backfill_toofull, last acting [2,0]
</span><span class='line'>pg 3.6d is stuck unclean for 7067083.634454, current state active+degraded+remapped+backfill_toofull, last acting [2,0]
</span><span class='line'>pg 3.6e is stuck unclean for 7067098.452576, current state active+degraded+remapped+backfill_toofull, last acting [2,0]
</span><span class='line'>pg 3.c is stuck unclean for 5658116.678331, current state active+degraded+remapped+backfill_toofull, last acting [2,0]
</span><span class='line'>pg 3.e is stuck unclean for 7067078.646953, current state active+degraded+remapped+backfill_toofull, last acting [2,0]
</span><span class='line'>pg 3.20 is stuck unclean for 7067140.530849, current state active+degraded+remapped+backfill_toofull, last acting [0,2]
</span><span class='line'>pg 3.7d is active+degraded+remapped+backfill_toofull, acting [2,0]
</span><span class='line'>pg 3.7f is active+degraded+remapped+backfill_toofull, acting [0,2]
</span><span class='line'>pg 3.6d is active+degraded+remapped+backfill_toofull, acting [2,0]
</span><span class='line'>pg 3.6e is active+degraded+remapped+backfill_toofull, acting [2,0]
</span><span class='line'>pg 3.5d is active+degraded+remapped+backfill_toofull, acting [2,0]
</span><span class='line'>pg 3.20 is active+degraded+remapped+backfill_toofull, acting [0,2]
</span><span class='line'>pg 3.21 is active+degraded+remapped+backfill_toofull, acting [0,2]
</span><span class='line'>pg 3.22 is active+degraded+remapped+backfill_toofull, acting [0,2]
</span><span class='line'>pg 3.1e is active+degraded+remapped+backfill_toofull, acting [0,2]
</span><span class='line'>pg 3.19 is active+degraded+remapped+backfill_toofull, acting [0,2]
</span><span class='line'>pg 3.1a is active+degraded+remapped+backfill_toofull, acting [2,0]
</span><span class='line'>pg 3.1b is active+degraded+remapped+backfill_toofull, acting [0,2]
</span><span class='line'>pg 3.15 is active+degraded+remapped+backfill_toofull, acting [2,0]
</span><span class='line'>pg 3.11 is active+degraded+remapped+backfill_toofull, acting [2,0]
</span><span class='line'>pg 3.c is active+degraded+remapped+backfill_toofull, acting [2,0]
</span><span class='line'>pg 3.e is active+degraded+remapped+backfill_toofull, acting [2,0]
</span><span class='line'>pg 3.8 is active+degraded+remapped+backfill_toofull, acting [2,0]
</span><span class='line'>pg 3.a is active+degraded+remapped+backfill_toofull, acting [2,0]
</span><span class='line'>pg 3.5 is active+degraded+remapped+backfill_toofull, acting [2,0]
</span><span class='line'>pg 3.3 is active+degraded+remapped+backfill_toofull, acting [2,0]
</span><span class='line'>recovery 7482/129081 objects degraded (5.796%)
</span><span class='line'>osd.0 is full at 95%
</span><span class='line'>osd.2 is full at 95%
</span><span class='line'>osd.1 is near full at 93%</span></code></pre></td></tr></table></div></figure>


<h2>解决方案一(已验证)</h2>

<p>增加OSD节点，这也是官方文档中推荐的做法，增加新的节点后，Ceph开始重新平衡数据，OSD使用空间开始下降</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>2015-04-29 06:51:58.623262 osd.1 [WRN] OSD near full (91%)
</span><span class='line'>2015-04-29 06:52:01.500813 osd.2 [WRN] OSD near full (92%)</span></code></pre></td></tr></table></div></figure>


<h2>解决方案二(理论上，没有进行验证)</h2>

<p>如果在没有新的硬盘的情况下，只能采用另外一种方式。在当前状态下，Ceph不允许任何的读写操作，所以此时任何的Ceph命令都不好使，解决的方案就是尝试降低Ceph对于full的比例定义，我们从上面的日志中可以看到Ceph的full的比例为95%，我们需要做的就是提高full的比例，之后尽快尝试删除数据，将比例下降。</p>

<ul>
<li>尝试直接用命令设置，但是失败了，Ceph集群并没有重新同步数据，怀疑可能仍然需要重启服务本身</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ceph mon tell \* injectargs '--mon-osd-full-ratio 0.98'</span></code></pre></td></tr></table></div></figure>


<ul>
<li>修改配置文件，之后重启monitor服务，但是担心出问题，所以没有敢尝试该方法，后续经过在邮件列表确认，该方法应该不会对数据产生影响，但是前提是在恢复期间，所有的虚拟机不要向Ceph再写入任何数据。</li>
</ul>


<p>默认情况下full的比例是95%，而near full的比例是85%，所以需要根据实际情况对该配置进行调整。</p>

<figure class='code'><figcaption><span>/etc/ceph/ceph.conf</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[global]
</span><span class='line'>    mon osd full ratio = .98
</span><span class='line'>    mon osd nearfull ratio = .80</span></code></pre></td></tr></table></div></figure>


<h2>分析总结</h2>

<h3>原因</h3>

<p>根据Ceph官方文档中的描述，当一个OSD full比例达到95%时，集群将不接受任何Ceph Client端的读写数据的请求。所以导致虚拟机在重启时，无法启动的情况。</p>

<h3>解决方法</h3>

<p>从官方的推荐来看，应该比较支持添加新的OSD的方式，当然临时的提高比例是一个解决方案，但是并不推荐，因为需要手动的删除数据去解决，而且一旦再有一个新的节点出现故障，仍然会出现比例变满的状况，所以解决之道最好是扩容。</p>

<h3>思考</h3>

<p>在这次故障过程中，有两点是值得思考的：</p>

<ul>
<li>监控：由于当时服务器在配置过程中DNS配置错误，导致监控邮件无法正常发出，从而没有收到Ceph WARN的提示信息</li>
<li>云平台本身： 由于Ceph的机制，在OpenStack平台中分配中，大多时候是超分的，从用户角度看，拷贝大量数据的行为并没有不妥之处，但是由于云平台并没有相应的预警机制，导致了该问题的发生</li>
</ul>


<h2>参考文档</h2>

<ul>
<li><a href="http://ceph.com/docs/master/rados/configuration/mon-config-ref/#storage-capacity">http://ceph.com/docs/master/rados/configuration/mon-config-ref/#storage-capacity</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[(Kilo)Devstack Kilo版本localrc推荐]]></title>
    <link href="http://xiaoquqi.github.io/blog/2015/05/11/best-localrc-for-devstack-kilo/"/>
    <updated>2015-05-11T11:33:44+08:00</updated>
    <id>http://xiaoquqi.github.io/blog/2015/05/11/best-localrc-for-devstack-kilo</id>
    <content type="html"><![CDATA[<p>Devstack在Kilo版本中发生了一些变化，其中一个commit(279cfe75198c723519f1fb361b2bff3c641c6cef)的就是优化默认启动的程序，尽量减小对硬件的要求。如果不修改默认的配置进行安装，会产生一些问题，例如VNC无法打开，Heat模块没有加载等。这里给出一个个人比较常用的localrc，供大家参考。该配置在Ubuntu 14.04 Server LTS进行了测试。</p>

<!-- more -->


<p>该配置文件中开启了所有的OpenStack的核心模块，以下几点需要注意：</p>

<ul>
<li>为了运行Neutron，服务器必须是双网卡，否则外网不会通</li>
<li>我的实验网段为200.21.0.0/16，eth0的IP为200.21.1.61，eth1与eth0为同一网段</li>
<li>eth1为公网访问网络，floating网络范围200.21.50.1/24，配置的GATEWAY为200.21.50.2</li>
<li>保证eth1所处的网段能够连接外网，但是配置为manual模式，配置如下：</li>
</ul>


<figure class='code'><figcaption><span>/etc/network/interface</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>auto eth1
</span><span class='line'>iface eth1 inet manual
</span><span class='line'>up ifconfig $IFACE 0.0.0.0 up
</span><span class='line'>down ifconfig $IFACE 0.0.0.0 down</span></code></pre></td></tr></table></div></figure>


<ul>
<li>localrc的配置</li>
</ul>


<figure class='code'><figcaption><span>localrc</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># Misc
</span><span class='line'>ADMIN_PASSWORD=sysadmin
</span><span class='line'>DATABASE_PASSWORD=$ADMIN_PASSWORD
</span><span class='line'>RABBIT_PASSWORD=$ADMIN_PASSWORD
</span><span class='line'>SERVICE_PASSWORD=$ADMIN_PASSWORD
</span><span class='line'>SERVICE_TOKEN=$ADMIN_PASSWORD
</span><span class='line'>
</span><span class='line'># Target Path
</span><span class='line'>DEST=/opt/stack.kilo
</span><span class='line'>
</span><span class='line'># Enable Logging
</span><span class='line'>LOGFILE=$DEST/logs/stack.sh.log
</span><span class='line'>VERBOSE=True
</span><span class='line'>LOG_COLOR=True
</span><span class='line'>SCREEN_LOGDIR=$DEST/logs
</span><span class='line'>
</span><span class='line'># Nova
</span><span class='line'>enable_service n-novnc n-cauth
</span><span class='line'>
</span><span class='line'># Neutron
</span><span class='line'>disable_service n-net
</span><span class='line'>ENABLED_SERVICES+=,q-svc,q-agt,q-dhcp,q-l3,q-meta,neutron
</span><span class='line'>ENABLED_SERVICES+=,q-lbaas,q-vpn,q-fwaas
</span><span class='line'>
</span><span class='line'># Ceilometer
</span><span class='line'>enable_service ceilometer-acompute ceilometer-acentral ceilometer-anotification ceilometer-collector ceilometer-api
</span><span class='line'>enable_service ceilometer-alarm-notifier ceilometer-alarm-evaluator
</span><span class='line'>
</span><span class='line'># Enable Heat
</span><span class='line'>enable_service heat h-api h-api-cfn h-api-cw h-eng
</span><span class='line'>
</span><span class='line'># Trove
</span><span class='line'>enable_service trove tr-api tr-tmgr tr-cond
</span><span class='line'>
</span><span class='line'># Sahara
</span><span class='line'>enable_service sahara
</span><span class='line'>
</span><span class='line'>#FIXED_RANGE=10.0.0.0/24
</span><span class='line'>HOST_IP=200.21.1.61
</span><span class='line'>FLOATING_RANGE=200.21.50.1/24
</span><span class='line'>PUBLIC_NETWORK_GATEWAY=200.21.50.2
</span><span class='line'>Q_FLOATING_ALLOCATION_POOL=start=200.21.50.100,end=200.21.50.150</span></code></pre></td></tr></table></div></figure>


<ul>
<li>确认br-ex是否存在</li>
</ul>


<figure class='code'><figcaption><span>sudo ovs-vsctl show</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Bridge br-ex
</span><span class='line'>    Port br-ex
</span><span class='line'>        Interface br-ex
</span><span class='line'>            type: internal
</span><span class='line'>    Port "qg-7ec5be02-69"
</span><span class='line'>        Interface "qg-7ec5be02-69"
</span><span class='line'>            type: internal
</span><span class='line'>ovs_version: "2.0.2"</span></code></pre></td></tr></table></div></figure>


<ul>
<li>将eth1作为br-ex的接口</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>sudo ovs-vsctl add-port br-ex eth1
</span></code></pre></td></tr></table></div></figure>




<figure class='code'><figcaption><span>sudo ovs-vsctl show</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Bridge br-ex
</span><span class='line'>    Port br-ex
</span><span class='line'>        Interface br-ex
</span><span class='line'>            type: internal
</span><span class='line'>    Port "qg-7ec5be02-69"
</span><span class='line'>        Interface "qg-7ec5be02-69"
</span><span class='line'>            type: internal
</span><span class='line'>    Port "eth1"
</span><span class='line'>        Interface "eth1"
</span><span class='line'>ovs_version: "2.0.2"</span></code></pre></td></tr></table></div></figure>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[OpenStack Kilo版本新功能分析]]></title>
    <link href="http://xiaoquqi.github.io/blog/2015/05/04/what-is-new-in-kilo/"/>
    <updated>2015-05-04T10:37:22+08:00</updated>
    <id>http://xiaoquqi.github.io/blog/2015/05/04/what-is-new-in-kilo</id>
    <content type="html"><![CDATA[<p>OpenStack Kilo版本已经于2015年4月30日正式Release，这是OpenStack第11个版本，距离OpenStack项目推出已经整整过去了5年多的时间。在这个阶段OpenStack得到不断的增强，同时OpenStack社区也成为即Linux之后的第二大开源社区，参与的人数、厂商众多，也成就了OpenStack今天盛世的局面。虽然OpenStack在今年经历了Nebula的倒闭，但是随着国内的传统行业用户对OpenStack越来越重视，我们坚信OpenStack明天会更好。</p>

<p>OpenStack Kilo版本的完整翻译版本可见：<a href="https://wiki.openstack.org/wiki/ReleaseNotes/Kilo/zh-hans">https://wiki.openstack.org/wiki/ReleaseNotes/Kilo/zh-hans</a></p>

<p>OpenStack Kilo版本的翻译工作由我和我的同事裴莹莹(Wendy)共同完成，翻译校对工作由裴莹莹完成。如果翻译有任何问题，请各位多多指正。</p>

<!-- more -->


<h2>社区贡献分析</h2>

<p>我们先来看一下OpenStack在最近的4个稳定版本发布中，每一个项目的贡献情况：</p>

<p><img class="left" src="http://xiaoquqi.github.io/images/blogs/what-is-new-in-kilo-contribution-by-modules.jpg"></p>

<p>我们能够很明显的发现，OpenStack最早的几大核心模块(Nova, Cinder, Glance, Keystone, Horizon, Swift)的代码贡献所占比例呈明显下降趋势，这里强调一下，是比例而不是数量，从数量上来看，版本之间相差并不大，以Nova为例，从Havana版本的24%下降到如今的10%。这从一个侧面反映了OpenStack的核心模块日趋稳定，更多的关注集中到更高层次或者功能优化上。</p>

<p>Neutron模块则一直处于稳中有升的状态,从Havana版本的7%上升到10%，说明Neutron仍然处于需要进一步完善的状态。</p>

<p>对于Ceilometer，Heat，Sahara，Ironic, Trove等新晋的核心模块，都处于稳步增长的阶段。贡献的比例在四个版本中基本保持持平的态势。在Kilo版本中，Sahara和Heat进入了前十名。</p>

<p>从Kilo版本的比例来看，Others的比例过半，Others主要包括了OpenStack测试相关项目，例如Rally；开发相关项目，例如Devstack;以及一些新的模块，例如：Manila，Magnum等众多进入孵化器的项目;还包括所有的Client以及Spec等。可以预见，OpenStack的开发重心逐步从底层的核心模块，逐步向更高层次、提供更丰富功能的方向发展。</p>

<h2>国内社区贡献分析</h2>

<p><img class="center" src="http://xiaoquqi.github.io/images/blogs/what-is-new-in-kilo-contributor.png"></p>

<p>从企业贡献排名来看，几大巨头企业牢牢占据贡献榜的前几名，OpenStack最成功的公司-Mirantis排名紧追Redhat成为第二贡献大户。排名前几位的公司还包括：IBM, Rackspace, Cisco, Suse, VMware, Intel等。</p>

<p>国内方面，华为继续稳定在第13名，但Review的数量从Juno版本的1353提升到2548个，贡献的项目几乎涵盖所有的项目，主要贡献来自Heat，Ceilometer, Horizon，Neutron, Nova等项目。</p>

<p>国内排名第2的贡献企业是九州云，排名达到了21位，看来龚永生的到来为九州云添加了无限活力。九州云的贡献主要来自Horizon和Neutron两个项目，龚永生不愧为Neutron的Core，在网络方面的贡献，九州云的确很给力。</p>

<p>排名第3的企业是海云捷迅，排名为44位，海云是国内比较早的一批OpenStack创业企业，贡献方面以Sahara，Neutron，Nova，oslo.messaging以及Cinder为主，从之前了解的情况来看，海云的项目不少，可能提交的修改是与在实际项目中遇到的问题有关。</p>

<p>排名之后的企业还有Kylin Cloud，UnitedStack，EasyStack等。由于是手工统计，在统计过程中如有遗漏，希望大家多多指正。</p>

<h2>Horizon新功能</h2>

<p>Horizon在K版本除了增强了对新增模块的支持，从UE的角度也为我们带来了很多新功能</p>

<ul>
<li>支持向导式的创建虚拟机，现在还处于beta版本，如果想在Horizon里激活，可以通过设置local_setting.py的配置实现：</li>
</ul>


<figure class='code'><figcaption><span>local_setting.py</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>LAUNCH_INSTANCE_NG_ENABLED = True</span></code></pre></td></tr></table></div></figure>


<p><img class="left" src="http://xiaoquqi.github.io/images/blogs/what-is-new-in-kilo-instance-guide1.png"></p>

<p><img class="left" src="http://xiaoquqi.github.io/images/blogs/what-is-new-in-kilo-instance-guide2.png"></p>

<ul>
<li>支持简单的主题，主要通过修改<em>variables.scss和</em>style.scss完成对主题颜色和简单样式的修改，但是格局不能改变，修改local_settings.py</li>
</ul>


<figure class='code'><figcaption><span>local_setting.py</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>CUSTOM_THEME_PATH = 'static/themes/blue'</span></code></pre></td></tr></table></div></figure>




<figure class='code'><figcaption><span>static/themes/blue/_variables.scss</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$gray:                   #2751DB !default;
</span><span class='line'>$gray-darker:            #94A5F2 !default;
</span><span class='line'>$gray-dark:              #0C0CED !default;
</span><span class='line'>$gray-light:             #C7CFF2 !default;
</span><span class='line'>$gray-lighter:           #DCE1F5 !default;
</span><span class='line'>
</span><span class='line'>$brand-primary:         #375A7F !default;
</span><span class='line'>$brand-success:         #00bc8c !default;
</span><span class='line'>$brand-info:            #34DB98 !default;
</span><span class='line'>$brand-warning:         #F39C12 !default;
</span><span class='line'>$brand-danger:          #E74C3C !default;</span></code></pre></td></tr></table></div></figure>




<figure class='code'><figcaption><span>static/themes/blue/_style.scss</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>// Blue
</span><span class='line'>// ----
</span><span class='line'>
</span><span class='line'>@mixin btn-shadow($color) {
</span><span class='line'>  @include gradient-vertical-three-colors(lighten($color, 3%), $color, 6%, darken($color, 3%));
</span><span class='line'>  filter: none;
</span><span class='line'>  border: 1px solid darken($color, 10%);
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>// Buttons ====================================================================
</span><span class='line'>
</span><span class='line'>.btn-default,
</span><span class='line'>.btn-default:hover {
</span><span class='line'>  @include btn-shadow($btn-default-bg);
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>.btn-primary,
</span><span class='line'>.btn-primary:hover {
</span><span class='line'>  @include btn-shadow($btn-primary-bg);
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p><img class="left" src="http://xiaoquqi.github.io/images/blogs/what-is-new-in-kilo-horizon-theme1.png"></p>

<p><img class="left" src="http://xiaoquqi.github.io/images/blogs/what-is-new-in-kilo-horizon-theme2.png"></p>

<h2>Nova新功能</h2>

<h3>Nova Scheduler</h3>

<ul>
<li>标准化了conductor，compute与scheduler的接口，为之后的接口分离做好准备，对于部分直接访问nova数据库的filters进行了优化，不再允许直接访问，参考链接：<a href="https://github.com/openstack/nova-specs/blob/master/specs/kilo/approved/isolate-scheduler-db-filters.rst">https://github.com/openstack/nova-specs/blob/master/specs/kilo/approved/isolate-scheduler-db-filters.rst</a></li>
<li>对Scheduler做了一些优化，例如：Scheduler对于每一个请求都会重新进行Filters/Weighers，为了优化这个问题，将filter/weighter的初始化从handler移到scheduler，这样每次请求的时候都可以重新使用了。</li>
</ul>


<h3>Libvirt NFV相关功能</h3>

<ul>
<li>NUMA(Non Uniform Memory Architecture)，在这个架构下，每个处理器都会访问“本地”的内存池，从而在CPU和存储之间有更小的延迟和更大的带宽。</li>
<li>在Kilo版本中针对此功能的实现包括：基于NUMA的调度的实现；可以将vCPU绑定在物理CPU上；超大页的支持。以上提到的三点都是通过Flavor的Extra Spces完成定义的。</li>
</ul>


<h3>EC2 API</h3>

<ul>
<li>EC2 API被从Nova中踢出去了</li>
<li>取而代之的是在stackforge的EC2 API转换服务</li>
</ul>


<h3>API Microversioning</h3>

<p>先来解释一下为什么需要API的微版本：主要原因在于现在这种API扩展方式，对于API实现的代码的增加或减少管理非常不方便，容易导致不一致性。引入微版本主要目的就是让开发人员在修改API代码时能够向前兼容，而不是加入一个新的API扩展；用户通过指定API的版本，在请求时也能决定是使用的具体的动作。</p>

<p>包含版本的返回:</p>

<figure class='code'><figcaption><span>Result</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>GET /
</span><span class='line'>{
</span><span class='line'>     "versions": [
</span><span class='line'>        {
</span><span class='line'>            "id": "v2.1",
</span><span class='line'>            "links": [
</span><span class='line'>                  {
</span><span class='line'>                    "href": "http://localhost:8774/v2/",
</span><span class='line'>                    "rel": "self"
</span><span class='line'>                }
</span><span class='line'>            ],
</span><span class='line'>            "status": "CURRENT",
</span><span class='line'>            "version": "5.2"
</span><span class='line'>            "min_version": "2.1"
</span><span class='line'>        },
</span><span class='line'>   ]
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>客户端的Header信息：</p>

<figure class='code'><figcaption><span>Header</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>X-OpenStack-Nova-API-Version: 2.114</span></code></pre></td></tr></table></div></figure>


<h3>一个已知的问题：Evacuate</h3>

<p>这个问题的产生主要是因为Evacuate的清理机制，主机名的变化会导致nova-compute重启过程中误删所有虚拟机，所以一个变通的方法是设置</p>

<figure class='code'><figcaption><span>nova.conf</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>destroy_after_evacuate=False</span></code></pre></td></tr></table></div></figure>


<p>这个问题会在Liberty中得到修复，相关的Spec：<a href="https://review.openstack.org/#/c/161444/3/specs/liberty/approved/robustify_evacuate.rst">https://review.openstack.org/#/c/161444/3/specs/liberty/approved/robustify_evacuate.rst</a></p>

<h2>Glance新功能</h2>

<ul>
<li>自动进行镜像格式转化，例如，Ceph是使用RAW格式的，假如我们上传的是QCOW2，创建虚拟机时，就会经历一番上传下载的过程，速度异常缓慢。而且RAW格式通常都是原始大小，上传时候非常慢，完全可以通过上传小镜像自动转换为指定格式。</li>
<li>Glance支持多字段排序</li>
</ul>


<figure class='code'><figcaption><span>API</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>/images?sort_key=status&sort_dir=asc&sort_key=name&sort_dir=asc&sort_key=created_at&sort_dir=desc</span></code></pre></td></tr></table></div></figure>


<ul>
<li>临时将镜像设置为非活跃状态，假如一个镜像里有病毒，管理员就会将该镜像设置为非活跃状态，在清理后重新发布该镜像，在这个过程中，所有非管理员用户都无法使用或者下载这个镜像</li>
<li>免重启动态加载配置文件，配置文件改动后重启服务，现在可以给glance服务发送SIGHUP触发，这样升级就可以零当机时间。</li>
<li>使用多个Swift容器存储镜像，减少大规模部署时的请求瓶颈</li>
</ul>


<h2>Cinder新功能</h2>

<ul>
<li>实现服务逻辑代码与数据库结构之间的解耦，支持Rolling更新</li>
<li>一致性组是指具备公共操作的卷，逻辑上化为一组。在K版本中对增强一致性组的功能：可以添加、删除卷，从已经存在的快照创建新的组，关于一致性组的详细操作可以参考：<a href="http://docs.openstack.org/admin-guide-cloud/content/consistency-groups.html">http://docs.openstack.org/admin-guide-cloud/content/consistency-groups.html</a></li>
</ul>


<figure class='code'><figcaption><span>cinder</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cinder consisgroup-update
</span><span class='line'>[--name NAME]
</span><span class='line'>[--description DESCRIPTION]
</span><span class='line'>[--add-volumes UUID1,UUID2,......]
</span><span class='line'>[--remove-volumes UUID3,UUID4,......]
</span><span class='line'>CG</span></code></pre></td></tr></table></div></figure>




<figure class='code'><figcaption><span>cinder</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cinder consisgroup-create-from-src
</span><span class='line'>[--cgsnapshot CGSNAPSHOT]
</span><span class='line'>[--name NAME]
</span><span class='line'>[--description DESCRIPTION]</span></code></pre></td></tr></table></div></figure>


<ul>
<li>卷类型的增强功能主要包含两个：为某一项目创建私有的卷类型和为卷类型增加描述信息</li>
</ul>


<figure class='code'><figcaption><span>cinder</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cinder type-create &lt;name&gt; --is-public
</span><span class='line'>cinder type-create &lt;name&gt; &lt;description&gt;</span></code></pre></td></tr></table></div></figure>


<h2>Neutron新功能</h2>

<ul>
<li>DVR支持OVS中的VLANs</li>
<li>新的V2版本的LBaas的API</li>
<li>新的插件的更新，详情请见更新日志中</li>
<li>一些高级服务的分离，例如：L3, ML2, VPNaaS, LBaaS</li>
</ul>


<p>网络方面我不是权威，希望有高人能出来讲讲Kilo中的Neutron新功能。</p>

<h2>Keystone新功能</h2>

<ul>
<li>项目嵌套，创建一个新的Project时候，可以指定parent的Project</li>
</ul>


<figure class='code'><figcaption><span>keystone</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>POST /projects
</span><span class='line'>
</span><span class='line'>{
</span><span class='line'>    "project": {
</span><span class='line'>        "description": "Project space for Test Group",
</span><span class='line'>        "domain_id": "1789d1",
</span><span class='line'>        "enabled": true,
</span><span class='line'>        "name": "Test Group",
</span><span class='line'>        "parent_id": "7fa612"
</span><span class='line'>    }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<ul>
<li>Keystone与Keystone的联盟，有了这个功能两个或者更多的云服务提供者就可以共享资源，这个功能在J版本引入，在K版本中主要针对该功能的进一步增强，具体的使用方法可参考这篇博文：<a href="http://blog.rodrigods.com/playing-with-keystone-to-keystone-federation/">http://blog.rodrigods.com/playing-with-keystone-to-keystone-federation/</a></li>
<li>针对新人授权的一些增强功能</li>
<li>keystone的配置中有部分配置发生了变化，例如：keystone.token.backends.memcache被keystone.token.persistence.backends.memcache取代，更多详细内容请参考更新日志</li>
</ul>


<h2>Swift新功能</h2>

<ul>
<li>纠删码的加入应该是这个版本最大的亮点，但是纠删码作为beta版本发布，并不推荐应用于生产环境，关于纠删码的详细介绍可以参考：<a href="http://docs.openstack.org/developer/swift/overview_erasure_code.html">http://docs.openstack.org/developer/swift/overview_erasure_code.html</a></li>
<li>复合型令牌，简而言之就是需要用户加上服务的Token才能对Swfit存放的内容进行操作，如下图所示：</li>
</ul>


<figure class='code'><figcaption><span>swift</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>client
</span><span class='line'>   \
</span><span class='line'>    \   &lt;request&gt;: &lt;path-specific-to-the-service&gt;
</span><span class='line'>     \  x-auth-token: &lt;user-token&gt;
</span><span class='line'>      \
</span><span class='line'>    SERVICE
</span><span class='line'>       \
</span><span class='line'>        \    PUT: /v1/SERVICE_1234/&lt;container&gt;/&lt;object&gt;
</span><span class='line'>         \   x-auth-token: &lt;user-token&gt;
</span><span class='line'>          \  x-service-token: &lt;service-token&gt;
</span><span class='line'>           \
</span><span class='line'>          Swift</span></code></pre></td></tr></table></div></figure>


<p>具体的设计文档：<a href="http://docs.openstack.org/developer/swift/overview_backing_store.html">http://docs.openstack.org/developer/swift/overview_backing_store.html</a></p>

<ul>
<li>全局性的集群复制优化，大幅提高效率，避免经过广域网传播的数据</li>
</ul>


<h2>Ceilometer新功能</h2>

<ul>
<li>支持Ceph对象存储监控，当对象存储为Ceph而不是Swfit的时候，使用Polling机制，使用Ceph的Rados Gateway的API接口获取数据，具体的设计文档：<a href="https://github.com/openstack/ceilometer-specs/blob/master/specs/kilo/ceilometer_ceph_integration.rst">https://github.com/openstack/ceilometer-specs/blob/master/specs/kilo/ceilometer_ceph_integration.rst</a></li>
<li>Ceilometer API RBAC - 更细粒度的权限控制: <a href="https://github.com/openstack/ceilometer-specs/blob/master/specs/kilo/ceilometer-rbac.rst">https://github.com/openstack/ceilometer-specs/blob/master/specs/kilo/ceilometer-rbac.rst</a></li>
</ul>


<figure class='code'><figcaption><span>Ceilometer</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>    "context_is_admin": [["role:admin"]]
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>更细粒度的控制</p>

<figure class='code'><figcaption><span>Ceilometer</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>     "context_is_admin": [["role:admin"]],
</span><span class='line'>     "admin_or_cloud_admin": [["rule:context_is_admin"],
</span><span class='line'>              ["rule:admin_and_matching_project_domain_id"]],
</span><span class='line'>     "telemetry:alarm_delete": [["rule:admin_or_cloud_admin"]]
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<ul>
<li>接口中的模糊查询，增加了一个新的查询符号=~</li>
<li>支持更多的测量，包括Hyper-V，IPMI相关的</li>
</ul>


<h2>Ironic新功能</h2>

<ul>
<li>iLO的优化</li>
<li>使用Config Drive替代Metadata服务</li>
<li>全盘镜像支持，可以跳过raddisk和kernel，这样就可以部署Windows的镜像了</li>
<li>使用本地盘启动，替代PXE方式，可以通过设置flavor的capabilities:boot_option实现</li>
</ul>


<h2>Oslo</h2>

<p>解决了很多之前遗留的技术债，还有一些命名规范的问题。olso.messaging实现了心跳，olso.log在所有项目中使用，优化了oslo.db的代码。</p>

<h2>OpenStack文档</h2>

<p>优化了docs.openstack.org页面，也可以从中选择相应的语言。有专门的团队负责安装、网络和高可靠的文档。</p>

<h2>其他模块</h2>

<p>对于Sahara, Heat, Trove等模块的更新没有在这里Highlight出来，大家可以参考更新日志里的内容，或者查看specs中的具体描述。</p>

<h2>总结</h2>

<p>通过Kilo的一些更新可以看到，Kilo版本在不断优化代码结构的基础上，增加了一些新功能，也偿还了一些技术债，总体来说是一种稳中有升的态势，但是总体感觉并没有太多的惊喜和出人意料。相信随着更多的孵化项目进入正式版本中，OpenStack一定会向更多元化的方向发展。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[(Havana)将OpenStack Havana源代码编译为DEB包]]></title>
    <link href="http://xiaoquqi.github.io/blog/2015/03/05/build-openstack-source-code-to-deb-package/"/>
    <updated>2015-03-05T21:57:16+08:00</updated>
    <id>http://xiaoquqi.github.io/blog/2015/03/05/build-openstack-source-code-to-deb-package</id>
    <content type="html"><![CDATA[<h2>Why</h2>

<p>我想有以下有几个原因促使我写这篇Blog：</p>

<ul>
<li>很多人开始OpenStack之旅是从Ubuntu开始，但是却没有一篇文章系统的介绍如何将修改后的代码重新编译回DEB包。</li>
<li>如果我们采用源代码直接安装的方式对OpenStack模块进行管理，一致性很难保证，难以维护。</li>
<li>Debian类系统的打包看起来比RPM包复杂很多。</li>
</ul>


<h2>Who</h2>

<p>谁需要看这篇文章呢？</p>

<ul>
<li>不了解如何编译DEB包</li>
<li>想把修改过的OpenStack源代码重新发布，供内部使用</li>
<li>希望改变直接维护源代码</li>
</ul>


<p>当然，如果您已经是这方面的高手，欢迎给我指正我Blog中的不足，十分感谢。</p>

<!-- more -->


<h2>Quick Start</h2>

<p>我已经将整个的编译过程集成在Vagrant脚本中，你可以直接安装Vagrant后，下载我的源代码，启动后就能看到整个的编译过程。</p>

<p>Vagrant 版本要求为1.3.5，Virtualbox版本要求为4.1或者4.2均可。</p>

<h2>Let&rsquo;s play some magic</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>git clone https://github.com/xiaoquqi/vagrant-build-openstack-deb
</span><span class='line'>cd vagrant-build-openstack-deb
</span><span class='line'>vagrant up</span></code></pre></td></tr></table></div></figure>


<p>虚拟机启动后，将会自动从github(这里使用的是csdn code的镜像代码)同步最新代码，然后使用编译脚本，执行打包操作。如果不考虑下载的时间，整个过程大概持续5分钟左右的时间，编译好的Deb包将会存放在/root/build目录下。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>vagrant ssh</span></code></pre></td></tr></table></div></figure>


<p>即可登陆到虚拟机，切换到root目录就可以查看到所有打包好的DEB的情况了，当然你也可以直接使用dpkg -i命令进行安装。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo -s
</span><span class='line'>cd /root/build
</span><span class='line'>ls -lrt *.deb
</span><span class='line'>dpkg -i python-glance_2013.2.2.dev1.g5cd7a22~precise-0ubuntu1_all.deb</span></code></pre></td></tr></table></div></figure>


<h2>Step by Step</h2>

<p>看过了整个的编译过程，下面来介绍一点点细节。</p>

<p>全部的编译部分代码都在这个文件中：<a href="https://github.com/xiaoquqi/vagrant-build-openstack-deb/blob/master/scripts/build.sh">https://github.com/xiaoquqi/vagrant-build-openstack-deb/blob/master/scripts/build.sh</a></p>

<p>下面让我们来仔细分析一下整个编译过程。</p>

<ul>
<li>添加必要的源</li>
</ul>


<p>这里面我们用的源包含sohu的Ubuntu 12.04源以及Ubuntu的Havana源</p>

<pre><code>deb http://mirrors.sohu.com/ubuntu/ precise main restricted
deb http://mirrors.sohu.com/ubuntu/ precise-updates main restricted
deb http://mirrors.sohu.com/ubuntu/ precise universe
deb http://mirrors.sohu.com/ubuntu/ precise-updates universe
deb http://mirrors.sohu.com/ubuntu/ precise multiverse
deb http://mirrors.sohu.com/ubuntu/ precise-updates multiverse
deb http://mirrors.sohu.com/ubuntu/ precise-backports main restricted universe multiverse
deb http://mirrors.sohu.com/ubuntu/ precise-security main restricted
deb http://mirrors.sohu.com/ubuntu/ precise-security universe
deb http://mirrors.sohu.com/ubuntu/ precise-security multiverse
deb http://ubuntu-cloud.archive.canonical.com/ubuntu precise-updates/havana main
</code></pre>

<ul>
<li>安装必要的编译软件</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>apt-get install -y debootstrap equivs schroot
</span><span class='line'>apt-get install -y devscripts
</span><span class='line'>apt-get install -y build-essential checkinstall sbuild
</span><span class='line'>apt-get install -y dh-make
</span><span class='line'>apt-get install -y bzr bzr-builddeb
</span><span class='line'>apt-get install -y git
</span><span class='line'>apt-get install -y python-setuptools</span></code></pre></td></tr></table></div></figure>


<ul>
<li>编译脚本的源代码仓库</li>
</ul>


<p>Ubuntu维护源代码编译脚本是使用叫做bzr的工具，常使用Launchpad的朋友应该比较熟悉，这是一套类似于git的分布式管理工具，不同的是这是一套完全用python语言实现的管理工具，不仅具有代码版本控制功能并且与Launchpad高度整合，作为Ubuntu维护不可缺少的重要工具之一。例如，这里面用到的glance编译脚本就可以在这里找到：</p>

<p><a href="https://code.launchpad.net/~ubuntu-server-dev/glance/havana">https://code.launchpad.net/~ubuntu-server-dev/glance/havana</a></p>

<p>页面上方有下载代码的方式：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>bzr branch lp:~ubuntu-server-dev/glance/havana
</span><span class='line'>git clone https://code.csdn.net/openstack/glance.git --branch "stable/havana" glance_source</span></code></pre></td></tr></table></div></figure>


<ul>
<li>准备环境</li>
</ul>


<p>在Vagrant启动一台新虚拟机之后，并没有pip，如果不安装pip，则会在python setup.py sdist过程中，把pip安装到源代码目录中，引起Build失败。将//vagrant/pip/pip-1.4.1.tar.gz解压缩并安装，之后安装pbr：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>tar zxvf pip-1.4.1.tar.gz
</span><span class='line'>cd pip-1.4.1
</span><span class='line'>sudo python setup.py install
</span><span class='line'>sudo pip install pbr</span></code></pre></td></tr></table></div></figure>


<ul>
<li>生成source文件</li>
</ul>


<p>进入glance_source目录，执行</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>python setup.py sdist</span></code></pre></td></tr></table></div></figure>


<p>生成的tar.gz文件会在glance_source/dist下，注意此时该文件的名称为：</p>

<pre><code>glance-2013.2.2.dev1.g5cd7a22.tar.gz
</code></pre>

<p>接下来我们需要将该文件重命名为：</p>

<pre><code>glance_2013.2.2.dev1.g5cd7a22~precise.orig.tar.gz
</code></pre>

<p>特别注意：glance后面已经变为下划线！！！</p>

<p>把文件移动到与glance和glance_source同一级别的目录，这样在编译的时候，才能找到source文件。此时的目录结构为：</p>

<pre><code>├── glance
│   ├── debian
├── glance_source
├── glance_2013.2.2.dev1.g5cd7a22~precise.orig.tar.gz
</code></pre>

<ul>
<li>安装依赖包</li>
</ul>


<p>为了保证顺利的完成编译，我们需要安装要编译包的所有依赖包，简单来说就是glance/debian/control文件中定义的Depends部分的内容。当然在编译的时候我们也可以完全忽略依赖，但是并不推荐。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>mk-build-deps -i -t 'apt-get -y' debian/control</span></code></pre></td></tr></table></div></figure>


<p>这样系统就会自动安装所有依赖包，并且生成一个glance-build-deps_1.0_all.deb文件。</p>

<ul>
<li>生成日志信息</li>
</ul>


<p>开始编译前，我们还需要告诉编译器我们要编译的版本，还记得刚才生成的dist包吗，把那个版本拿出来作为我们commit的版本。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cd glance
</span><span class='line'>dch -b -D precise --newversion "1:2013.2.2.dev1.g5cd7a22~precise-0ubuntu1" 'This is a build test.'
</span><span class='line'>debcommit</span></code></pre></td></tr></table></div></figure>


<p>这样在glance/debian/changelog中就会增加一条新的日志。</p>

<ul>
<li>开始编译</li>
</ul>


<p>万事俱备，只欠东风。我们利用bzr提供的builddeb开始编译，这里我们忽略签名问题。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>cd glance
</span><span class='line'>bzr builddeb -- -sa -us -uc</span></code></pre></td></tr></table></div></figure>


<p>大功告成啦。快去/root/build/glance下看看你的deb包吧。</p>

<h2>总结</h2>

<p>Debian包的编译的确涉及很多知识点，而且可使用的编译工具很多，关系很复杂。这篇博文，只为了帮助大家对DEB包的编译有一个快速的认识，如果想了解更多关于编译的知识，请关注后续的博文。</p>

<p>最后，我们仍然希望有更多的热爱OpenStack的朋友们加入我们公司，如果有意向的请与我联系</p>

<ul>
<li>邮箱：<a href="&#109;&#x61;&#x69;&#x6c;&#x74;&#x6f;&#58;&#120;&#x69;&#97;&#111;&#113;&#117;&#x71;&#x69;&#64;&#x67;&#x6d;&#x61;&#105;&#x6c;&#46;&#99;&#111;&#x6d;">&#x78;&#105;&#97;&#x6f;&#113;&#x75;&#113;&#x69;&#64;&#x67;&#x6d;&#x61;&#x69;&#x6c;&#46;&#99;&#111;&#109;</a></li>
<li>新浪微博：@RaySun(<a href="http://weibo.com/xiaoquqi">http://weibo.com/xiaoquqi</a>)</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[(Juno)OpenStack Neutron L3高可靠]]></title>
    <link href="http://xiaoquqi.github.io/blog/2015/03/05/openstack-neutron-l3-high-availability/"/>
    <updated>2015-03-05T20:53:57+08:00</updated>
    <id>http://xiaoquqi.github.io/blog/2015/03/05/openstack-neutron-l3-high-availability</id>
    <content type="html"><![CDATA[<h2>L3层Agent的低可靠解决方案</h2>

<p>当前，你可以通过多网络节点的方式解决负载分担，但是这并非高可靠和冗余的解决方案。假设你有三个网络节点，当你创建新的路由时，会自动的将新路由规划和分布在这三个网络节点中的一个上。但是，如果一个节点坏掉，上面运行的所有路由将无法提供服务，路由转发也无法正常进行。在Neutron的IceHouse版本中，没有提供任何内置的解决方案。</p>

<!-- more -->


<h2>DHCP Agent的高可靠的变通之道</h2>

<p>DHCP的Agent是一个另类——DHCP协议本身就支持在同一个资源池内同时使用多个DHCP提供服务。</p>

<p>在neutron.conf中仅仅需要改变：</p>

<pre><code>dhcp_agents_per_network = X
</code></pre>

<p>这样DHCP的调度程序会为同一网络启动X个DHCP Agents。所以，对于三个网络节点，并设置dhcp_agents_per_network = 2，每个Neutron网络会在三个节点中启动两个DHCP Agents。这个是如何工作的呢？</p>

<p><img class="right" src="http://xiaoquqi.github.io/images/blogs/neutron-l3-ha-dhcp-ha.png" width="200" height="300"></p>

<p>首先，让我们来看一下物理层面的实现。当一台主机连接到子网10.0.0.0/24，会发出DHCP Discover广播包。两个DHCP服务进程dnsmasq1和dnsmasq2(或者其他的DHCP服务)收到广播包，并回复10.0.0.2。假设第一个DHCP服务响应了服务器请求，并将10.0.0.2的请求广播出去，并且指明提供IP的是dnsmasq1-10.0.0.253。所有服务都会接收到广播，但是只有dnsmasq1会回复ACK。由于所有DHCP通讯都是基于广播，第二个DHCP服务也会收到ACK，于是将10.0.0.2标记已经被AA:BB:CC:11:22:33获取，而不会提供给其他的主机。总结一下，所有客户端与服务端的通讯都是基于广播，因此状态(IP地址什么时候被分配，被分配给谁)可以被所有分布的节点正确获知。</p>

<p>在Neutron中，分配MAC地址与IP地址的关系，是在每个dnsmasq服务之前完成的，也就是当Neutron创建Port时。因此，在DHCP请求广播之前，所有两个dnsmasq服务已经在leases文件中获知了，AA:BB:CC:11:22:33应该分配10.0.0.2的映射关系。</p>

<h2>回到L3 Agent的低可用</h2>

<p>L3 Agent，没有(至少现在没有)提供任何DHCP所能提供的高可靠解决方案，但是用户的确很需要高可靠。怎么办呢？</p>

<p>Pacemaker/Corosync - 使用外部的集群管理技术，为Active节点指定一个Standby的网络节点。Standby节点在正常情况下等呀、等呀等，一旦Active节点发生故障，L3 Agent立即在Standby节点启动。这两个节点配置相同的主机名，当Standby的Agent出台并和服务之前开始同步后，它自己的ID不会改变，因此就像管理同一个router一样。</p>

<p>另外一个方案是采用定时同步的方式(cron job)。用Python SDK开发一段脚本，使用API获取所有已经故去的Agent们，之后获取所有上面承载的路由，并且把他们重新分配给其他的Agent。</p>

<p>在Juno开发过程中，查看Kevin Benton的这个Patch，让Neutron自己具备重新分配路由的功能: <a href="https://review.openstack.org/#/c/110893/">https://review.openstack.org/#/c/110893/</a></p>

<h2>重新分配路由——路漫漫兮</h2>

<p>以上列出的解决方案，实质上都有从失败到恢复的时间，如果在简单的应用场景下，恢复一定数量的路由到新节点并不算慢。但是想象一下，如果有上千个路由就需要话费数个小时完成，重新分配和配置的过程。人们非常需要快速的故障恢复！</p>

<h2>分布式虚拟路由(Distributed Virtual Router)</h2>

<p>这里有一些文档描述DVR是如何工作的：</p>

<ul>
<li><a href="http://specs.openstack.org/openstack/neutron-specs/specs/juno/neutron-ovs-dvr.html">http://specs.openstack.org/openstack/neutron-specs/specs/juno/neutron-ovs-dvr.html</a></li>
<li><a href="https://docs.google.com/document/d/1jCmraZGirmXq5V1MtRqhjdZCbUfiwBhRkUjDXGt5QUQ/">https://docs.google.com/document/d/1jCmraZGirmXq5V1MtRqhjdZCbUfiwBhRkUjDXGt5QUQ/</a></li>
<li><a href="https://docs.google.com/document/d/1depasJSnGZPOnRLxEC_PYsVLcGVFXZLqP52RFTe21BE/">https://docs.google.com/document/d/1depasJSnGZPOnRLxEC_PYsVLcGVFXZLqP52RFTe21BE/</a></li>
</ul>


<p>这里的要点是将路由放到计算节点(compute nodes)，这让网络节点的L3 Agent变得没用了。是不是这样呢？</p>

<ul>
<li>DVR主要处理Floating IPs，把SNAT留给网络节点的L3 Agent</li>
<li>不和VLANs一起工作，仅仅支持tunnes和L2pop开启</li>
<li>每个计算节点需要连接外网</li>
<li>L3 HA是对部署的一种简化，这个基于Havana和Icehouse版本部署的云平台所不具备的</li>
</ul>


<p>理想情况下，你想把DVR和L3 HA一起使用。Floating IP的流量会从你的计算节点直接路由出去，而SNAT的流量还是会从你的计算节点HA集群的L3 Agent进行转发。</p>

<h2>3层高可靠</h2>

<p>Juno版本的L3的HA解决方案应用了Linux上流行的keepalived工具，在内部使用了VRRP。首先，我们先来讨论一下VRRP。</p>

<h2>什么是VRRP，如何在真实世界里工作</h2>

<p>虚拟路由冗余协议(Virtual Router Redundancy Protocol)是一个第一条冗余协议——目的是为了提供一个网络默认网关的高可靠，或者是路由的下一跳的高可靠。那它解决了什么问题呢？在一个网络拓扑中，有两个路由提供网络连接，你可以将网络的默认路由配置为第一个路由地址，另外一个配置成第二个。</p>

<p><img class="left" src="http://xiaoquqi.github.io/images/blogs/neutron-l3-ha-router_ha-topology-before-vrrp.png" width="200" height="300"></p>

<p><img class="left" src="http://xiaoquqi.github.io/images/blogs/neutron-l3-ha-switch-moves-mac.png" width="200" height="300"></p>

<p>这样将提供负载分担，但是如果其中一个路由失去了连接，会发生什么呢？这里一个想法就是虚拟IP地址，或者一个浮动的地址，配置为网络默认的网管地址。当发生错误时，Standby的路由并不会收到从Master节点发出的VRRP Hello信息，并且这将触发选举程序，获胜的成为Active网管，另外一个仍然作为Standby。Active路由配置虚拟IP地址(简写VIP)，内部的局域网接口，回复ARP请求时会附加虚拟的MAC地址。由于在该网络内的计算机已经拥有了ARP缓存(VIP+虚拟机MAC地址)，也就没有必要重新发送ARP请求了。依据选举机制，有效的Standby路由变为Active，并且发送一个非必要的ARP请求——来向网络中声明当前的VIP+MAC对已经属于它了。这个切换，包含了网络中将虚拟机MAC地址从旧的迁移到新的。</p>

<p>为了实现这一点，指向默认网关的流量会从当前的(新的)Active路由经过。注意这个解决方案中并没有实现负载分担，这种情况下，所有的流量都是从Active路由转发的。(注意：在Neutron的用户使用场景中，负载分担并没有在单独的路由级别完成，而是在节点(Node)级别，也就是要有一定数量的路由)。那么如何在路由层面实现负载分担呢？VRRP组：VRRP的投中包含虚拟机路由识别码(Virtual Router Identifier)，也就是VRID。网络中一半的主机配置为第一个VIP，另外一个使用第二个。在失败的场景下，VIP会从失败的路由转移到另外一个。</p>

<p><img class="left" src="http://xiaoquqi.github.io/images/blogs/neutron-l3-ha-router-ha-two-vrrp-groups.png" width="200" height="300"></p>

<p><img class="left" src="http://xiaoquqi.github.io/images/blogs/neutron-l3-ha-router-ha-external-trap.png" width="200" height="300"></p>

<p>善于观察的读者已经发现了一个明显的问题——如果一个Active路由失去了与Internet的连接怎么办？那它还会作为Active路由，但是不能转发？VRRP增加了监控外部连接的能力，并且当发生失败后交出Active路由的地位。</p>

<p>注意：一旦地址发生改变，可能会出发两种模式：</p>

<ul>
<li>每一个路由得到一个新的IP地址，不管VRRP的状态。Master路由将VIP配置为附加的或第二地址。</li>
<li>仅仅VIP配置了。例如：Master路由配置了VIP，同时Slave上没有IP配置。</li>
</ul>


<h2>VRRP —— 一些事实</h2>

<ul>
<li>直接在IP协议中封装</li>
<li>Active实例使用多播地址224.0.0.18, MAC 01-00-5E-00-00-12来给Standby路由发送hello消息</li>
<li>虚拟MAC地址格式：00-00-5E-00-01-{VRID}，因此只有256个不同的VRIDs(0到255)在一个广播域中</li>
<li>选举机制使用用户配置优先级，从1到255，越高优先级越高</li>
<li>优先选举策略(Preemptive elections)，和其他网络协议一样，意味着一个Standby被配置为较高优先级，或者从连接中断回复后(之前是Active实例)，它始终会恢复为Active路由</li>
<li>非优先选举策略(Non-preemptive elections)意外着当Active路由回复后，仍然作为Standby角色</li>
<li>发送Hello间隔是可以设置的(假定为每T秒)，如果Standby路由在3T秒后仍然没有收到master的hello消息，就会触发选举机制</li>
</ul>


<h2>回到Neutron的领地</h2>

<p>L3 HA在每一个路由空间上启动一个keepalived实例。不同路由实例间的通讯，通过制定的HA网络，每一个tenant一个。这个网络是由一个空白的(blank) tenant下创建的，并且无法通过CLI或者GUI操作。这个HA网络也是一个Neutron tenant网络，和所有其他的一样，也是用了默认的分区技术。keepalived流量被转发到HA设备(在keepalived.conf中指定，在路由的命名空间中keepalived实例会使用)。这是路由中命名空间&#8217;ip address&#8217;的输出：</p>

<pre><code>[stack@vpn-6-88 ~]$ sudo ip netns exec qrouter-b30064f9-414e-4c98-ab42-646197c74020 ip address
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default
    ...
2794: &lt;/span&gt;&lt;span style="color:#ff0000;"&gt;&lt;strong&gt;ha-45249562-ec&lt;/strong&gt;&lt;/span&gt;&lt;span style="color:#333333;"&gt;: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UNKNOWN group default
    link/ether 12:34:56:78:2b:5d brd ff:ff:ff:ff:ff:ff
    inet 169.254.0.2/24 brd 169.254.0.255 scope global ha-54b92d86-4f
      valid_lft forever preferred_lft forever
    inet6 fe80::1034:56ff:fe78:2b5d/64 scope link
      valid_lft forever preferred_lft forever
2795: qr-dc9d93c6-e2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UNKNOWN group default
    link/ether ca:fe:de:ad:be:ef brd ff:ff:ff:ff:ff:ff
    inet 10.0.0.1/24 scope global qr-0d51eced-0f
      valid_lft forever preferred_lft forever
    inet6 fe80::c8fe:deff:fead:beef/64 scope link
      valid_lft forever preferred_lft forever
2796: qg-843de7e6-8f: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UNKNOWN group default
    link/ether ca:fe:de:ad:be:ef brd ff:ff:ff:ff:ff:ff
    inet 19.4.4.4/24 scope global qg-75688938-8d
      valid_lft forever preferred_lft forever
    inet6 fe80::c8fe:deff:fead:beef/64 scope link
      valid_lft forever preferred_lft forever&lt;/span&gt;
</code></pre>

<p>这是在master实例中的输出。在另外一个节点的同一个路由上，在ha, hr或者qg设备上没有IP地址。也没有Floating Ip或者是路由记录。这些是被配置在keepalived.conf中的，当keepalived检测到Master实例的失败后，这些地址(或者:VIPs)会被keepalived在适当的设备中重新配置。这是对于同一个路由的keepalived.conf的实例：</p>

<pre><code>vrrp_sync_group VG_1 {
    group {
        VR_1
    }
    notify_backup "/path/to/notify_backup.sh"
    notify_master "/path/to/notify_master.sh"
    notify_fault "/path/to/notify_fault.sh"
}
vrrp_instance VR_1 {
    state BACKUP
    interface ha-45249562-ec
    virtual_router_id 1
    priority 50
    nopreempt
    advert_int 2
    track_interface {
        ha-45249562-ec
    }
    virtual_ipaddress {
        19.4.4.4/24 dev qg-843de7e6-8f
    }
    virtual_ipaddress_excluded {
        10.0.0.1/24 dev qr-dc9d93c6-e2
    }
    virtual_routes {
        0.0.0.0/0 via 19.4.4.1 dev qg-843de7e6-8f
    }
}
</code></pre>

<p>这些notify脚本是干虾米用的呢？这些脚本是被keepalived执行，转换为Master，备份或者失败。这些Master脚本内容：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c">#!/usr/bin/env bash</span>
</span><span class='line'>neutron-ns-metadata-proxy --pid_file<span class="o">=</span>/tmp/tmpp_6Lcx/tmpllLzNs/external/pids/b30064f9-414e-4c98-ab42-646197c74020/pid --metadata_proxy_socket<span class="o">=</span>/tmp/tmpp_6Lcx/tmpllLzNs/metadata_proxy --router_id<span class="o">=</span>b30064f9-414e-4c98-ab42-646197c74020 --state_path<span class="o">=</span>/opt/openstack/neutron --metadata_port<span class="o">=</span><span class="m">9697</span> --debug --verbose
</span><span class='line'><span class="nb">echo</span> -n master &gt; /tmp/tmpp_6Lcx/tmpllLzNs/ha_confs/b30064f9-414e-4c98-ab42-646197c74020/state
</span></code></pre></td></tr></table></div></figure>


<p>这个Master脚本简单的打开了metadata代理，将状态写入文件，状态文件之后会被L3 Agent读取。备份和出错脚本杀死代理服务并且将状态写入刚才的提到的状态文件。这就意味着metadata服务职能在master路由节点存在。</p>

<h2>我们是不是忘了Metadata Agent呢？</h2>

<p>在每个网络节点启动metadata agent就好啦。</p>

<h2>未来的工作和局限性</h2>

<ul>
<li>TCP连接跟踪——在当前的实现中，TCP连接的session在失败恢复后中断。一种解决方案是使用conntrackd复制HA路由间的session状态，这样当故障恢复后，TCP的session会恢复到失败前的状态。</li>
<li>Master节点在哪？当前，还没有办法让管理员知道哪个网络节点是HA路由的Master实例。计划由Agent提供这些信息，并可以通过API进行查询。</li>
<li>Agent大逃亡——理想状态下，将一个节点变为维护模式后，应该触发所有HA路由所在节点回收他们的Master状态，加速恢复速度。</li>
<li>通知L2pop VIP的改变——考虑在一个tenant网络中路由IP/MAC，只有Master配置真正的有IP地址，但是同一个Neutron Port和同样的MAC会在相关的网络出现。这可能对配置了L2pop驱动产生不利，因为它只希望在一个网络中MAC地址只存在一处。解决的计划是一旦检测到VRRP状态改变，从Agent发送一个RPC消息，这样当路由变为Master，控制节点被通知到了，这样就能改变L2pop的状态了。</li>
<li>内置的防火墙、VPN和负载均衡即服务。在DVR和L3 HA与这些服务整合时还有问题，可能会在kilo中解决。</li>
<li>每一个Tenant一个HA网络。这就意味着每个Tenant只能有255个HA路由，因为每个路由需要一个VRID，根据VRRP协议每个广播域只允许255个不同的VRID值。</li>
</ul>


<h2>使用和配置</h2>

<p>neutron.conf</p>

<pre><code>l3_ha = True
max_l3_agents_per_router = 2
min_l3_agents_per_router = 2
</code></pre>

<ul>
<li>l3_ha 表示所有的路由默认使用HA模式(与之前不同)。默认是关闭的。</li>
<li>你可以根据网络节点的数量设置最大最小值。如果你部署了4个网络节点，但是设置最大值为2，只有两个L3 Agent会被用于HA路由(一个是Master，一个是Slave)。</li>
<li>min被用来稳健性(sanity)的检查：如果你有两个网络节点，其中一个坏掉了，任何新建的路由在这段时间都会失败，因为你至少需要min个L3 Agent启动来建立HA路由。</li>
</ul>


<p>l3_ha控制默认的开关，当管理员(仅管理员)通过CLI方式可以覆盖这个选项，为每个路由创建单独的配置：</p>

<pre><code>neutron router-create --ha=&lt;True | False&gt; router1
</code></pre>

<h2>参考文档</h2>

<ul>
<li><a href="https://blueprints.launchpad.net/neutron/+spec/l3-high-availability">Blueprint</a></li>
<li><a href="http://specs.openstack.org/openstack/neutron-specs/specs/juno/l3-high-availability.html">Spec</a></li>
<li><a href="https://docs.google.com/document/d/1P2OnlKAGMeSZTbGENNAKOse6B2TRXJ8keUMVvtUCUSM/">How to test</a></li>
<li><a href="https://review.openstack.org/#/q/topic:bp/l3-high-availability,n,z">Code</a></li>
<li><a href="https://wiki.openstack.org/wiki/Neutron/L3_High_Availability_VRRP">Dedicated wiki page</a></li>
<li><a href="https://wiki.openstack.org/wiki/Meetings/Neutron-L3-Subteam#Blueprint:_l3-high-availability_.28safchain.2C_amuller.29">Section in Neutron L3 sub team wiki (Including overview of patch dependencies and future work)</a></li>
<li><a href="http://assafmuller.com/2014/08/16/layer-3-high-availability/">http://assafmuller.com/2014/08/16/layer-3-high-availability/</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ceph可靠性的量化分析]]></title>
    <link href="http://xiaoquqi.github.io/blog/2015/03/04/ceph-reliability/"/>
    <updated>2015-03-04T08:36:06+08:00</updated>
    <id>http://xiaoquqi.github.io/blog/2015/03/04/ceph-reliability</id>
    <content type="html"><![CDATA[<p>在开始正文之前，首先要感谢UnitedStack工程师朱荣泽对这篇博文的大力帮助和悉心指教。本文主要针对UnitedStack公司在巴黎峰会上对Ceph可靠性的计算方法(<a href="https://www.ustack.com/blog/build-block-storage-service/">https://www.ustack.com/blog/build-block-storage-service/</a>)做了一个更明确的分析和阐述，供对此话题感兴趣的朋友一起来讨论、研究，文章中如果有不当之处，还请各位高人指教。</p>

<!-- more -->


<h2>什么情况下数据会丢失？</h2>

<p>这个话题的另外一种提法就是存储的可靠性，所谓存储的可靠性最基本的一点就是数据不要丢失，也就是我们俗称的“找不回来了”。所以，要分析Ceph的可靠性我们只需要搞清楚，到底在什么情况下我们的数据会丢失，并且再也无法恢复，基于此我们便可以创建我们的计算模型。</p>

<p>我们先来假定一套简单的Ceph环境，3个OSD节点，每个OSD节点对应一块物理硬盘，副本数为3。那么我们排除MON的因素影响Ceph集群的运行的问题，显而易见，当三个OSD对应的物理硬盘全部损坏时，数据必然无法恢复。所以此时集群的可靠性是与硬盘本身的可靠性直接相关。</p>

<p>我们再来假定一套更大的Ceph环境，30个OSD节点，分3个机架摆放，每一个机架有10个OSD节点，每个OSD节点仍然对应一块物理硬盘，副本数为3，并且通过CRUSH MAP，将每一份副本均匀分布在三个机架上，不会出现两份副本同时出现在一个机架的情况。此时，什么时候会出现数据丢失的情况呢？当三个机架上都有一块硬盘损坏，而恰恰这三块硬盘又保存了同一个Object的全部副本，此时数据就会出现丢失的情况。</p>

<p>所以根据以上的分析，我们认为，Ceph的可靠性的计算是与OSD的数量(N)、副本数(R)、每一个服务节点的OSD数量(S)、硬盘的年失败概率(AFR)。这里我们使用UnitedStack相关参数进行计算。</p>

<p>具体取值如下图所示：</p>

<p><img src="http://xiaoquqi.github.io/images/blogs/ceph-reliability-formula.jpg" width="640" height="480"></p>

<p><img src="http://xiaoquqi.github.io/images/blogs/ceph-reliability-constant.jpg" width="640" height="480"></p>

<h2>硬盘年失败概率</h2>

<p>根据维基百科的计算方法(<a href="http://en.wikipedia.org/wiki/Annualized_failure_rate">http://en.wikipedia.org/wiki/Annualized_failure_rate</a>)，AFR的计算方法如下：</p>

<p><img src="http://xiaoquqi.github.io/images/blogs/ceph-reliability-afr.jpg" width="640" height="480"></p>

<p>例如，计算Seagate某企业级硬盘的AFR，根据文档查到MTBF为1,200,000小时，则AFR为0.73%，计算过程如下：</p>

<p><img src="http://xiaoquqi.github.io/images/blogs/ceph-reliability-afr-example.jpg" width="640" height="480"></p>

<p>但是，根据Google的相关计算，在一个大规模集群环境下，往往AFR的值并没有硬盘厂商那样乐观，下面的统计告诉了我们在真实环境下AFR变化的情况：</p>

<p><img src="http://xiaoquqi.github.io/images/blogs/ceph-reliability-google-afr.jpg" width="640" height="480"></p>

<p>所以我们可以看到实际的AFR的变化范围随着年份而变化，取值范围在1.7%-8%左右，所以本文中AFR为1.7%。</p>

<h2>硬盘在一年之内损坏的概率</h2>

<p>有了AFR，我们就可以尝试计算硬盘在一年中出现故障的概率，根据相关研究，硬盘在一定时间内的失败概率符合Possion分布(已经把知识还给老师的同学请移步：<a href="http://en.wikipedia.org/wiki/Poisson_distribution">http://en.wikipedia.org/wiki/Poisson_distribution</a>)。具体的计算公式为：</p>

<p><img src="http://xiaoquqi.github.io/images/blogs/ceph-reliability-Pn.jpg" width="640" height="480"></p>

<p>当我最初拿到这个计算公式时，一下子懵了，到底该如何确定数学期望值lamda呢？</p>

<h2>lamda的计算过程</h2>

<p>根据相关的研究资料，单块的硬盘损坏的期望值(Failures in Time)是指每10亿小时硬盘的失败率(Failure Rate λ)，计算过程如下：</p>

<p><img src="http://xiaoquqi.github.io/images/blogs/ceph-reliability-fit.jpg" width="640" height="480"></p>

<p>这里的Af(Acceleration Factor)是由测试时间乘以阿伦尼乌斯方程的值得出来的结果，好吧，我承认，我也是现学现卖，这个方程式是化学反应的速率常数与温度之间的关系式，适用于基元反应和非基元反应，甚至某些非均相反应。不过可以看出Failure Rate的计算过程实质主要是计算环境因素引起的物理变化，最终导致失败的数学期望值。所以根据相关研究，最终FIT的计算方法为：</p>

<p><img src="http://xiaoquqi.github.io/images/blogs/ceph-reliability-fit-afr.jpg" width="640" height="480"></p>

<p>有了这些参数后，我们就可以开始正式计算Ceph集群中，不同机架上有三块硬盘同时出现损坏的概率啦。</p>

<h2>任意一个OSD出现损坏的概率P1(any)</h2>

<p>我们不太容易直接去计算任意一个OSD出现损坏的概率，但是我们很容易计算没有OSD出现问题的概率，方法如下，用一减去无OSD节点出现问题的概率，得到P1(any)。</p>

<p><img src="http://xiaoquqi.github.io/images/blogs/ceph-reliability-osd1-failure.jpg" width="640" height="480"></p>

<h2>在恢复时间内第二个节点出现故障的概率P2(any)</h2>

<p>我们知道当Ceph发现一个有问题的OSD节点时，会自动的将节点OUT出去，这个时间大约为10min，同时Ceph的自我修复机制会自动平衡数据，将故障节点的数据重新分配在其他的OSD节点上。</p>

<p>我们假设我们单盘的容量为1000 GB，使用率为75%，也就是此时将有750 GB的数据需要同步。我们的数据只在本机架平衡，节点写入速度为50 MB/s，计算方法如下：</p>

<p><img src="http://xiaoquqi.github.io/images/blogs/ceph-reliability-recovery-time.jpg" width="640" height="480"></p>

<p>注意：由于每个节点有三个OSD，所以要求每台物理机所承受的节点带宽至少要大于150 MB/s。并且在这个计算模型下，并没有计算元数据、请求数据、IP包头等额外的信息的大小。</p>

<p>有了Recovery Time，我们就可以计算我们第二个节点在Recovery Time内失败的概率，具体的计算过程如下：</p>

<p><img src="http://xiaoquqi.github.io/images/blogs/ceph-reliability-osd2-failure.jpg" width="640" height="480"></p>

<h2>在恢复时间内第三个节点出现故障的概率P3(any)</h2>

<p>计算方法同上，计算过程如下：</p>

<p><img src="http://xiaoquqi.github.io/images/blogs/ceph-reliability-osd3-failure.jpg" width="640" height="480"></p>

<h2>一年内任意副本数&reg;个OSD出现故障的概率</h2>

<p>所以将上述概率相乘即可得到一年内任意副本数&reg;个OSD出现故障的概率。</p>

<p><img src="http://xiaoquqi.github.io/images/blogs/ceph-reliability-arbitrary-osd-failure.jpg" width="640" height="480"></p>

<h2>Copy Sets(M)</h2>

<p>在这个计算模型中，因为任意R个OSD节点的损坏并不意外着副本的完全丢失，因为损坏的R个OSD未必保存着一个Object的全部副本信息，所以未必造成数据不可恢复，所以这里引入了Copy Sets的概念。简单来说，Copyset就是存放所有拷贝的一个集合，具体的定义和计算方法可以查看参考链接。那么这里的场景下，Copy Sets为三个机架OSD数量相乘，即M=24<em>24</em>24。当然如果是两个副本的情况下，M应该为24<em>24+24</em>24+24*24。</p>

<p><img src="http://xiaoquqi.github.io/images/blogs/ceph-reliability-copysets.jpg" width="640" height="480"></p>

<h2>CEPH的可靠性</h2>

<p>所以最终归纳出CEPH可靠性的算法为：</p>

<p><img src="http://xiaoquqi.github.io/images/blogs/ceph-reliability-copysets-failure.jpg" width="640" height="480"></p>

<p>可以看出Ceph三副本的可靠性大约为9个9，由于Recovery Time和AFR取值的问题，所以计算结果和UnitedStack上略有出入。</p>

<h2>参考链接</h2>

<ul>
<li><a href="http://en.wikipedia.org/wiki/Annualized_failure_rate">Annualized Failure Rate</a></li>
<li><a href="http://en.wikipedia.org/wiki/Poisson_distribution">Poisson distribution</a></li>
<li><a href="http://www.microsemi.com/document-portal/doc_view/124041-calculating-reliability-using-fit-mttf-arrhenius-htol-model">Calculating Reliability using FIT &amp; MTTF: Arrhenius HTOL Model</a></li>
<li><a href="http://storagemojo.com/2007/02/19/googles-disk-failure-experience/">Google’s Disk Failure Experience</a></li>
<li><a href="https://static.googleusercontent.com/media/research.google.com/en//archive/disk_failures.pdf">Failure Trends in a Large Disk Drive Population</a></li>
<li><a href="http://0b4af6cdc2f0c5998459-c0245c5c937c5dedcca3f1764ecc9b2f.r43.cf2.rackcdn.com/11727-atc13-cidon.pdf">Copysets: Reducing the Frequency of Data Loss in Cloud Storage</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[OpenStack虚拟机的高可靠]]></title>
    <link href="http://xiaoquqi.github.io/blog/2015/03/03/openstack-instance-ha-high-availability/"/>
    <updated>2015-03-03T20:58:19+08:00</updated>
    <id>http://xiaoquqi.github.io/blog/2015/03/03/openstack-instance-ha-high-availability</id>
    <content type="html"><![CDATA[<p>译者注：OpenStack虚拟机级别的HA是在企业私有云中必须提及的话题，换句话说如果没有此机制，很多企业级用户根本不会考虑使用OpenStack+开源云平台的解决方案。这一点也得益于VMware等大公司孜孜不倦、持之以恒、长年累月的对用户的洗脑，这样的洗脑让用户觉得一些VMware的功能成为了“云”的标准(HA/FT/DRS/DPM等)。个人认为，OpenStack这部分功能的缺失也直接的阻碍了OpenStack进入中国行业用户的步伐，记得在夏天的时候，华为曾经为社区提供了一个HA的解决方案(用C语言实现)，打算贡献给社区，但是经过社区激烈的讨论，终于不了了之。</p>

<p>在我所经历的私有云项目中，也尝试了一些虚拟机级别的HA解决方案，我的个人观点是，如果将OpenStack作为一个项目，可以不提供HA，但是作为产品，必须要提供HA的解决方案(私有云)。这篇文章中提到HA实现的过程，也恰恰是我们在实际中遇到的状况，下面让我们来看一看OpenStack社区是如何设想实现该问题的。感谢 @陈沙克 微博提供的资料。</p>

<!-- more -->


<p>原文地址：<a href="http://blog.russellbryant.net/2014/10/15/openstack-instance-ha-proposal/">http://blog.russellbryant.net/2014/10/15/openstack-instance-ha-proposal/</a></p>

<p>在一个完美世界中(不是那个游戏公司)，OpenStack承载的云主机上运行的应用都应当具备天然的横向扩展能力和容灾能力。但是现实世界却并不是这样。我们一直看到在OpenStack运行传统负载的需求积极伴随而来的HA的需求。</p>

<p>传统应用运行在OpenStack在大多数情况下是没有问题的。一些需要可靠性要求的应用部署在OpenStack上是没有自动提供这种能力的。如果虚拟化软件挂掉了，没人会去拯救运行在上面的虚拟机。OpenStack中有手动拯救的能力，但是这需要云平台的运维人员或者外部的工具完成。</p>

<p>这篇文章主要讨论如何在虚拟化程序失败后自动侦测并拯救运行在上面的虚拟机于水火之中。对于不同的虚拟机化软件有不同的解决方案。我这里主要关注libivrt/kvm，下面的部分也主要围绕着它进行。除非特别提及libvirt，我想所有提及的一切也同样适用于xenserver驱动。</p>

<p>这是OpenStack社区的定期讨论的话题。已经有反对将这个功能放到OpenStack。无论哪个功能组件被使用，我想我们应该提供一个针对问题的解决方案。我想使用现有的软件来解决这个问题。</p>

<h3>范围</h3>

<p>我们主要针对基础架构层的故障。也有其他的一些因素会影响应用的可靠性。客户机的操作系统或者软件自身出现故障。对于这种故障的恢复，我们主要留给应用的开发者或部署者。</p>

<p>值得注意的是，OpenStack中的libvirt/kvm驱动并不包含于客户机操作系统故障相关的功能。在Icehouse版本中的Nova实现了一个libvirt-watchdog的blueprint。这个功能允许你设置hw_watchdog_action属性在image或是flavor中。合法的值包含：poweroff，rest，pause和none。当选项被打开时，libvirt会为客户机开启i7300esb watchdog驱动，并且当watchdog被出发时发送动作。这可能是对你客户机故障恢复策略很有帮助的部件。</p>

<h3>架构</h3>

<p>解决这个问题需要一些关键的部件：</p>

<ul>
<li>监控(Monitoring) - 系统检测到虚拟化层的故障</li>
<li>隔离(或是围栏，Fencing) - 系统隔离故障计算节点</li>
<li>恢复(Recovery) - 从故障的虚拟化上恢复虚拟机</li>
</ul>


<h3>监控</h3>

<p>针对这种解决方案的监控部件有两个主要需求：</p>

<ul>
<li>检测主机是否已经失败</li>
<li>针对错误出发自动的相应(隔离和恢复)</li>
</ul>


<p>通常建议这个解决方案应该是OpenStack的一部分。很多人建议这个功能应该在Nova中实现。将这个部分放在Nova中主要是因为，Nova已经能过获知运行环境下的基础架构的健康状况。servicegroup API能够提供基础的组的成员信息。特别是他持续跟踪计算节点的活跃状态。然而，这只能提供你nova-compute服务本身的状态。对于客户的虚拟机而言(即使nova-compute不再运行)，他们也能运行良好。将基础架构层的状态信息放入Nova之中，有违Nova的层级。无论如何，这将对Nova有一个重大的(管理)范围的扩大，所以我也不指望Nova团队会同意这么做。</p>

<p>还有一种建议是将功能做进Heat里。最重要的功能问题是，我们不该让云平台用户去使用Heat重启他们出现故障的虚拟机。另外一种建议是用其他的(可能是全新的)OpenStack模块来做这件事情。像我不喜欢这些放在Nova的理由一样，我也不认为他们该放在新的模块一样( I don’t like that for many of the same reasons I don’t think it should be in Nova.)。我觉得这件事情应该是基础架构层需要支持的，而不是OpenStack自己。</p>

<p>放弃将这部分功能放入OpenStack的想法，我认为应当从基础架构的角度入手支持OpenStack部署。许多OpenStack部署中已经使用了Pacemaker提供部署中的高可靠。从历史的角度来看，由于集群中横向限制，Pacemaker并不会用在计算节点上，因为他们太多了。这个限制其实在Corosync而不是Pacemaker本身。最近，Pacemaker提供了一个新功能叫做pacemaker_remote，允许将一台主机作为Pacemaker集群的一部分，而不需要作为Corosync集群的一部分。这样看起来可以被作为OpenStack计算节点的一个合适的解决方案。</p>

<p>许多OpenStack部署中也使用监控工具像Nagios来监控他们的计算节点。这也很合理。</p>

<h3>隔离(Fencing)</h3>

<p>概括一下，隔离就是将故障的计算节点完全隔离(isolates)。举个例子，这个可能由IPMI保证失败的节点已经关机了。隔离非常重要，有以下几点原有。很多原因都会造成节点故障，我们在将同样的虚拟机恢复之前，完全确认它确实不在(completely gone)啦。我们不想让我们的虚拟机跑两份。用户也肯定不想看到。更糟糕的是，处理自动疏散(evacuate)时，OpenStack的部署可能是基于共享存储的，跑两个一样的虚拟机可能会引起数据损坏，因为两个虚拟机尝试使用同一块磁盘。另外一个问题就是，在网络上产生两个相同的IP。</p>

<p>用Pacemaker最大的好处就是他内建隔离，因为这正是HA解决方案中的一个核心组件。如果你使用Nagios，隔离的集成需要你自己实现。</p>

<h3>恢复</h3>

<p>一旦故障被检测到并且计算节点被隔离，需要触发疏散(evacuate)。概括一下，所谓疏散就是将一台故障节点的虚拟机实例在另外一个节点上启动起来。Nova提供了API去疏散一个实例。这个功能正常工作的前提是需要虚拟机磁盘文件在共享存储上。或者是从卷启动的。有意思的是，即使疏散中没有以上两个条件，API仍然可以运行。结果就是用基础镜像重新启动一个新的实例而没有任何数据。这样的唯一好处就是你得到一个和你之前虚拟机相同UUID的实例。</p>

<p>一个通用的疏散用例是“从一个指定的Host上疏散所有虚拟机”。因为这个太通用了，所以这个功能在novalcient库中实现了(译者：Juno更新日志提到了这一点)。所以监控工具可以通过novaclient触发这个功能。</p>

<p>如果这个功能在你的OpenStack的部署上用于所有虚拟机，那么我们的解决方案还是挺好的。许多人有了额外的需求：用户应该可以自行对每一个虚拟机做(HA)的设定。这个的确很合理，但是却带来了一个额外的问题。我们在OpenStack中该如何让用户指定哪台虚拟机需要被自动恢复？</p>

<p>通常的方式就是用镜像的属性或者规格的extra-specs。这样当然可以工作，但是对于我好像并不太灵活。我并不认为用户应该创建一个新的镜像叫做“让这个虚拟机一直运行”。Flavor的extra-specs还行，如果你觉得为你所有虚拟机使用特殊的flavor或者是flavor类。在任何一种情况下，都需要修改novaclient的&#8221;疏散一个Host&#8221;来支持他。</p>

<p>另外一种潜在的解决方案是使用一个用户自定义的特殊标记。已经有一个正在review的功能提供一个API来给虚拟机打标签(tagging)。对于我们的讨论，我们假设标签是“自动回复”。我们也需要更新novaclient来支持“将所有带指定标记的虚拟机从Host疏散”。监控工具也会触发这个功能，让novalcient将带有“自动恢复“标记的所有虚拟机从Host疏散。</p>

<h3>结论和下一步计划</h3>

<p>虚拟机的HA显然是许多部署需要提供的功能。我相信可以通过在部署中将现有软件进行集成方式实现，特别是Pacemaker。下一步就是提供具体的信息，如何建立已经如何测试。</p>

<p>我希望有人可能说”但是我已经使用系统Foo(Nagios或其他的什么)来监控我的计算节点“。你也可以按照这条路尝试。我不确认如何将Nagios之类的监控软件和隔离部分进行整合。如果在这个解决方案中跳过隔离，你要在失败时保持和平(keep the pieces when it breaks，译者：就是上面提到的fencing出现的问题)。除此之外，你的监控系统能够像Pacemaker一样出发novalcient的疏散功能。</p>

<p>未来非常好的开发方向可能是将这个功能集成到OpenStack管理界面。我希望通过部署的控制面板告诉我哪些失败了，出发了哪些响应动作。这个需要pcsd提供REST API(WIP)来导出这些信息。</p>

<p>最后，值得思考一下TripleO在这个问题的内容。如果你使用OpenStack部署OpenStack，解决方案是不是不同呢？在那个世界里，你所有的裸金属节点都是通过OpenStack Ironic管理的资源。Ceilometer可以被用于监控这些资源。如果是那样，OpenStack本身就有足够的信息来支持基础设施完成这个功能。再次强调，为了避免对OpenStack的改造，我们在这种条件小也应该使用更通用的Pacemaker解决方案。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用MongoDB作为Salt Pillar后端存储数据]]></title>
    <link href="http://xiaoquqi.github.io/blog/2015/02/23/use-mongodb-to-store-salt-pillar/"/>
    <updated>2015-02-23T15:19:21+08:00</updated>
    <id>http://xiaoquqi.github.io/blog/2015/02/23/use-mongodb-to-store-salt-pillar</id>
    <content type="html"><![CDATA[<p>今天在查找salt中pillar嵌套pillar的方法时，无意之间发现了pillar除了可以直接使用文件(sls)外，也同时支持多种后端的数据存储方式。例如：MySQL, MongoDB, Ldap, json, cobbler甚至是puppet。这无疑为开发中的接口提供了极大的便利。</p>

<!-- more -->


<p>详细的支持列表可见：<a href="http://docs.saltstack.com/en/latest/ref/pillar/all/index.html#all-salt-pillars">http://docs.saltstack.com/en/latest/ref/pillar/all/index.html#all-salt-pillars</a></p>

<p>严格意义上来说，这篇博文并非完全原创，英文原文请参考：<a href="http://www.tmartin.io/articles/2014/salt-pillar-mongodb/">http://www.tmartin.io/articles/2014/salt-pillar-mongodb/</a></p>

<p>下面就来说说详细的配置方式，假定你已经有了一个部署好的salt环境，并且正确配置了salt master和salt minion，并且完成认证，主机名为salt-master.salt.com，这里我们使用Ubuntu 12.04 64bit作为演示环境。</p>

<h2>安装MongoDB和Python MongoDB</h2>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>apt-get install mongodb python-pymongo python-pymongo-ext</span></code></pre></td></tr></table></div></figure>


<p>确保你能连接到MongoDB</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>mongo</span></code></pre></td></tr></table></div></figure>


<pre><code>MongoDB shell version: 2.2.3
connecting to: test
&gt;
</code></pre>

<h2>创建MongoDB数据库和存放Pillar的Collection</h2>

<ul>
<li>创建数据库pillar</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>use pillar</span></code></pre></td></tr></table></div></figure>


<ul>
<li>在数据库中插入pillar数据</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>db.pillar.insert({
</span><span class='line'>    _id: 'salt-master.salt.com',
</span><span class='line'>    mongo_pillar: {
</span><span class='line'>        key1: "value1",
</span><span class='line'>        key2: "value2",
</span><span class='line'>    }})</span></code></pre></td></tr></table></div></figure>


<p>注意：这里的_id必须要和你的minion节点的主机名一致，并且无法使用通配符，也就是一个节点都有自己一套独立的pillar，这一点和文件中定义pillar有很大的不同。mongo_pillar部分中是定义的是pillar中的内容，也就是我们可以直接引用的部分。</p>

<h3>配置Salt Master</h3>

<ul>
<li><p>下一步就是告诉Salt Master，我们在MongoDB中存放了pillar数据，需要劳您大驾，移步MongoDB读取数据。修改：</p>

<p>  /etc/salt/master</p></li>
</ul>


<p>添加</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>mongo.db: "pillar"
</span><span class='line'>mongo.host: "localhost"
</span><span class='line'>ext_pillar:
</span><span class='line'>    - mongo: {}</span></code></pre></td></tr></table></div></figure>


<p>注意：如果需要使用不同于标准安装接口，请使用mongo.port，如果需要配置用户名和密码，请使用mongo.user和mongo.password。其他参数定义，请详见：<a href="http://docs.saltstack.com/en/latest/ref/pillar/all/salt.pillar.mongo.html#module-documentation">http://docs.saltstack.com/en/latest/ref/pillar/all/salt.pillar.mongo.html#module-documentation</a></p>

<ul>
<li>测试</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>salt salt-master.salt.com pillar.item mongo_pillar</span></code></pre></td></tr></table></div></figure>


<p>返回</p>

<pre><code>salt-master.salt.com:
    ----------
    mongo_pillar:
        ----------
        key1:
            value1
        key2:
            value2
</code></pre>

<ul>
<li>如果想在sls中直接使用</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{{ salt['pillar.get']('mongo_pillar:key1') }}</span></code></pre></td></tr></table></div></figure>


<h2>总结</h2>

<p>pillar应该是salt中一个比较灵活的配置选项，个人理解pillar的作用就像puppet中init定义的初始化的参数的默认值，每次部署时，只需要更改pillar的文件就可以啦。但是随着代码的增长(主要用于部署OpenStack)，发现pillar的管理越来越难，pillar本身对如何组织结构并没有严格的限制，而且嵌套(extend)功能暂时还不能很完美的支持(<a href="https://github.com/saltstack/salt/issues/3991">https://github.com/saltstack/salt/issues/3991</a>)，这也给pillar的管理提高了复杂度。</p>
]]></content>
  </entry>
  
</feed>
